======================

outer fold 1
lay_id=0
feature 149 (0.040106)
feature 171 (0.031250)
feature 162 (0.025201)
feature 144 (0.022835)
feature 127 (0.020868)
feature 138 (0.020820)
feature 218 (0.020274)
feature 151 (0.019212)
feature 137 (0.017295)
feature 438 (0.016766)
feature 134 (0.016600)
feature 196 (0.016232)
feature 164 (0.015831)
feature 95 (0.015630)
feature 184 (0.015416)
feature 78 (0.014644)
feature 340 (0.014222)
feature 223 (0.013857)
feature 379 (0.013753)
feature 161 (0.013129)
feature 42 (0.012617)
feature 271 (0.012435)
feature 98 (0.011697)
feature 290 (0.011595)
feature 160 (0.011485)
feature 1 (0.011126)
feature 97 (0.010830)
feature 167 (0.010797)
feature 20 (0.010564)
feature 38 (0.010535)
inner fold=0
accuracy=0.630434782609
feature 100 (0.039068)
feature 132 (0.024597)
feature 51 (0.023705)
feature 167 (0.021785)
feature 38 (0.021758)
feature 171 (0.021194)
feature 180 (0.018871)
feature 126 (0.018125)
feature 144 (0.017819)
feature 138 (0.016942)
feature 170 (0.016696)
feature 161 (0.015915)
feature 223 (0.015498)
feature 231 (0.015436)
feature 66 (0.014899)
feature 80 (0.013587)
feature 26 (0.013380)
feature 139 (0.013019)
feature 10 (0.012885)
feature 57 (0.012609)
feature 155 (0.011974)
feature 290 (0.011777)
feature 220 (0.011743)
feature 54 (0.011257)
feature 58 (0.011239)
feature 32 (0.011238)
feature 212 (0.010980)
feature 29 (0.010635)
feature 143 (0.010622)
feature 78 (0.010422)
inner fold=1
accuracy=0.586956521739
feature 170 (0.030910)
feature 290 (0.024744)
feature 199 (0.021270)
feature 77 (0.019281)
feature 73 (0.018718)
feature 14 (0.018426)
feature 139 (0.016516)
feature 160 (0.016163)
feature 177 (0.015418)
feature 144 (0.015126)
feature 147 (0.015034)
feature 156 (0.014904)
feature 134 (0.014881)
feature 152 (0.014250)
feature 206 (0.014205)
feature 42 (0.014149)
feature 162 (0.013605)
feature 209 (0.012685)
feature 204 (0.012313)
feature 54 (0.012074)
feature 69 (0.011733)
feature 98 (0.011344)
feature 116 (0.011129)
feature 131 (0.010980)
feature 145 (0.010916)
feature 189 (0.010854)
feature 167 (0.010140)
feature 168 (0.009998)
feature 336 (0.009539)
feature 10 (0.009504)
inner fold=2
accuracy=0.622222222222
feature 42 (0.033677)
feature 290 (0.032373)
feature 227 (0.029679)
feature 122 (0.027589)
feature 25 (0.026207)
feature 121 (0.021081)
feature 209 (0.020535)
feature 124 (0.016367)
feature 153 (0.016358)
feature 78 (0.016218)
feature 69 (0.016117)
feature 97 (0.016056)
feature 131 (0.015306)
feature 144 (0.013937)
feature 134 (0.013771)
feature 48 (0.013431)
feature 26 (0.013301)
feature 354 (0.012826)
feature 180 (0.012745)
feature 377 (0.012671)
feature 168 (0.012194)
feature 40 (0.012096)
feature 379 (0.012089)
feature 210 (0.011472)
feature 164 (0.011209)
feature 219 (0.011144)
feature 199 (0.010662)
feature 152 (0.010545)
feature 8 (0.010375)
feature 147 (0.010307)
inner fold=3
accuracy=0.688888888889
feature 132 (0.036452)
feature 290 (0.032467)
feature 205 (0.030536)
feature 40 (0.026022)
feature 121 (0.024954)
feature 74 (0.023111)
feature 125 (0.021356)
feature 161 (0.018297)
feature 52 (0.017364)
feature 51 (0.017312)
feature 153 (0.015806)
feature 111 (0.014944)
feature 0 (0.014466)
feature 212 (0.013699)
feature 231 (0.013692)
feature 49 (0.013445)
feature 195 (0.013366)
feature 10 (0.013342)
feature 4 (0.013301)
feature 168 (0.012484)
feature 155 (0.011938)
feature 75 (0.011906)
feature 97 (0.011900)
feature 79 (0.011297)
feature 209 (0.011244)
feature 162 (0.011185)
feature 118 (0.011047)
feature 36 (0.010406)
feature 144 (0.010017)
feature 180 (0.009738)
inner fold=4
accuracy=0.533333333333
feature 42 (0.030746)
feature 110 (0.027304)
feature 170 (0.024916)
feature 40 (0.024811)
feature 164 (0.023523)
feature 199 (0.022343)
feature 340 (0.018751)
feature 148 (0.017367)
feature 227 (0.017128)
feature 75 (0.016382)
feature 34 (0.015955)
feature 127 (0.015592)
feature 209 (0.015090)
feature 332 (0.014397)
feature 105 (0.013418)
feature 14 (0.013361)
feature 106 (0.013237)
feature 231 (0.013115)
feature 153 (0.013007)
feature 130 (0.012866)
feature 358 (0.012786)
feature 290 (0.012461)
feature 134 (0.012444)
feature 149 (0.012419)
feature 10 (0.011875)
feature 97 (0.011840)
feature 196 (0.011417)
feature 126 (0.010777)
feature 169 (0.010612)
feature 171 (0.010570)
inner fold=0
accuracy=0.586956521739
feature 168 (0.032958)
feature 129 (0.029685)
feature 164 (0.028996)
feature 152 (0.027539)
feature 77 (0.026723)
feature 154 (0.024960)
feature 199 (0.020224)
feature 227 (0.019974)
feature 46 (0.019835)
feature 137 (0.019657)
feature 20 (0.018424)
feature 127 (0.015964)
feature 9 (0.015496)
feature 290 (0.015319)
feature 149 (0.015296)
feature 42 (0.013162)
feature 209 (0.013055)
feature 144 (0.013046)
feature 47 (0.012185)
feature 408 (0.011896)
feature 110 (0.011116)
feature 78 (0.011009)
feature 358 (0.010878)
feature 148 (0.010848)
feature 139 (0.010770)
feature 106 (0.010700)
feature 133 (0.010676)
feature 145 (0.009843)
feature 268 (0.009824)
feature 52 (0.009547)
inner fold=1
accuracy=0.652173913043
feature 168 (0.039520)
feature 160 (0.021008)
feature 340 (0.020606)
feature 54 (0.019848)
feature 231 (0.019697)
feature 162 (0.019482)
feature 165 (0.019304)
feature 218 (0.016610)
feature 130 (0.016252)
feature 99 (0.015863)
feature 227 (0.015751)
feature 157 (0.014779)
feature 106 (0.014771)
feature 161 (0.014719)
feature 119 (0.014397)
feature 77 (0.014351)
feature 290 (0.014109)
feature 199 (0.014025)
feature 215 (0.014009)
feature 164 (0.012742)
feature 133 (0.012521)
feature 392 (0.012447)
feature 377 (0.012303)
feature 381 (0.011842)
feature 129 (0.011586)
feature 230 (0.011381)
feature 95 (0.011140)
feature 223 (0.011061)
feature 75 (0.011021)
feature 10 (0.011013)
inner fold=2
accuracy=0.577777777778
feature 164 (0.036131)
feature 54 (0.032408)
feature 100 (0.027594)
feature 125 (0.026007)
feature 48 (0.023359)
feature 97 (0.018990)
feature 160 (0.018987)
feature 290 (0.018155)
feature 77 (0.018141)
feature 209 (0.016867)
feature 169 (0.014944)
feature 162 (0.014650)
feature 96 (0.014357)
feature 148 (0.014245)
feature 95 (0.014118)
feature 132 (0.013969)
feature 46 (0.013850)
feature 227 (0.013326)
feature 204 (0.013304)
feature 94 (0.013283)
feature 198 (0.012751)
feature 44 (0.012744)
feature 65 (0.012543)
feature 98 (0.012430)
feature 42 (0.011764)
feature 14 (0.011756)
feature 335 (0.011654)
feature 179 (0.011309)
feature 163 (0.011134)
feature 207 (0.010860)
inner fold=3
accuracy=0.688888888889
feature 32 (0.032543)
feature 130 (0.030755)
feature 169 (0.020146)
feature 161 (0.017656)
feature 38 (0.017403)
feature 218 (0.016721)
feature 48 (0.016226)
feature 131 (0.016130)
feature 290 (0.016055)
feature 157 (0.015479)
feature 96 (0.015276)
feature 106 (0.015079)
feature 42 (0.015048)
feature 340 (0.014805)
feature 223 (0.014507)
feature 97 (0.013860)
feature 126 (0.013860)
feature 123 (0.013822)
feature 227 (0.013217)
feature 77 (0.013160)
feature 134 (0.012647)
feature 46 (0.012647)
feature 52 (0.012627)
feature 211 (0.011831)
feature 95 (0.011627)
feature 124 (0.011587)
feature 168 (0.011485)
feature 53 (0.011278)
feature 151 (0.010958)
feature 199 (0.010927)
inner fold=4
accuracy=0.555555555556

lay_id=1
feature 213 (0.026454)
feature 109 (0.023602)
feature 80 (0.023543)
feature 171 (0.020650)
feature 231 (0.020552)
feature 202 (0.020189)
feature 294 (0.019188)
feature 81 (0.018687)
feature 52 (0.018250)
feature 208 (0.017402)
feature 126 (0.017353)
feature 101 (0.017202)
feature 55 (0.016990)
feature 172 (0.016457)
feature 216 (0.015516)
feature 139 (0.015039)
feature 127 (0.014367)
feature 152 (0.014342)
feature 115 (0.013750)
feature 123 (0.012920)
feature 138 (0.012407)
feature 156 (0.011986)
feature 175 (0.011946)
feature 412 (0.011904)
feature 1 (0.011137)
feature 272 (0.011111)
feature 102 (0.011065)
feature 44 (0.010548)
feature 165 (0.010472)
feature 24 (0.010269)
inner fold=0
accuracy=0.521739130435
feature 46 (0.041540)
feature 148 (0.025157)
feature 82 (0.020607)
feature 213 (0.020068)
feature 174 (0.017250)
feature 135 (0.016895)
feature 211 (0.016601)
feature 385 (0.016364)
feature 47 (0.016080)
feature 125 (0.015899)
feature 62 (0.015758)
feature 99 (0.015686)
feature 227 (0.015679)
feature 129 (0.015469)
feature 179 (0.015037)
feature 115 (0.014764)
feature 104 (0.014537)
feature 199 (0.014081)
feature 53 (0.012921)
feature 173 (0.012116)
feature 153 (0.012085)
feature 187 (0.012065)
feature 81 (0.011925)
feature 201 (0.011808)
feature 30 (0.011599)
feature 223 (0.011269)
feature 156 (0.011067)
feature 139 (0.011049)
feature 165 (0.010799)
feature 2 (0.010627)
inner fold=1
accuracy=0.608695652174
feature 203 (0.028998)
feature 227 (0.028101)
feature 44 (0.027850)
feature 33 (0.026232)
feature 172 (0.022921)
feature 173 (0.022068)
feature 106 (0.020929)
feature 383 (0.020445)
feature 168 (0.019045)
feature 50 (0.018356)
feature 184 (0.017741)
feature 80 (0.017288)
feature 142 (0.016850)
feature 134 (0.016122)
feature 123 (0.014856)
feature 102 (0.014784)
feature 213 (0.014651)
feature 157 (0.014096)
feature 231 (0.013589)
feature 174 (0.013100)
feature 148 (0.012702)
feature 175 (0.012556)
feature 344 (0.012176)
feature 131 (0.011932)
feature 101 (0.011651)
feature 139 (0.011170)
feature 57 (0.011065)
feature 21 (0.010830)
feature 143 (0.010829)
feature 209 (0.010741)
inner fold=2
accuracy=0.644444444444
feature 168 (0.046290)
feature 227 (0.032424)
feature 123 (0.031055)
feature 156 (0.028692)
feature 84 (0.028683)
feature 153 (0.024627)
feature 129 (0.023665)
feature 203 (0.022821)
feature 46 (0.021257)
feature 148 (0.019032)
feature 294 (0.018393)
feature 53 (0.016973)
feature 166 (0.015523)
feature 231 (0.015346)
feature 24 (0.013478)
feature 47 (0.013140)
feature 130 (0.013014)
feature 101 (0.012634)
feature 173 (0.012303)
feature 109 (0.012246)
feature 174 (0.012165)
feature 127 (0.012150)
feature 0 (0.012014)
feature 151 (0.011860)
feature 155 (0.011813)
feature 27 (0.011797)
feature 171 (0.011389)
feature 209 (0.010983)
feature 40 (0.010782)
feature 55 (0.010772)
inner fold=3
accuracy=0.644444444444
feature 172 (0.051380)
feature 294 (0.035359)
feature 203 (0.024716)
feature 199 (0.023192)
feature 122 (0.022488)
feature 174 (0.021255)
feature 130 (0.020291)
feature 138 (0.020074)
feature 168 (0.017096)
feature 129 (0.016081)
feature 156 (0.015811)
feature 58 (0.015420)
feature 38 (0.014062)
feature 148 (0.013891)
feature 202 (0.013865)
feature 134 (0.013062)
feature 30 (0.012898)
feature 183 (0.012475)
feature 110 (0.012145)
feature 53 (0.011929)
feature 90 (0.011894)
feature 131 (0.011424)
feature 0 (0.011091)
feature 142 (0.010887)
feature 33 (0.010747)
feature 211 (0.010710)
feature 115 (0.010538)
feature 139 (0.010351)
feature 385 (0.010310)
feature 5 (0.010186)
inner fold=4
accuracy=0.577777777778
feature 207 (0.023563)
feature 51 (0.022695)
feature 106 (0.022162)
feature 188 (0.021449)
feature 148 (0.018282)
feature 164 (0.017691)
feature 131 (0.016270)
feature 129 (0.015892)
feature 165 (0.015669)
feature 53 (0.015259)
feature 142 (0.015227)
feature 14 (0.014609)
feature 143 (0.014214)
feature 294 (0.014201)
feature 84 (0.013096)
feature 110 (0.012987)
feature 194 (0.012886)
feature 13 (0.012759)
feature 171 (0.012687)
feature 79 (0.012489)
feature 2 (0.012480)
feature 99 (0.012001)
feature 50 (0.011984)
feature 101 (0.011926)
feature 151 (0.011769)
feature 30 (0.011756)
feature 235 (0.011042)
feature 3 (0.010971)
feature 172 (0.010900)
feature 82 (0.010544)
inner fold=0
accuracy=0.630434782609
feature 294 (0.021021)
feature 33 (0.018670)
feature 135 (0.018320)
feature 213 (0.018270)
feature 81 (0.017900)
feature 78 (0.016318)
feature 107 (0.016139)
feature 202 (0.014868)
feature 174 (0.014217)
feature 173 (0.013824)
feature 57 (0.013478)
feature 82 (0.012825)
feature 155 (0.012438)
feature 24 (0.012366)
feature 165 (0.012141)
feature 18 (0.012111)
feature 73 (0.011648)
feature 156 (0.011453)
feature 97 (0.011330)
feature 149 (0.010720)
feature 381 (0.010672)
feature 387 (0.010444)
feature 137 (0.010348)
feature 77 (0.010145)
feature 231 (0.010022)
feature 108 (0.009946)
feature 171 (0.009667)
feature 114 (0.009516)
feature 412 (0.009418)
feature 110 (0.009254)
inner fold=1
accuracy=0.565217391304
feature 172 (0.037606)
feature 70 (0.024305)
feature 4 (0.021869)
feature 81 (0.021260)
feature 0 (0.018377)
feature 12 (0.017968)
feature 152 (0.017067)
feature 106 (0.015673)
feature 207 (0.015625)
feature 174 (0.014772)
feature 222 (0.014249)
feature 122 (0.014146)
feature 169 (0.014073)
feature 160 (0.013947)
feature 121 (0.013922)
feature 80 (0.013751)
feature 125 (0.013587)
feature 223 (0.013567)
feature 383 (0.013527)
feature 180 (0.013346)
feature 155 (0.013280)
feature 159 (0.013069)
feature 188 (0.012108)
feature 3 (0.012042)
feature 182 (0.011998)
feature 141 (0.011762)
feature 275 (0.011511)
feature 184 (0.011262)
feature 73 (0.011152)
feature 127 (0.010997)
inner fold=2
accuracy=0.466666666667
feature 171 (0.027374)
feature 81 (0.026991)
feature 77 (0.026080)
feature 14 (0.022393)
feature 5 (0.020310)
feature 53 (0.020172)
feature 56 (0.018471)
feature 125 (0.018294)
feature 110 (0.016428)
feature 114 (0.015652)
feature 137 (0.015459)
feature 12 (0.015458)
feature 34 (0.013931)
feature 21 (0.013813)
feature 283 (0.013113)
feature 123 (0.013110)
feature 80 (0.012298)
feature 164 (0.012239)
feature 272 (0.012176)
feature 213 (0.012173)
feature 148 (0.011628)
feature 46 (0.011581)
feature 231 (0.011544)
feature 51 (0.011466)
feature 30 (0.011309)
feature 15 (0.011054)
feature 381 (0.011053)
feature 84 (0.011051)
feature 54 (0.011033)
feature 211 (0.010752)
inner fold=3
accuracy=0.622222222222
feature 53 (0.024428)
feature 16 (0.024065)
feature 46 (0.021447)
feature 44 (0.020415)
feature 123 (0.019703)
feature 214 (0.018176)
feature 171 (0.017432)
feature 81 (0.017238)
feature 172 (0.016721)
feature 454 (0.015774)
feature 209 (0.014634)
feature 110 (0.013908)
feature 153 (0.013833)
feature 99 (0.013513)
feature 131 (0.013412)
feature 161 (0.013303)
feature 143 (0.013069)
feature 55 (0.012977)
feature 235 (0.012969)
feature 142 (0.012654)
feature 203 (0.012384)
feature 56 (0.012089)
feature 30 (0.011978)
feature 155 (0.011806)
feature 261 (0.011441)
feature 166 (0.011328)
feature 294 (0.010717)
feature 390 (0.010538)
feature 165 (0.010486)
feature 157 (0.010462)
inner fold=4
accuracy=0.666666666667

lay_id=2
feature 294 (0.030337)
feature 43 (0.028904)
feature 127 (0.025914)
feature 231 (0.020631)
feature 114 (0.018037)
feature 51 (0.016286)
feature 142 (0.015902)
feature 126 (0.015036)
feature 48 (0.014812)
feature 362 (0.014583)
feature 46 (0.014321)
feature 30 (0.014226)
feature 166 (0.013872)
feature 169 (0.013714)
feature 171 (0.013314)
feature 53 (0.012889)
feature 164 (0.012848)
feature 125 (0.012844)
feature 185 (0.012461)
feature 77 (0.012302)
feature 200 (0.012088)
feature 344 (0.011713)
feature 174 (0.011623)
feature 173 (0.011543)
feature 115 (0.011504)
feature 110 (0.011466)
feature 58 (0.011302)
feature 203 (0.011167)
feature 227 (0.011008)
feature 129 (0.010941)
inner fold=0
accuracy=0.695652173913
feature 171 (0.023030)
feature 30 (0.020798)
feature 164 (0.020335)
feature 134 (0.019686)
feature 110 (0.019383)
feature 40 (0.019373)
feature 81 (0.018951)
feature 4 (0.018199)
feature 139 (0.017886)
feature 136 (0.017109)
feature 159 (0.017086)
feature 14 (0.015246)
feature 38 (0.015153)
feature 188 (0.014736)
feature 173 (0.014330)
feature 161 (0.014076)
feature 157 (0.014043)
feature 50 (0.013462)
feature 129 (0.013310)
feature 77 (0.012743)
feature 53 (0.012718)
feature 135 (0.012553)
feature 52 (0.012417)
feature 168 (0.012368)
feature 183 (0.012366)
feature 138 (0.012344)
feature 108 (0.012336)
feature 149 (0.012168)
feature 56 (0.011963)
feature 120 (0.011902)
inner fold=1
accuracy=0.521739130435
feature 166 (0.035580)
feature 137 (0.022110)
feature 211 (0.021210)
feature 84 (0.019635)
feature 134 (0.018557)
feature 157 (0.017321)
feature 46 (0.016784)
feature 294 (0.016595)
feature 14 (0.015765)
feature 168 (0.014014)
feature 30 (0.013397)
feature 209 (0.013120)
feature 172 (0.012936)
feature 153 (0.012846)
feature 0 (0.012758)
feature 201 (0.012555)
feature 207 (0.012492)
feature 222 (0.011279)
feature 81 (0.010991)
feature 171 (0.010945)
feature 223 (0.010888)
feature 53 (0.010615)
feature 143 (0.010525)
feature 58 (0.010378)
feature 121 (0.010250)
feature 155 (0.010240)
feature 219 (0.010174)
feature 78 (0.010120)
feature 227 (0.010079)
feature 107 (0.010066)
inner fold=2
accuracy=0.688888888889
feature 29 (0.034252)
feature 123 (0.021874)
feature 174 (0.021451)
feature 106 (0.019188)
feature 110 (0.017292)
feature 55 (0.017203)
feature 171 (0.016841)
feature 166 (0.016834)
feature 130 (0.016598)
feature 4 (0.015866)
feature 202 (0.015497)
feature 51 (0.015000)
feature 33 (0.014937)
feature 164 (0.014512)
feature 158 (0.014384)
feature 100 (0.014185)
feature 102 (0.013636)
feature 44 (0.013237)
feature 120 (0.012850)
feature 231 (0.012673)
feature 79 (0.012501)
feature 21 (0.012429)
feature 77 (0.012243)
feature 136 (0.012157)
feature 211 (0.012061)
feature 172 (0.011886)
feature 70 (0.011783)
feature 40 (0.011397)
feature 58 (0.011082)
feature 145 (0.011041)
inner fold=3
accuracy=0.533333333333
feature 128 (0.025070)
feature 153 (0.024871)
feature 151 (0.022635)
feature 231 (0.021924)
feature 142 (0.021587)
feature 171 (0.020259)
feature 165 (0.019565)
feature 184 (0.019322)
feature 174 (0.018931)
feature 158 (0.018821)
feature 148 (0.018695)
feature 38 (0.018592)
feature 168 (0.017846)
feature 182 (0.016060)
feature 141 (0.014763)
feature 84 (0.014753)
feature 135 (0.014705)
feature 188 (0.014390)
feature 136 (0.014112)
feature 172 (0.013923)
feature 46 (0.013899)
feature 227 (0.013076)
feature 134 (0.012838)
feature 294 (0.012394)
feature 199 (0.012294)
feature 62 (0.012100)
feature 70 (0.010861)
feature 30 (0.010749)
feature 157 (0.010636)
feature 114 (0.010584)
inner fold=4
accuracy=0.577777777778
feature 110 (0.032523)
feature 52 (0.030584)
feature 203 (0.028159)
feature 18 (0.018837)
feature 202 (0.018835)
feature 344 (0.017966)
feature 109 (0.017251)
feature 136 (0.016857)
feature 81 (0.016105)
feature 166 (0.016011)
feature 294 (0.015975)
feature 156 (0.015602)
feature 84 (0.015298)
feature 34 (0.015002)
feature 148 (0.014233)
feature 127 (0.014196)
feature 8 (0.013460)
feature 99 (0.013392)
feature 77 (0.012655)
feature 41 (0.012641)
feature 214 (0.012262)
feature 175 (0.011975)
feature 160 (0.011717)
feature 85 (0.011626)
feature 275 (0.011434)
feature 464 (0.011362)
feature 129 (0.011216)
feature 0 (0.010980)
feature 272 (0.010583)
feature 155 (0.010371)
inner fold=0
accuracy=0.630434782609
feature 294 (0.039554)
feature 215 (0.031465)
feature 211 (0.025613)
feature 199 (0.023910)
feature 155 (0.023179)
feature 454 (0.020990)
feature 123 (0.020060)
feature 46 (0.019799)
feature 171 (0.018811)
feature 142 (0.017825)
feature 208 (0.017480)
feature 14 (0.016443)
feature 172 (0.016219)
feature 60 (0.016012)
feature 156 (0.015982)
feature 134 (0.015144)
feature 121 (0.015063)
feature 44 (0.014555)
feature 80 (0.014437)
feature 175 (0.014290)
feature 42 (0.014051)
feature 153 (0.013244)
feature 385 (0.013197)
feature 139 (0.012826)
feature 174 (0.012588)
feature 216 (0.012465)
feature 261 (0.011781)
feature 209 (0.011194)
feature 115 (0.011122)
feature 408 (0.010518)
inner fold=1
accuracy=0.608695652174
feature 171 (0.035168)
feature 46 (0.029745)
feature 208 (0.028309)
feature 203 (0.022180)
feature 155 (0.020832)
feature 222 (0.020744)
feature 136 (0.019179)
feature 80 (0.017929)
feature 134 (0.017823)
feature 145 (0.017771)
feature 294 (0.016723)
feature 129 (0.016610)
feature 52 (0.016556)
feature 193 (0.014940)
feature 148 (0.013542)
feature 57 (0.013517)
feature 38 (0.012907)
feature 168 (0.012466)
feature 126 (0.012260)
feature 170 (0.012224)
feature 412 (0.012058)
feature 84 (0.011927)
feature 173 (0.011912)
feature 42 (0.011540)
feature 223 (0.011493)
feature 109 (0.011438)
feature 235 (0.011378)
feature 151 (0.010719)
feature 184 (0.010714)
feature 99 (0.010500)
inner fold=2
accuracy=0.688888888889
feature 84 (0.030010)
feature 231 (0.025209)
feature 173 (0.024404)
feature 110 (0.019405)
feature 14 (0.019168)
feature 215 (0.019090)
feature 139 (0.018636)
feature 44 (0.018589)
feature 52 (0.018396)
feature 203 (0.017603)
feature 207 (0.016608)
feature 165 (0.016321)
feature 385 (0.015895)
feature 126 (0.015623)
feature 12 (0.015616)
feature 81 (0.015029)
feature 383 (0.014510)
feature 152 (0.013375)
feature 153 (0.013041)
feature 294 (0.012926)
feature 442 (0.012778)
feature 109 (0.012649)
feature 142 (0.012573)
feature 164 (0.012505)
feature 101 (0.012137)
feature 390 (0.011947)
feature 159 (0.011917)
feature 56 (0.011790)
feature 223 (0.011280)
feature 161 (0.011007)
inner fold=3
accuracy=0.511111111111
feature 172 (0.032142)
feature 143 (0.024844)
feature 174 (0.019840)
feature 97 (0.018901)
feature 294 (0.018808)
feature 128 (0.018557)
feature 148 (0.018557)
feature 203 (0.018314)
feature 201 (0.017362)
feature 161 (0.015484)
feature 106 (0.015094)
feature 129 (0.015094)
feature 222 (0.015041)
feature 188 (0.014861)
feature 171 (0.014063)
feature 131 (0.013385)
feature 58 (0.013141)
feature 21 (0.013020)
feature 142 (0.012849)
feature 156 (0.012150)
feature 223 (0.011916)
feature 48 (0.011775)
feature 152 (0.011736)
feature 383 (0.011519)
feature 344 (0.010962)
feature 109 (0.010906)
feature 52 (0.010354)
feature 336 (0.010155)
feature 149 (0.009988)
feature 24 (0.009689)
inner fold=4
accuracy=0.644444444444

lay_id=3
feature 129 (0.021800)
feature 130 (0.019759)
feature 14 (0.019652)
feature 30 (0.019576)
feature 176 (0.016958)
feature 156 (0.016953)
feature 164 (0.016930)
feature 97 (0.016733)
feature 57 (0.014818)
feature 153 (0.014555)
feature 152 (0.014298)
feature 442 (0.014199)
feature 18 (0.013759)
feature 207 (0.013386)
feature 80 (0.013190)
feature 148 (0.012917)
feature 184 (0.012894)
feature 171 (0.012860)
feature 137 (0.012620)
feature 142 (0.012335)
feature 172 (0.011965)
feature 110 (0.011771)
feature 210 (0.011662)
feature 56 (0.010810)
feature 155 (0.010644)
feature 100 (0.010464)
feature 58 (0.010448)
feature 202 (0.010262)
feature 115 (0.010121)
feature 166 (0.010086)
inner fold=0
accuracy=0.608695652174
feature 156 (0.040623)
feature 166 (0.028687)
feature 129 (0.023487)
feature 172 (0.023030)
feature 53 (0.019481)
feature 159 (0.019406)
feature 24 (0.017431)
feature 381 (0.017064)
feature 99 (0.016641)
feature 105 (0.015995)
feature 215 (0.015557)
feature 199 (0.015014)
feature 137 (0.014493)
feature 114 (0.014183)
feature 145 (0.014081)
feature 175 (0.013779)
feature 294 (0.013653)
feature 43 (0.013467)
feature 115 (0.013126)
feature 30 (0.012153)
feature 181 (0.011983)
feature 174 (0.011846)
feature 135 (0.011749)
feature 203 (0.011525)
feature 141 (0.010826)
feature 18 (0.010598)
feature 198 (0.010592)
feature 2 (0.010464)
feature 78 (0.010457)
feature 122 (0.010432)
inner fold=1
accuracy=0.673913043478
feature 166 (0.047643)
feature 102 (0.026069)
feature 157 (0.023707)
feature 33 (0.022323)
feature 159 (0.022227)
feature 203 (0.021533)
feature 125 (0.021329)
feature 171 (0.019908)
feature 81 (0.018856)
feature 294 (0.017015)
feature 126 (0.015808)
feature 18 (0.015154)
feature 0 (0.014393)
feature 158 (0.014217)
feature 160 (0.014158)
feature 146 (0.013656)
feature 56 (0.013554)
feature 123 (0.013504)
feature 57 (0.013176)
feature 136 (0.012687)
feature 128 (0.012507)
feature 130 (0.012507)
feature 47 (0.012145)
feature 12 (0.011828)
feature 137 (0.011789)
feature 19 (0.011288)
feature 153 (0.011222)
feature 234 (0.010966)
feature 58 (0.010730)
feature 172 (0.010516)
inner fold=2
accuracy=0.644444444444
feature 156 (0.037933)
feature 166 (0.028541)
feature 165 (0.022608)
feature 216 (0.022303)
feature 84 (0.022134)
feature 171 (0.021376)
feature 120 (0.019544)
feature 235 (0.019106)
feature 227 (0.018940)
feature 81 (0.018421)
feature 125 (0.018073)
feature 30 (0.016959)
feature 203 (0.015306)
feature 151 (0.015131)
feature 136 (0.015057)
feature 62 (0.014617)
feature 188 (0.013957)
feature 50 (0.013768)
feature 167 (0.012516)
feature 58 (0.012007)
feature 33 (0.011963)
feature 199 (0.011682)
feature 139 (0.011624)
feature 164 (0.010730)
feature 215 (0.010695)
feature 53 (0.010620)
feature 202 (0.010265)
feature 294 (0.009996)
feature 78 (0.009952)
feature 70 (0.009580)
inner fold=3
accuracy=0.666666666667
feature 202 (0.037016)
feature 142 (0.032138)
feature 151 (0.028906)
feature 123 (0.026181)
feature 172 (0.025204)
feature 174 (0.024174)
feature 158 (0.022060)
feature 81 (0.021811)
feature 44 (0.021167)
feature 216 (0.018576)
feature 211 (0.018043)
feature 223 (0.017672)
feature 43 (0.016136)
feature 54 (0.015049)
feature 210 (0.014324)
feature 231 (0.014043)
feature 16 (0.013831)
feature 203 (0.013715)
feature 175 (0.013527)
feature 30 (0.013408)
feature 128 (0.012848)
feature 130 (0.012006)
feature 127 (0.011651)
feature 213 (0.011514)
feature 42 (0.011085)
feature 5 (0.010965)
feature 164 (0.010535)
feature 377 (0.010232)
feature 38 (0.010172)
feature 159 (0.010115)
inner fold=4
accuracy=0.533333333333
feature 208 (0.035116)
feature 203 (0.033637)
feature 24 (0.030683)
feature 294 (0.028517)
feature 138 (0.028148)
feature 336 (0.020962)
feature 84 (0.020080)
feature 148 (0.019677)
feature 135 (0.019444)
feature 30 (0.018042)
feature 153 (0.017257)
feature 143 (0.016558)
feature 145 (0.015899)
feature 57 (0.015854)
feature 209 (0.015848)
feature 202 (0.015656)
feature 58 (0.015417)
feature 101 (0.015268)
feature 109 (0.014905)
feature 29 (0.014617)
feature 300 (0.014470)
feature 80 (0.013531)
feature 139 (0.013306)
feature 95 (0.012274)
feature 157 (0.011901)
feature 165 (0.011379)
feature 126 (0.010714)
feature 129 (0.010700)
feature 18 (0.010603)
feature 164 (0.010228)
inner fold=0
accuracy=0.521739130435
feature 156 (0.037149)
feature 164 (0.033450)
feature 12 (0.027338)
feature 136 (0.021850)
feature 139 (0.020394)
feature 202 (0.019826)
feature 55 (0.019713)
feature 390 (0.019257)
feature 8 (0.017402)
feature 33 (0.014663)
feature 82 (0.014591)
feature 81 (0.014578)
feature 129 (0.014568)
feature 227 (0.014114)
feature 61 (0.013836)
feature 214 (0.013106)
feature 155 (0.012831)
feature 131 (0.012593)
feature 149 (0.012499)
feature 142 (0.012407)
feature 44 (0.012295)
feature 211 (0.012001)
feature 115 (0.011415)
feature 135 (0.011383)
feature 138 (0.011361)
feature 5 (0.010704)
feature 145 (0.010378)
feature 84 (0.010302)
feature 43 (0.010296)
feature 153 (0.009880)
inner fold=1
accuracy=0.608695652174
feature 227 (0.034281)
feature 142 (0.026656)
feature 46 (0.026033)
feature 128 (0.024931)
feature 109 (0.021397)
feature 143 (0.021191)
feature 18 (0.019812)
feature 148 (0.018480)
feature 106 (0.018009)
feature 174 (0.016497)
feature 53 (0.015393)
feature 342 (0.014879)
feature 126 (0.014801)
feature 235 (0.014539)
feature 188 (0.013817)
feature 159 (0.013450)
feature 39 (0.013316)
feature 80 (0.012552)
feature 156 (0.012021)
feature 139 (0.011823)
feature 197 (0.011767)
feature 158 (0.011346)
feature 166 (0.011293)
feature 219 (0.011061)
feature 84 (0.010689)
feature 3 (0.010159)
feature 181 (0.010150)
feature 272 (0.010039)
feature 203 (0.009657)
feature 164 (0.009641)
inner fold=2
accuracy=0.644444444444
feature 168 (0.032625)
feature 81 (0.030743)
feature 138 (0.021705)
feature 158 (0.020032)
feature 344 (0.018663)
feature 172 (0.018516)
feature 55 (0.018172)
feature 294 (0.017477)
feature 131 (0.017168)
feature 122 (0.016386)
feature 79 (0.015944)
feature 129 (0.015786)
feature 0 (0.015183)
feature 3 (0.014974)
feature 126 (0.014458)
feature 70 (0.013844)
feature 235 (0.013530)
feature 38 (0.013154)
feature 194 (0.012959)
feature 159 (0.012844)
feature 164 (0.012511)
feature 102 (0.012488)
feature 174 (0.012170)
feature 77 (0.012151)
feature 14 (0.011371)
feature 223 (0.011297)
feature 171 (0.011136)
feature 125 (0.011094)
feature 107 (0.010862)
feature 216 (0.010799)
inner fold=3
accuracy=0.466666666667
feature 172 (0.045341)
feature 156 (0.033268)
feature 381 (0.027730)
feature 227 (0.025503)
feature 52 (0.025266)
feature 294 (0.024275)
feature 168 (0.024191)
feature 208 (0.022507)
feature 5 (0.019397)
feature 110 (0.018928)
feature 174 (0.017191)
feature 123 (0.015814)
feature 106 (0.014817)
feature 78 (0.014502)
feature 134 (0.014117)
feature 120 (0.012891)
feature 3 (0.012531)
feature 54 (0.012384)
feature 147 (0.011725)
feature 137 (0.011664)
feature 107 (0.011608)
feature 223 (0.011577)
feature 138 (0.011077)
feature 83 (0.011037)
feature 15 (0.010505)
feature 71 (0.010082)
feature 159 (0.010016)
feature 46 (0.009829)
feature 122 (0.009788)
feature 35 (0.009717)
inner fold=4
accuracy=0.688888888889

lay_id=4
feature 168 (0.035685)
feature 81 (0.021514)
feature 156 (0.020001)
feature 152 (0.019710)
feature 203 (0.019682)
feature 176 (0.017753)
feature 294 (0.017660)
feature 139 (0.017513)
feature 142 (0.017269)
feature 30 (0.017186)
feature 385 (0.014590)
feature 114 (0.014485)
feature 33 (0.014451)
feature 50 (0.014070)
feature 62 (0.013977)
feature 167 (0.013504)
feature 145 (0.013411)
feature 151 (0.013321)
feature 383 (0.013191)
feature 55 (0.013171)
feature 207 (0.013151)
feature 13 (0.013121)
feature 79 (0.012739)
feature 174 (0.012448)
feature 122 (0.011876)
feature 199 (0.011336)
feature 38 (0.011042)
feature 1 (0.011041)
feature 214 (0.011030)
feature 208 (0.010723)
inner fold=0
accuracy=0.586956521739
feature 203 (0.028981)
feature 79 (0.026502)
feature 211 (0.023750)
feature 81 (0.020986)
feature 47 (0.018347)
feature 130 (0.018337)
feature 294 (0.017628)
feature 1 (0.017490)
feature 46 (0.017162)
feature 14 (0.015938)
feature 73 (0.015927)
feature 171 (0.015212)
feature 34 (0.013912)
feature 208 (0.012646)
feature 174 (0.012200)
feature 159 (0.012183)
feature 202 (0.011723)
feature 69 (0.011693)
feature 215 (0.011692)
feature 153 (0.011558)
feature 158 (0.011343)
feature 383 (0.011312)
feature 390 (0.011255)
feature 114 (0.010652)
feature 110 (0.010629)
feature 157 (0.010490)
feature 165 (0.010428)
feature 24 (0.010409)
feature 4 (0.010089)
feature 44 (0.009847)
inner fold=1
accuracy=0.608695652174
feature 42 (0.028149)
feature 12 (0.026637)
feature 203 (0.024296)
feature 166 (0.024280)
feature 159 (0.023512)
feature 151 (0.018399)
feature 156 (0.017984)
feature 148 (0.017700)
feature 142 (0.017126)
feature 294 (0.016922)
feature 130 (0.016669)
feature 81 (0.015637)
feature 14 (0.014754)
feature 74 (0.014160)
feature 187 (0.014042)
feature 174 (0.013534)
feature 381 (0.013012)
feature 104 (0.012885)
feature 21 (0.012231)
feature 50 (0.012205)
feature 131 (0.012078)
feature 99 (0.012072)
feature 128 (0.011957)
feature 106 (0.011708)
feature 129 (0.011397)
feature 122 (0.011379)
feature 57 (0.010836)
feature 38 (0.010792)
feature 41 (0.010730)
feature 135 (0.010290)
inner fold=2
accuracy=0.488888888889
feature 33 (0.036468)
feature 44 (0.035163)
feature 171 (0.028142)
feature 120 (0.027139)
feature 227 (0.024950)
feature 12 (0.023238)
feature 125 (0.022401)
feature 168 (0.017749)
feature 156 (0.017239)
feature 152 (0.017154)
feature 42 (0.016587)
feature 1 (0.016558)
feature 140 (0.015947)
feature 85 (0.015904)
feature 81 (0.014859)
feature 122 (0.014796)
feature 175 (0.014542)
feature 129 (0.013856)
feature 14 (0.013124)
feature 148 (0.013073)
feature 138 (0.012978)
feature 136 (0.012068)
feature 82 (0.011817)
feature 135 (0.011264)
feature 142 (0.011078)
feature 48 (0.010922)
feature 188 (0.010868)
feature 100 (0.010789)
feature 134 (0.010635)
feature 207 (0.010364)
inner fold=3
accuracy=0.555555555556
feature 134 (0.025673)
feature 123 (0.024779)
feature 201 (0.022945)
feature 223 (0.020673)
feature 135 (0.018797)
feature 153 (0.018691)
feature 174 (0.017572)
feature 58 (0.017540)
feature 60 (0.017038)
feature 173 (0.016730)
feature 14 (0.016726)
feature 79 (0.016469)
feature 157 (0.015836)
feature 18 (0.015071)
feature 152 (0.015042)
feature 227 (0.014527)
feature 275 (0.013635)
feature 46 (0.013519)
feature 194 (0.013424)
feature 156 (0.013398)
feature 138 (0.013165)
feature 210 (0.012934)
feature 166 (0.012919)
feature 24 (0.012400)
feature 101 (0.012355)
feature 122 (0.011675)
feature 70 (0.011521)
feature 82 (0.011285)
feature 102 (0.011185)
feature 148 (0.010653)
inner fold=4
accuracy=0.644444444444
feature 166 (0.076960)
feature 14 (0.038109)
feature 171 (0.032365)
feature 203 (0.022745)
feature 152 (0.019917)
feature 199 (0.019633)
feature 168 (0.018896)
feature 1 (0.018187)
feature 200 (0.017825)
feature 344 (0.017326)
feature 8 (0.016674)
feature 73 (0.015605)
feature 156 (0.015235)
feature 40 (0.014849)
feature 223 (0.014700)
feature 377 (0.013103)
feature 27 (0.012600)
feature 77 (0.012296)
feature 138 (0.012143)
feature 57 (0.011625)
feature 173 (0.011083)
feature 235 (0.010977)
feature 78 (0.010406)
feature 182 (0.010202)
feature 390 (0.010040)
feature 53 (0.009950)
feature 134 (0.009515)
feature 145 (0.009384)
feature 213 (0.009362)
feature 231 (0.009203)
inner fold=0
accuracy=0.630434782609
feature 84 (0.030936)
feature 14 (0.026064)
feature 166 (0.025356)
feature 156 (0.025274)
feature 40 (0.023768)
feature 46 (0.022066)
feature 202 (0.021306)
feature 12 (0.019594)
feature 171 (0.018727)
feature 1 (0.017566)
feature 105 (0.015652)
feature 153 (0.015373)
feature 223 (0.014598)
feature 79 (0.014340)
feature 138 (0.014056)
feature 294 (0.013467)
feature 143 (0.013376)
feature 196 (0.013185)
feature 120 (0.012989)
feature 62 (0.012835)
feature 139 (0.012790)
feature 101 (0.012414)
feature 160 (0.012144)
feature 222 (0.011977)
feature 211 (0.011951)
feature 210 (0.011729)
feature 235 (0.011257)
feature 168 (0.010498)
feature 192 (0.009621)
feature 3 (0.009564)
inner fold=1
accuracy=0.630434782609
feature 166 (0.026920)
feature 129 (0.020491)
feature 110 (0.019259)
feature 215 (0.018900)
feature 29 (0.018329)
feature 168 (0.017930)
feature 158 (0.017731)
feature 142 (0.017569)
feature 51 (0.017148)
feature 136 (0.016910)
feature 4 (0.016155)
feature 21 (0.015567)
feature 79 (0.015264)
feature 148 (0.015217)
feature 80 (0.014876)
feature 81 (0.014119)
feature 362 (0.012663)
feature 77 (0.012643)
feature 15 (0.012331)
feature 131 (0.012223)
feature 155 (0.012158)
feature 364 (0.012139)
feature 214 (0.012102)
feature 222 (0.012078)
feature 103 (0.011561)
feature 169 (0.011063)
feature 62 (0.010784)
feature 174 (0.010613)
feature 60 (0.010545)
feature 54 (0.010522)
inner fold=2
accuracy=0.688888888889
feature 168 (0.044714)
feature 171 (0.035895)
feature 56 (0.033138)
feature 12 (0.026024)
feature 211 (0.020958)
feature 208 (0.019239)
feature 142 (0.018527)
feature 81 (0.016160)
feature 97 (0.015874)
feature 344 (0.015492)
feature 173 (0.015401)
feature 156 (0.015045)
feature 130 (0.014701)
feature 100 (0.014408)
feature 153 (0.013922)
feature 33 (0.012835)
feature 52 (0.012430)
feature 51 (0.012188)
feature 73 (0.012062)
feature 44 (0.011970)
feature 146 (0.011864)
feature 42 (0.011121)
feature 123 (0.011038)
feature 166 (0.010564)
feature 383 (0.010523)
feature 109 (0.010336)
feature 46 (0.010112)
feature 169 (0.009103)
feature 381 (0.008919)
feature 53 (0.008910)
inner fold=3
accuracy=0.688888888889
feature 46 (0.034942)
feature 110 (0.020170)
feature 166 (0.019821)
feature 159 (0.019211)
feature 143 (0.018708)
feature 145 (0.017295)
feature 203 (0.016211)
feature 52 (0.015179)
feature 24 (0.015137)
feature 165 (0.015104)
feature 372 (0.015094)
feature 12 (0.015065)
feature 135 (0.014921)
feature 138 (0.014719)
feature 172 (0.014465)
feature 130 (0.014113)
feature 56 (0.013710)
feature 51 (0.013387)
feature 294 (0.013387)
feature 125 (0.012892)
feature 77 (0.012643)
feature 156 (0.012500)
feature 216 (0.012440)
feature 272 (0.012191)
feature 82 (0.011616)
feature 148 (0.011578)
feature 81 (0.011336)
feature 114 (0.011307)
feature 208 (0.011192)
feature 38 (0.011125)
inner fold=4
accuracy=0.711111111111

lay_id=5
feature 235 (0.027340)
feature 183 (0.027168)
feature 153 (0.025242)
feature 44 (0.024400)
feature 78 (0.020404)
feature 131 (0.019813)
feature 2 (0.018665)
feature 215 (0.016349)
feature 223 (0.016225)
feature 383 (0.016175)
feature 166 (0.015794)
feature 84 (0.014598)
feature 184 (0.014216)
feature 208 (0.014141)
feature 182 (0.013971)
feature 1 (0.013671)
feature 145 (0.013580)
feature 137 (0.013514)
feature 29 (0.013514)
feature 14 (0.012183)
feature 213 (0.012002)
feature 172 (0.011968)
feature 63 (0.011738)
feature 207 (0.011309)
feature 30 (0.011174)
feature 81 (0.010804)
feature 57 (0.010714)
feature 336 (0.010643)
feature 197 (0.010602)
feature 125 (0.010411)
inner fold=0
accuracy=0.673913043478
feature 22 (0.023239)
feature 362 (0.022867)
feature 381 (0.021193)
feature 56 (0.019892)
feature 235 (0.019419)
feature 106 (0.017592)
feature 215 (0.015885)
feature 24 (0.015633)
feature 216 (0.015196)
feature 84 (0.014633)
feature 53 (0.014200)
feature 127 (0.013797)
feature 285 (0.013355)
feature 115 (0.012930)
feature 62 (0.012107)
feature 199 (0.012047)
feature 2 (0.011874)
feature 231 (0.011824)
feature 153 (0.011083)
feature 159 (0.010889)
feature 30 (0.010822)
feature 12 (0.010576)
feature 161 (0.010289)
feature 42 (0.010241)
feature 44 (0.010139)
feature 168 (0.010033)
feature 107 (0.010004)
feature 156 (0.009942)
feature 43 (0.009902)
feature 227 (0.009894)
inner fold=1
accuracy=0.695652173913
feature 84 (0.032049)
feature 46 (0.027665)
feature 14 (0.026092)
feature 30 (0.022953)
feature 115 (0.018272)
feature 138 (0.017928)
feature 172 (0.017785)
feature 147 (0.017763)
feature 183 (0.017150)
feature 128 (0.016131)
feature 12 (0.015518)
feature 151 (0.014818)
feature 174 (0.014694)
feature 199 (0.014455)
feature 29 (0.014406)
feature 175 (0.014157)
feature 139 (0.013348)
feature 74 (0.013002)
feature 165 (0.012647)
feature 362 (0.012594)
feature 201 (0.012296)
feature 168 (0.012172)
feature 100 (0.011800)
feature 142 (0.011485)
feature 24 (0.010853)
feature 131 (0.010565)
feature 275 (0.010475)
feature 81 (0.010335)
feature 126 (0.010047)
feature 78 (0.009807)
inner fold=2
accuracy=0.6
feature 153 (0.034409)
feature 172 (0.032849)
feature 136 (0.022329)
feature 148 (0.021184)
feature 107 (0.019363)
feature 30 (0.018812)
feature 129 (0.018596)
feature 63 (0.018069)
feature 123 (0.016796)
feature 214 (0.016725)
feature 165 (0.016687)
feature 156 (0.016627)
feature 80 (0.016509)
feature 201 (0.015770)
feature 52 (0.015276)
feature 159 (0.014145)
feature 134 (0.013762)
feature 82 (0.013753)
feature 381 (0.013339)
feature 203 (0.013222)
feature 362 (0.013131)
feature 135 (0.012993)
feature 127 (0.012398)
feature 175 (0.012014)
feature 216 (0.011871)
feature 157 (0.011719)
feature 3 (0.011698)
feature 126 (0.011658)
feature 155 (0.010987)
feature 81 (0.010703)
inner fold=3
accuracy=0.644444444444
feature 171 (0.027861)
feature 123 (0.025660)
feature 24 (0.022286)
feature 143 (0.021320)
feature 120 (0.017953)
feature 142 (0.016544)
feature 184 (0.016384)
feature 2 (0.015927)
feature 84 (0.014995)
feature 147 (0.014843)
feature 157 (0.014800)
feature 168 (0.014286)
feature 55 (0.014201)
feature 29 (0.013772)
feature 50 (0.013662)
feature 14 (0.013577)
feature 80 (0.013418)
feature 12 (0.013409)
feature 164 (0.012867)
feature 122 (0.012279)
feature 9 (0.012121)
feature 294 (0.011920)
feature 203 (0.011824)
feature 48 (0.011599)
feature 172 (0.011586)
feature 167 (0.010956)
feature 128 (0.010917)
feature 79 (0.010895)
feature 82 (0.010681)
feature 46 (0.010455)
inner fold=4
accuracy=0.555555555556
feature 156 (0.062984)
feature 203 (0.041695)
feature 235 (0.026313)
feature 142 (0.025131)
feature 395 (0.020245)
feature 171 (0.019142)
feature 46 (0.018953)
feature 60 (0.018250)
feature 79 (0.016978)
feature 34 (0.016744)
feature 127 (0.016409)
feature 137 (0.014941)
feature 362 (0.014708)
feature 12 (0.014115)
feature 161 (0.014047)
feature 97 (0.013555)
feature 272 (0.013304)
feature 130 (0.012711)
feature 81 (0.012395)
feature 136 (0.011768)
feature 214 (0.011652)
feature 0 (0.010745)
feature 30 (0.010501)
feature 78 (0.010347)
feature 123 (0.010225)
feature 43 (0.009967)
feature 207 (0.009865)
feature 135 (0.009695)
feature 294 (0.009549)
feature 184 (0.009031)
inner fold=0
accuracy=0.673913043478
feature 203 (0.038425)
feature 84 (0.028045)
feature 222 (0.025049)
feature 30 (0.024777)
feature 171 (0.022201)
feature 134 (0.019705)
feature 44 (0.019555)
feature 159 (0.019302)
feature 78 (0.019266)
feature 172 (0.018690)
feature 215 (0.017704)
feature 166 (0.015816)
feature 173 (0.015657)
feature 28 (0.014879)
feature 127 (0.013874)
feature 43 (0.013196)
feature 109 (0.013122)
feature 294 (0.012483)
feature 184 (0.011939)
feature 174 (0.011715)
feature 136 (0.011529)
feature 358 (0.011470)
feature 211 (0.011437)
feature 24 (0.011325)
feature 287 (0.010629)
feature 12 (0.010562)
feature 47 (0.010528)
feature 165 (0.010342)
feature 377 (0.010341)
feature 362 (0.010166)
inner fold=1
accuracy=0.565217391304
feature 12 (0.040308)
feature 172 (0.026268)
feature 164 (0.022879)
feature 175 (0.022840)
feature 84 (0.021547)
feature 275 (0.021042)
feature 173 (0.020090)
feature 127 (0.020056)
feature 209 (0.019029)
feature 227 (0.018699)
feature 168 (0.017621)
feature 123 (0.017351)
feature 235 (0.017062)
feature 81 (0.016039)
feature 139 (0.015592)
feature 138 (0.015167)
feature 158 (0.015147)
feature 137 (0.014966)
feature 385 (0.014610)
feature 171 (0.013835)
feature 156 (0.013683)
feature 134 (0.013663)
feature 58 (0.013462)
feature 145 (0.013349)
feature 147 (0.013196)
feature 104 (0.012570)
feature 157 (0.011929)
feature 30 (0.011826)
feature 102 (0.011581)
feature 287 (0.011100)
inner fold=2
accuracy=0.511111111111
feature 142 (0.038321)
feature 168 (0.023693)
feature 294 (0.023684)
feature 79 (0.022549)
feature 203 (0.022409)
feature 148 (0.020788)
feature 156 (0.019612)
feature 134 (0.019166)
feature 53 (0.018848)
feature 159 (0.017227)
feature 129 (0.016914)
feature 56 (0.016072)
feature 135 (0.015217)
feature 362 (0.014353)
feature 223 (0.013779)
feature 171 (0.013683)
feature 101 (0.013575)
feature 146 (0.013096)
feature 215 (0.012911)
feature 152 (0.012731)
feature 442 (0.012252)
feature 30 (0.012197)
feature 172 (0.012118)
feature 46 (0.012055)
feature 28 (0.012040)
feature 78 (0.011954)
feature 81 (0.011287)
feature 4 (0.010744)
feature 97 (0.010569)
feature 202 (0.010541)
inner fold=3
accuracy=0.644444444444
feature 172 (0.032675)
feature 12 (0.028562)
feature 381 (0.026875)
feature 126 (0.020433)
feature 156 (0.020105)
feature 168 (0.018160)
feature 210 (0.017415)
feature 362 (0.017234)
feature 107 (0.016107)
feature 158 (0.015858)
feature 231 (0.015462)
feature 155 (0.015190)
feature 151 (0.014777)
feature 40 (0.014588)
feature 53 (0.014154)
feature 235 (0.013870)
feature 109 (0.012510)
feature 135 (0.012379)
feature 294 (0.011812)
feature 106 (0.011647)
feature 166 (0.011631)
feature 17 (0.011116)
feature 301 (0.011060)
feature 207 (0.010910)
feature 78 (0.010753)
feature 102 (0.010489)
feature 134 (0.010054)
feature 69 (0.010048)
feature 130 (0.010036)
feature 4 (0.009835)
inner fold=4
accuracy=0.644444444444

lay_id=6
feature 153 (0.027695)
feature 107 (0.025163)
feature 157 (0.023002)
feature 175 (0.020953)
feature 123 (0.019425)
feature 207 (0.018802)
feature 44 (0.018499)
feature 102 (0.017532)
feature 122 (0.017393)
feature 200 (0.017363)
feature 4 (0.016679)
feature 203 (0.016258)
feature 77 (0.015915)
feature 84 (0.015733)
feature 168 (0.015576)
feature 211 (0.015092)
feature 173 (0.015030)
feature 62 (0.014974)
feature 199 (0.014765)
feature 81 (0.014665)
feature 5 (0.013372)
feature 129 (0.013351)
feature 104 (0.013182)
feature 8 (0.012951)
feature 165 (0.012408)
feature 21 (0.012208)
feature 464 (0.011580)
feature 52 (0.010802)
feature 147 (0.010669)
feature 216 (0.010482)
inner fold=0
accuracy=0.630434782609
feature 148 (0.036383)
feature 142 (0.024082)
feature 294 (0.023962)
feature 203 (0.021451)
feature 43 (0.019950)
feature 166 (0.019565)
feature 0 (0.017374)
feature 164 (0.016738)
feature 215 (0.015382)
feature 4 (0.014940)
feature 153 (0.014716)
feature 114 (0.014497)
feature 71 (0.013621)
feature 16 (0.013272)
feature 42 (0.013086)
feature 58 (0.013075)
feature 160 (0.012428)
feature 155 (0.012239)
feature 105 (0.012230)
feature 81 (0.012168)
feature 159 (0.011728)
feature 171 (0.011600)
feature 188 (0.011452)
feature 168 (0.011285)
feature 52 (0.010762)
feature 385 (0.010693)
feature 383 (0.010640)
feature 130 (0.010151)
feature 172 (0.009857)
feature 381 (0.009825)
inner fold=1
accuracy=0.565217391304
feature 157 (0.031227)
feature 129 (0.025722)
feature 203 (0.025165)
feature 385 (0.024307)
feature 4 (0.024206)
feature 151 (0.021615)
feature 115 (0.018222)
feature 201 (0.017093)
feature 294 (0.016876)
feature 172 (0.016585)
feature 1 (0.015903)
feature 141 (0.015054)
feature 79 (0.014656)
feature 99 (0.014219)
feature 171 (0.014077)
feature 81 (0.014049)
feature 164 (0.013480)
feature 175 (0.013479)
feature 184 (0.012408)
feature 153 (0.012033)
feature 199 (0.011835)
feature 120 (0.011790)
feature 55 (0.011367)
feature 46 (0.011165)
feature 126 (0.011161)
feature 136 (0.011083)
feature 0 (0.010946)
feature 130 (0.010849)
feature 155 (0.010725)
feature 128 (0.010654)
inner fold=2
accuracy=0.666666666667
feature 172 (0.026160)
feature 148 (0.025036)
feature 81 (0.023969)
feature 84 (0.023566)
feature 193 (0.021668)
feature 110 (0.019080)
feature 208 (0.018177)
feature 129 (0.016031)
feature 34 (0.015935)
feature 24 (0.015824)
feature 209 (0.015797)
feature 165 (0.014696)
feature 99 (0.013999)
feature 213 (0.013888)
feature 158 (0.013857)
feature 46 (0.013614)
feature 106 (0.013588)
feature 166 (0.013586)
feature 77 (0.012239)
feature 136 (0.011760)
feature 390 (0.011532)
feature 275 (0.010843)
feature 203 (0.010717)
feature 173 (0.010320)
feature 53 (0.010173)
feature 294 (0.010106)
feature 383 (0.010085)
feature 222 (0.009760)
feature 30 (0.009750)
feature 420 (0.009731)
inner fold=3
accuracy=0.555555555556
feature 152 (0.026468)
feature 153 (0.025257)
feature 44 (0.024167)
feature 223 (0.023890)
feature 211 (0.023379)
feature 208 (0.022610)
feature 129 (0.021893)
feature 114 (0.020224)
feature 145 (0.019564)
feature 55 (0.017898)
feature 122 (0.016527)
feature 46 (0.016316)
feature 48 (0.014338)
feature 27 (0.014254)
feature 33 (0.014055)
feature 156 (0.013552)
feature 209 (0.012603)
feature 131 (0.012428)
feature 58 (0.012265)
feature 381 (0.012195)
feature 203 (0.011073)
feature 181 (0.011014)
feature 227 (0.010965)
feature 130 (0.010578)
feature 110 (0.010399)
feature 78 (0.010089)
feature 106 (0.010078)
feature 139 (0.009273)
feature 69 (0.009215)
feature 172 (0.009079)
inner fold=4
accuracy=0.577777777778
feature 136 (0.031236)
feature 123 (0.028907)
feature 155 (0.028137)
feature 294 (0.026245)
feature 110 (0.026124)
feature 156 (0.025230)
feature 46 (0.022589)
feature 222 (0.019739)
feature 34 (0.019474)
feature 142 (0.018757)
feature 125 (0.015607)
feature 128 (0.015485)
feature 203 (0.014916)
feature 153 (0.014473)
feature 14 (0.014363)
feature 126 (0.014335)
feature 38 (0.014106)
feature 138 (0.013924)
feature 78 (0.013720)
feature 381 (0.013672)
feature 231 (0.012388)
feature 109 (0.011925)
feature 340 (0.011124)
feature 51 (0.011049)
feature 200 (0.010739)
feature 157 (0.010292)
feature 120 (0.010273)
feature 166 (0.010116)
feature 148 (0.009624)
feature 52 (0.009444)
inner fold=0
accuracy=0.5
feature 171 (0.031844)
feature 40 (0.024207)
feature 165 (0.021947)
feature 156 (0.021458)
feature 79 (0.021218)
feature 153 (0.021100)
feature 102 (0.020845)
feature 158 (0.020841)
feature 131 (0.019144)
feature 101 (0.019087)
feature 215 (0.018523)
feature 52 (0.018014)
feature 137 (0.017997)
feature 199 (0.015779)
feature 294 (0.013508)
feature 148 (0.013109)
feature 122 (0.013056)
feature 129 (0.011537)
feature 4 (0.011494)
feature 57 (0.011397)
feature 202 (0.011223)
feature 18 (0.011213)
feature 174 (0.011111)
feature 139 (0.011054)
feature 84 (0.011001)
feature 140 (0.010712)
feature 80 (0.010694)
feature 81 (0.010365)
feature 0 (0.010338)
feature 97 (0.010290)
inner fold=1
accuracy=0.608695652174
feature 172 (0.027164)
feature 294 (0.024735)
feature 106 (0.023063)
feature 199 (0.022897)
feature 14 (0.020332)
feature 143 (0.019523)
feature 208 (0.019290)
feature 101 (0.019258)
feature 107 (0.018455)
feature 138 (0.017974)
feature 5 (0.017782)
feature 222 (0.017316)
feature 58 (0.016906)
feature 209 (0.015421)
feature 129 (0.014976)
feature 82 (0.014021)
feature 181 (0.013903)
feature 135 (0.013762)
feature 165 (0.013711)
feature 156 (0.013669)
feature 64 (0.013634)
feature 110 (0.012859)
feature 159 (0.012250)
feature 78 (0.011444)
feature 38 (0.011392)
feature 24 (0.010832)
feature 175 (0.010773)
feature 109 (0.010602)
feature 283 (0.010569)
feature 123 (0.010475)
inner fold=2
accuracy=0.6
feature 44 (0.040423)
feature 153 (0.028411)
feature 166 (0.027122)
feature 381 (0.024758)
feature 171 (0.021498)
feature 79 (0.019883)
feature 216 (0.018365)
feature 0 (0.017223)
feature 155 (0.015999)
feature 159 (0.015646)
feature 156 (0.015446)
feature 82 (0.014782)
feature 52 (0.014459)
feature 33 (0.013902)
feature 222 (0.013584)
feature 147 (0.013206)
feature 109 (0.013146)
feature 107 (0.012796)
feature 160 (0.012765)
feature 227 (0.012486)
feature 148 (0.012316)
feature 193 (0.012283)
feature 152 (0.012127)
feature 157 (0.012058)
feature 81 (0.011656)
feature 101 (0.010955)
feature 158 (0.010938)
feature 45 (0.010081)
feature 294 (0.009969)
feature 102 (0.009887)
inner fold=3
accuracy=0.644444444444
feature 136 (0.032034)
feature 123 (0.026050)
feature 24 (0.025701)
feature 344 (0.020609)
feature 40 (0.017823)
feature 171 (0.016004)
feature 17 (0.015519)
feature 127 (0.014668)
feature 385 (0.014003)
feature 202 (0.013523)
feature 181 (0.013506)
feature 235 (0.013486)
feature 464 (0.013384)
feature 141 (0.013238)
feature 13 (0.012884)
feature 139 (0.012847)
feature 77 (0.012305)
feature 45 (0.012250)
feature 156 (0.012210)
feature 97 (0.012036)
feature 213 (0.011421)
feature 169 (0.011393)
feature 148 (0.011389)
feature 362 (0.011179)
feature 0 (0.010982)
feature 55 (0.010956)
feature 130 (0.010753)
feature 165 (0.010704)
feature 128 (0.010069)
feature 30 (0.010029)
inner fold=4
accuracy=0.488888888889

outer fold 2
lay_id=0
feature 196 (0.028442)
feature 438 (0.020990)
feature 51 (0.018256)
feature 143 (0.017527)
feature 340 (0.017332)
feature 123 (0.016339)
feature 49 (0.016291)
feature 162 (0.015965)
feature 178 (0.015362)
feature 160 (0.015176)
feature 78 (0.014755)
feature 290 (0.014149)
feature 164 (0.013664)
feature 39 (0.013586)
feature 29 (0.013424)
feature 133 (0.013143)
feature 106 (0.013141)
feature 125 (0.012895)
feature 81 (0.011679)
feature 154 (0.011549)
feature 197 (0.011479)
feature 116 (0.011201)
feature 161 (0.011147)
feature 122 (0.010927)
feature 379 (0.010823)
feature 210 (0.010393)
feature 34 (0.010333)
feature 95 (0.010245)
feature 199 (0.010223)
feature 135 (0.010209)
inner fold=0
accuracy=0.521739130435
feature 144 (0.030863)
feature 132 (0.027426)
feature 51 (0.025249)
feature 97 (0.024868)
feature 162 (0.020563)
feature 98 (0.019819)
feature 141 (0.018501)
feature 20 (0.017755)
feature 78 (0.017574)
feature 197 (0.017208)
feature 209 (0.016501)
feature 167 (0.016302)
feature 121 (0.016275)
feature 220 (0.015815)
feature 129 (0.015035)
feature 178 (0.014461)
feature 140 (0.014309)
feature 100 (0.013342)
feature 134 (0.012803)
feature 25 (0.012664)
feature 68 (0.012338)
feature 95 (0.012183)
feature 168 (0.012059)
feature 118 (0.012036)
feature 154 (0.011824)
feature 135 (0.010935)
feature 198 (0.010888)
feature 450 (0.010604)
feature 106 (0.010350)
feature 149 (0.010306)
inner fold=1
accuracy=0.54347826087
feature 76 (0.035424)
feature 106 (0.026455)
feature 290 (0.024903)
feature 51 (0.021934)
feature 40 (0.019935)
feature 75 (0.019365)
feature 281 (0.017236)
feature 74 (0.017131)
feature 54 (0.016921)
feature 210 (0.015437)
feature 148 (0.015104)
feature 69 (0.014907)
feature 153 (0.014421)
feature 30 (0.014090)
feature 18 (0.013965)
feature 102 (0.013868)
feature 149 (0.013744)
feature 134 (0.013409)
feature 79 (0.013409)
feature 122 (0.013396)
feature 131 (0.012771)
feature 46 (0.012509)
feature 377 (0.012135)
feature 385 (0.011982)
feature 125 (0.011826)
feature 167 (0.011746)
feature 227 (0.011474)
feature 340 (0.011399)
feature 172 (0.011201)
feature 162 (0.010982)
inner fold=2
accuracy=0.644444444444
feature 10 (0.029986)
feature 53 (0.029291)
feature 180 (0.023559)
feature 25 (0.021846)
feature 51 (0.019296)
feature 377 (0.018788)
feature 336 (0.016806)
feature 50 (0.016525)
feature 168 (0.016388)
feature 167 (0.016309)
feature 42 (0.016066)
feature 105 (0.014423)
feature 152 (0.014410)
feature 439 (0.013368)
feature 197 (0.013111)
feature 121 (0.012883)
feature 354 (0.012451)
feature 73 (0.012348)
feature 41 (0.012235)
feature 205 (0.011917)
feature 126 (0.011401)
feature 52 (0.011363)
feature 78 (0.011288)
feature 31 (0.011188)
feature 75 (0.010969)
feature 26 (0.010918)
feature 148 (0.010889)
feature 48 (0.010835)
feature 49 (0.010714)
feature 59 (0.010639)
inner fold=3
accuracy=0.533333333333
feature 1 (0.029646)
feature 204 (0.028410)
feature 290 (0.022757)
feature 209 (0.019230)
feature 161 (0.018847)
feature 169 (0.017970)
feature 49 (0.017361)
feature 199 (0.016977)
feature 42 (0.015974)
feature 119 (0.015217)
feature 103 (0.014011)
feature 231 (0.013715)
feature 122 (0.013350)
feature 149 (0.013061)
feature 0 (0.012801)
feature 34 (0.012679)
feature 116 (0.011814)
feature 196 (0.011734)
feature 157 (0.011660)
feature 184 (0.011524)
feature 86 (0.011467)
feature 141 (0.011437)
feature 104 (0.011315)
feature 134 (0.010989)
feature 52 (0.010600)
feature 131 (0.010422)
feature 450 (0.010384)
feature 168 (0.010144)
feature 219 (0.009823)
feature 69 (0.009611)
inner fold=4
accuracy=0.533333333333
feature 164 (0.024227)
feature 153 (0.021438)
feature 77 (0.020083)
feature 340 (0.019401)
feature 125 (0.018979)
feature 141 (0.018649)
feature 75 (0.017942)
feature 196 (0.017187)
feature 169 (0.016738)
feature 198 (0.015857)
feature 290 (0.015708)
feature 218 (0.015523)
feature 170 (0.015462)
feature 119 (0.015261)
feature 57 (0.015211)
feature 129 (0.014854)
feature 155 (0.014568)
feature 162 (0.014248)
feature 73 (0.013704)
feature 74 (0.013159)
feature 227 (0.012957)
feature 10 (0.012464)
feature 132 (0.012431)
feature 126 (0.012235)
feature 127 (0.012091)
feature 161 (0.011852)
feature 8 (0.011717)
feature 34 (0.011660)
feature 38 (0.011491)
feature 122 (0.011212)
inner fold=0
accuracy=0.652173913043
feature 290 (0.046086)
feature 164 (0.036754)
feature 170 (0.026734)
feature 122 (0.026501)
feature 131 (0.023073)
feature 152 (0.022107)
feature 38 (0.021364)
feature 0 (0.018123)
feature 77 (0.017606)
feature 97 (0.016990)
feature 130 (0.016317)
feature 199 (0.015779)
feature 116 (0.015769)
feature 59 (0.015357)
feature 119 (0.015168)
feature 10 (0.014552)
feature 52 (0.014259)
feature 106 (0.014063)
feature 135 (0.013875)
feature 31 (0.013344)
feature 56 (0.013021)
feature 160 (0.012959)
feature 118 (0.012596)
feature 125 (0.012450)
feature 129 (0.012309)
feature 207 (0.012201)
feature 148 (0.012066)
feature 111 (0.011407)
feature 133 (0.011026)
feature 42 (0.010635)
inner fold=1
accuracy=0.478260869565
feature 162 (0.033603)
feature 77 (0.029674)
feature 290 (0.026064)
feature 48 (0.025116)
feature 125 (0.019800)
feature 167 (0.018478)
feature 93 (0.017837)
feature 164 (0.017149)
feature 106 (0.016712)
feature 105 (0.015915)
feature 42 (0.015776)
feature 168 (0.015748)
feature 47 (0.015372)
feature 153 (0.014643)
feature 51 (0.014395)
feature 227 (0.014336)
feature 271 (0.014270)
feature 197 (0.013644)
feature 116 (0.013453)
feature 161 (0.013053)
feature 124 (0.012831)
feature 34 (0.012629)
feature 180 (0.012104)
feature 10 (0.011954)
feature 78 (0.011887)
feature 12 (0.011584)
feature 165 (0.011238)
feature 26 (0.011171)
feature 73 (0.010593)
feature 126 (0.010500)
inner fold=2
accuracy=0.466666666667
feature 167 (0.026883)
feature 77 (0.023559)
feature 75 (0.021724)
feature 58 (0.021480)
feature 209 (0.020203)
feature 99 (0.020197)
feature 290 (0.019835)
feature 31 (0.019314)
feature 40 (0.017149)
feature 111 (0.015607)
feature 368 (0.015354)
feature 148 (0.014805)
feature 176 (0.014463)
feature 199 (0.013597)
feature 74 (0.013446)
feature 211 (0.013192)
feature 20 (0.013114)
feature 450 (0.012936)
feature 47 (0.012828)
feature 127 (0.012565)
feature 144 (0.012442)
feature 59 (0.012332)
feature 169 (0.011896)
feature 54 (0.011318)
feature 122 (0.011282)
feature 9 (0.010756)
feature 196 (0.010494)
feature 157 (0.010340)
feature 126 (0.010276)
feature 231 (0.010225)
inner fold=3
accuracy=0.644444444444
feature 223 (0.043961)
feature 154 (0.032918)
feature 75 (0.030515)
feature 40 (0.027244)
feature 42 (0.021509)
feature 170 (0.020131)
feature 130 (0.019960)
feature 162 (0.019230)
feature 106 (0.016731)
feature 48 (0.016650)
feature 126 (0.016374)
feature 203 (0.015631)
feature 227 (0.014300)
feature 152 (0.014160)
feature 155 (0.014116)
feature 131 (0.013500)
feature 209 (0.012823)
feature 167 (0.011739)
feature 74 (0.011715)
feature 53 (0.011571)
feature 76 (0.010946)
feature 46 (0.010620)
feature 31 (0.010548)
feature 160 (0.010536)
feature 407 (0.010418)
feature 156 (0.010283)
feature 197 (0.010219)
feature 38 (0.009816)
feature 144 (0.009633)
feature 10 (0.009601)
inner fold=4
accuracy=0.6

lay_id=1
feature 81 (0.027112)
feature 172 (0.022319)
feature 344 (0.020978)
feature 209 (0.020901)
feature 171 (0.019970)
feature 235 (0.019538)
feature 54 (0.019521)
feature 129 (0.019366)
feature 165 (0.019131)
feature 294 (0.018597)
feature 122 (0.017950)
feature 161 (0.017949)
feature 73 (0.017649)
feature 166 (0.016911)
feature 50 (0.016555)
feature 135 (0.015397)
feature 4 (0.015170)
feature 34 (0.014231)
feature 58 (0.013526)
feature 181 (0.013364)
feature 102 (0.013312)
feature 211 (0.012750)
feature 44 (0.012624)
feature 79 (0.012548)
feature 213 (0.012355)
feature 138 (0.012112)
feature 148 (0.012090)
feature 231 (0.011516)
feature 63 (0.011281)
feature 42 (0.011219)
inner fold=0
accuracy=0.45652173913
feature 166 (0.035580)
feature 115 (0.028104)
feature 105 (0.019047)
feature 175 (0.018836)
feature 52 (0.018260)
feature 390 (0.017782)
feature 137 (0.017149)
feature 168 (0.016512)
feature 165 (0.016112)
feature 223 (0.015983)
feature 208 (0.015521)
feature 145 (0.015469)
feature 110 (0.014854)
feature 46 (0.014581)
feature 202 (0.014265)
feature 60 (0.014245)
feature 39 (0.014204)
feature 102 (0.013099)
feature 40 (0.013098)
feature 63 (0.013092)
feature 174 (0.012735)
feature 99 (0.011979)
feature 83 (0.011945)
feature 109 (0.011784)
feature 0 (0.011565)
feature 34 (0.011099)
feature 183 (0.010915)
feature 78 (0.010866)
feature 125 (0.010311)
feature 344 (0.010265)
inner fold=1
accuracy=0.586956521739
feature 227 (0.032671)
feature 203 (0.031259)
feature 172 (0.030366)
feature 173 (0.022596)
feature 126 (0.020839)
feature 188 (0.017073)
feature 193 (0.016666)
feature 52 (0.016637)
feature 294 (0.016290)
feature 4 (0.015822)
feature 185 (0.015555)
feature 110 (0.015278)
feature 199 (0.015069)
feature 101 (0.014403)
feature 44 (0.014262)
feature 143 (0.014149)
feature 175 (0.014010)
feature 184 (0.013857)
feature 211 (0.013614)
feature 163 (0.012522)
feature 129 (0.012259)
feature 18 (0.012247)
feature 50 (0.012115)
feature 383 (0.012051)
feature 285 (0.011967)
feature 168 (0.011852)
feature 134 (0.011519)
feature 152 (0.011385)
feature 142 (0.011303)
feature 33 (0.011054)
inner fold=2
accuracy=0.511111111111
feature 174 (0.027983)
feature 138 (0.026733)
feature 227 (0.020487)
feature 215 (0.020125)
feature 173 (0.019227)
feature 134 (0.018816)
feature 381 (0.017914)
feature 209 (0.017782)
feature 35 (0.017743)
feature 152 (0.016861)
feature 78 (0.016677)
feature 54 (0.015605)
feature 102 (0.015598)
feature 151 (0.015095)
feature 123 (0.014761)
feature 294 (0.014621)
feature 175 (0.014603)
feature 231 (0.014123)
feature 44 (0.012810)
feature 57 (0.012598)
feature 137 (0.012286)
feature 34 (0.011999)
feature 148 (0.011465)
feature 48 (0.010835)
feature 164 (0.010743)
feature 184 (0.010548)
feature 82 (0.010545)
feature 131 (0.010174)
feature 58 (0.010142)
feature 153 (0.010138)
inner fold=3
accuracy=0.555555555556
feature 294 (0.056008)
feature 231 (0.031934)
feature 173 (0.031387)
feature 55 (0.022617)
feature 411 (0.022337)
feature 151 (0.018239)
feature 152 (0.016567)
feature 168 (0.015864)
feature 12 (0.015784)
feature 362 (0.015022)
feature 115 (0.014812)
feature 201 (0.014634)
feature 175 (0.013971)
feature 122 (0.013741)
feature 203 (0.013173)
feature 172 (0.013087)
feature 272 (0.012883)
feature 213 (0.012763)
feature 16 (0.012678)
feature 156 (0.012667)
feature 185 (0.012446)
feature 80 (0.012156)
feature 30 (0.011871)
feature 171 (0.011619)
feature 193 (0.011524)
feature 14 (0.011391)
feature 209 (0.011291)
feature 134 (0.011242)
feature 158 (0.010776)
feature 50 (0.010765)
inner fold=4
accuracy=0.577777777778
feature 110 (0.022648)
feature 227 (0.022216)
feature 188 (0.020446)
feature 81 (0.020275)
feature 109 (0.019724)
feature 13 (0.018215)
feature 14 (0.016469)
feature 172 (0.016203)
feature 200 (0.016124)
feature 294 (0.015425)
feature 62 (0.014881)
feature 381 (0.013527)
feature 28 (0.013469)
feature 68 (0.013187)
feature 12 (0.013178)
feature 57 (0.012915)
feature 3 (0.012914)
feature 80 (0.012904)
feature 396 (0.012868)
feature 106 (0.012825)
feature 231 (0.012753)
feature 174 (0.012463)
feature 21 (0.012210)
feature 173 (0.012182)
feature 18 (0.011799)
feature 151 (0.011480)
feature 44 (0.011377)
feature 79 (0.011198)
feature 137 (0.010905)
feature 164 (0.010624)
inner fold=0
accuracy=0.608695652174
feature 155 (0.029238)
feature 110 (0.025964)
feature 125 (0.021916)
feature 159 (0.021910)
feature 78 (0.021565)
feature 70 (0.018760)
feature 53 (0.018449)
feature 139 (0.018388)
feature 201 (0.018198)
feature 172 (0.016854)
feature 101 (0.016054)
feature 390 (0.015830)
feature 102 (0.015548)
feature 138 (0.015401)
feature 5 (0.015169)
feature 174 (0.014840)
feature 30 (0.014238)
feature 21 (0.014117)
feature 17 (0.014071)
feature 34 (0.014058)
feature 103 (0.013998)
feature 152 (0.013297)
feature 385 (0.012959)
feature 142 (0.012383)
feature 84 (0.012020)
feature 223 (0.011983)
feature 184 (0.011739)
feature 104 (0.011704)
feature 173 (0.011683)
feature 383 (0.011591)
inner fold=1
accuracy=0.608695652174
feature 44 (0.029067)
feature 160 (0.024391)
feature 383 (0.019352)
feature 137 (0.018889)
feature 78 (0.018820)
feature 35 (0.018265)
feature 285 (0.018133)
feature 157 (0.017507)
feature 40 (0.017109)
feature 123 (0.016534)
feature 79 (0.016015)
feature 63 (0.015963)
feature 122 (0.015549)
feature 231 (0.014065)
feature 164 (0.013673)
feature 135 (0.013438)
feature 152 (0.013278)
feature 166 (0.013022)
feature 101 (0.012806)
feature 377 (0.012465)
feature 21 (0.012252)
feature 45 (0.012084)
feature 5 (0.011896)
feature 52 (0.011854)
feature 133 (0.011828)
feature 138 (0.011514)
feature 130 (0.011330)
feature 227 (0.011098)
feature 134 (0.011053)
feature 77 (0.011015)
inner fold=2
accuracy=0.577777777778
feature 81 (0.026035)
feature 80 (0.024056)
feature 12 (0.021095)
feature 294 (0.017816)
feature 227 (0.017184)
feature 55 (0.016943)
feature 79 (0.016378)
feature 30 (0.016275)
feature 213 (0.016049)
feature 200 (0.015929)
feature 164 (0.015139)
feature 166 (0.014911)
feature 139 (0.014461)
feature 123 (0.014281)
feature 209 (0.013825)
feature 101 (0.013740)
feature 136 (0.013116)
feature 181 (0.012685)
feature 34 (0.012564)
feature 156 (0.012333)
feature 114 (0.012179)
feature 71 (0.012173)
feature 78 (0.012165)
feature 135 (0.012103)
feature 60 (0.012100)
feature 110 (0.011806)
feature 199 (0.011474)
feature 172 (0.011339)
feature 137 (0.011331)
feature 235 (0.010932)
inner fold=3
accuracy=0.688888888889
feature 172 (0.023929)
feature 200 (0.023458)
feature 21 (0.021282)
feature 46 (0.019505)
feature 34 (0.019304)
feature 134 (0.018780)
feature 110 (0.017131)
feature 53 (0.017060)
feature 155 (0.015923)
feature 43 (0.014686)
feature 56 (0.014656)
feature 68 (0.014367)
feature 169 (0.014052)
feature 136 (0.013899)
feature 123 (0.013810)
feature 213 (0.013750)
feature 40 (0.013180)
feature 209 (0.012967)
feature 210 (0.012236)
feature 16 (0.011844)
feature 127 (0.011534)
feature 211 (0.011385)
feature 102 (0.011334)
feature 30 (0.011088)
feature 168 (0.010841)
feature 128 (0.010466)
feature 103 (0.010399)
feature 101 (0.010140)
feature 227 (0.009728)
feature 81 (0.009676)
inner fold=4
accuracy=0.644444444444

lay_id=2
feature 275 (0.034257)
feature 142 (0.024201)
feature 35 (0.021681)
feature 79 (0.019990)
feature 294 (0.019881)
feature 77 (0.019566)
feature 168 (0.017864)
feature 158 (0.017779)
feature 134 (0.016576)
feature 138 (0.016415)
feature 203 (0.014930)
feature 159 (0.014711)
feature 80 (0.014436)
feature 164 (0.013749)
feature 194 (0.013354)
feature 160 (0.013232)
feature 454 (0.013215)
feature 126 (0.012977)
feature 172 (0.012922)
feature 222 (0.011681)
feature 58 (0.011500)
feature 51 (0.011436)
feature 52 (0.011404)
feature 34 (0.011308)
feature 105 (0.011271)
feature 102 (0.010562)
feature 56 (0.010441)
feature 211 (0.010432)
feature 173 (0.010044)
feature 344 (0.009976)
inner fold=0
accuracy=0.608695652174
feature 171 (0.030855)
feature 81 (0.030544)
feature 138 (0.026935)
feature 199 (0.021549)
feature 97 (0.020511)
feature 55 (0.019939)
feature 152 (0.019693)
feature 84 (0.018439)
feature 131 (0.018057)
feature 166 (0.017837)
feature 294 (0.016060)
feature 208 (0.015884)
feature 110 (0.015522)
feature 194 (0.014764)
feature 159 (0.013396)
feature 155 (0.013362)
feature 185 (0.012924)
feature 29 (0.012756)
feature 173 (0.012717)
feature 26 (0.011898)
feature 0 (0.011635)
feature 129 (0.011631)
feature 156 (0.011597)
feature 134 (0.011553)
feature 120 (0.011008)
feature 141 (0.010829)
feature 223 (0.010797)
feature 136 (0.010513)
feature 142 (0.010192)
feature 123 (0.009989)
inner fold=1
accuracy=0.630434782609
feature 135 (0.027304)
feature 174 (0.025906)
feature 58 (0.025687)
feature 173 (0.021799)
feature 97 (0.021510)
feature 172 (0.020103)
feature 171 (0.017167)
feature 203 (0.016035)
feature 138 (0.015857)
feature 18 (0.015768)
feature 209 (0.015214)
feature 51 (0.015096)
feature 385 (0.013713)
feature 176 (0.013576)
feature 202 (0.013501)
feature 60 (0.012784)
feature 14 (0.012695)
feature 131 (0.012508)
feature 30 (0.012466)
feature 227 (0.012315)
feature 79 (0.012275)
feature 125 (0.012028)
feature 53 (0.012018)
feature 127 (0.011927)
feature 199 (0.011898)
feature 181 (0.011842)
feature 81 (0.011829)
feature 164 (0.011706)
feature 168 (0.011423)
feature 96 (0.011081)
inner fold=2
accuracy=0.555555555556
feature 46 (0.025074)
feature 138 (0.024180)
feature 44 (0.021895)
feature 120 (0.021858)
feature 29 (0.020655)
feature 166 (0.017833)
feature 152 (0.017114)
feature 125 (0.016120)
feature 57 (0.015429)
feature 199 (0.015272)
feature 139 (0.014964)
feature 77 (0.014961)
feature 210 (0.014665)
feature 131 (0.013293)
feature 47 (0.013150)
feature 78 (0.012788)
feature 122 (0.012775)
feature 169 (0.012500)
feature 99 (0.012239)
feature 101 (0.012130)
feature 123 (0.012045)
feature 145 (0.012043)
feature 130 (0.011957)
feature 2 (0.011932)
feature 4 (0.011907)
feature 81 (0.011839)
feature 213 (0.011512)
feature 82 (0.010638)
feature 136 (0.010535)
feature 165 (0.010420)
inner fold=3
accuracy=0.577777777778
feature 166 (0.026453)
feature 21 (0.023290)
feature 120 (0.021710)
feature 184 (0.021552)
feature 165 (0.020539)
feature 128 (0.020476)
feature 158 (0.019960)
feature 227 (0.019690)
feature 168 (0.019655)
feature 199 (0.018751)
feature 294 (0.015218)
feature 127 (0.014607)
feature 136 (0.014511)
feature 213 (0.014503)
feature 215 (0.014397)
feature 50 (0.014318)
feature 176 (0.014063)
feature 454 (0.013897)
feature 153 (0.013513)
feature 159 (0.013268)
feature 275 (0.013012)
feature 394 (0.012907)
feature 30 (0.012004)
feature 125 (0.011900)
feature 182 (0.011871)
feature 42 (0.011842)
feature 55 (0.011634)
feature 4 (0.011513)
feature 172 (0.011425)
feature 157 (0.011236)
inner fold=4
accuracy=0.555555555556
feature 97 (0.032073)
feature 294 (0.029034)
feature 148 (0.028670)
feature 100 (0.026787)
feature 52 (0.022326)
feature 211 (0.020204)
feature 12 (0.018653)
feature 156 (0.018239)
feature 203 (0.017550)
feature 71 (0.015960)
feature 210 (0.015528)
feature 135 (0.014879)
feature 133 (0.014843)
feature 385 (0.013950)
feature 174 (0.013885)
feature 139 (0.013656)
feature 46 (0.013280)
feature 129 (0.012624)
feature 454 (0.012126)
feature 58 (0.011541)
feature 200 (0.011199)
feature 275 (0.011065)
feature 235 (0.010839)
feature 53 (0.010413)
feature 138 (0.010388)
feature 105 (0.010305)
feature 24 (0.009906)
feature 223 (0.009894)
feature 412 (0.009667)
feature 79 (0.009618)
inner fold=0
accuracy=0.5
feature 110 (0.025057)
feature 126 (0.022035)
feature 53 (0.021029)
feature 171 (0.019391)
feature 151 (0.017844)
feature 454 (0.017828)
feature 46 (0.017480)
feature 123 (0.016336)
feature 210 (0.015027)
feature 211 (0.014715)
feature 208 (0.014521)
feature 385 (0.014008)
feature 412 (0.013909)
feature 84 (0.013763)
feature 141 (0.013114)
feature 155 (0.012808)
feature 136 (0.012648)
feature 43 (0.012090)
feature 120 (0.011832)
feature 28 (0.011766)
feature 184 (0.011687)
feature 464 (0.011248)
feature 156 (0.011223)
feature 209 (0.010957)
feature 381 (0.010870)
feature 142 (0.010735)
feature 34 (0.010692)
feature 199 (0.010582)
feature 161 (0.010550)
feature 30 (0.010264)
inner fold=1
accuracy=0.652173913043
feature 294 (0.025407)
feature 173 (0.025115)
feature 139 (0.024215)
feature 78 (0.023332)
feature 137 (0.021850)
feature 55 (0.021311)
feature 171 (0.020532)
feature 168 (0.018400)
feature 174 (0.018084)
feature 231 (0.016408)
feature 209 (0.014980)
feature 129 (0.014743)
feature 125 (0.014585)
feature 164 (0.014383)
feature 166 (0.013981)
feature 115 (0.013721)
feature 56 (0.013611)
feature 156 (0.012817)
feature 211 (0.012764)
feature 101 (0.012513)
feature 24 (0.012216)
feature 12 (0.012058)
feature 44 (0.011853)
feature 142 (0.011597)
feature 203 (0.011583)
feature 207 (0.010921)
feature 81 (0.010907)
feature 161 (0.010841)
feature 184 (0.010270)
feature 214 (0.010212)
inner fold=2
accuracy=0.644444444444
feature 153 (0.032417)
feature 55 (0.028618)
feature 137 (0.025356)
feature 123 (0.025069)
feature 44 (0.024949)
feature 173 (0.024809)
feature 110 (0.019207)
feature 136 (0.018961)
feature 80 (0.018910)
feature 109 (0.016923)
feature 29 (0.015352)
feature 213 (0.015232)
feature 172 (0.013659)
feature 70 (0.012897)
feature 301 (0.012502)
feature 442 (0.012404)
feature 77 (0.012208)
feature 159 (0.012131)
feature 201 (0.011846)
feature 106 (0.011768)
feature 53 (0.011691)
feature 207 (0.011628)
feature 169 (0.011473)
feature 285 (0.011374)
feature 175 (0.011103)
feature 97 (0.011076)
feature 12 (0.010962)
feature 160 (0.010833)
feature 165 (0.010709)
feature 187 (0.010671)
inner fold=3
accuracy=0.511111111111
feature 52 (0.030434)
feature 110 (0.026368)
feature 129 (0.022561)
feature 60 (0.021613)
feature 171 (0.020782)
feature 156 (0.020595)
feature 135 (0.020229)
feature 231 (0.018642)
feature 201 (0.017912)
feature 81 (0.016594)
feature 148 (0.014959)
feature 77 (0.014543)
feature 235 (0.014368)
feature 97 (0.014041)
feature 136 (0.013934)
feature 210 (0.012943)
feature 120 (0.012053)
feature 208 (0.011941)
feature 22 (0.011873)
feature 227 (0.011540)
feature 106 (0.011446)
feature 143 (0.011312)
feature 69 (0.011133)
feature 56 (0.011069)
feature 183 (0.010675)
feature 103 (0.010427)
feature 142 (0.010092)
feature 159 (0.009857)
feature 188 (0.009758)
feature 155 (0.009678)
inner fold=4
accuracy=0.577777777778

lay_id=3
feature 166 (0.029606)
feature 136 (0.020541)
feature 1 (0.020422)
feature 130 (0.018927)
feature 235 (0.016997)
feature 161 (0.016490)
feature 285 (0.016191)
feature 138 (0.015255)
feature 207 (0.014935)
feature 294 (0.014752)
feature 107 (0.013886)
feature 82 (0.013520)
feature 43 (0.013075)
feature 83 (0.012883)
feature 172 (0.012439)
feature 155 (0.012320)
feature 80 (0.012206)
feature 78 (0.012196)
feature 15 (0.012111)
feature 70 (0.011743)
feature 184 (0.011621)
feature 454 (0.010980)
feature 97 (0.010217)
feature 213 (0.010176)
feature 234 (0.010120)
feature 168 (0.010092)
feature 125 (0.010081)
feature 85 (0.010074)
feature 38 (0.010039)
feature 157 (0.009863)
inner fold=0
accuracy=0.695652173913
feature 156 (0.035137)
feature 43 (0.025380)
feature 81 (0.023103)
feature 158 (0.020830)
feature 30 (0.017430)
feature 52 (0.016820)
feature 97 (0.016393)
feature 129 (0.015745)
feature 238 (0.015446)
feature 55 (0.014997)
feature 159 (0.014924)
feature 78 (0.014819)
feature 166 (0.014388)
feature 71 (0.014224)
feature 208 (0.014134)
feature 235 (0.014042)
feature 102 (0.013716)
feature 171 (0.013675)
feature 114 (0.013381)
feature 130 (0.013349)
feature 122 (0.012863)
feature 63 (0.012479)
feature 138 (0.012336)
feature 196 (0.012295)
feature 199 (0.012249)
feature 38 (0.011664)
feature 294 (0.011370)
feature 131 (0.011248)
feature 35 (0.010810)
feature 115 (0.010693)
inner fold=1
accuracy=0.586956521739
feature 166 (0.047474)
feature 215 (0.043471)
feature 159 (0.027768)
feature 362 (0.025644)
feature 62 (0.020011)
feature 171 (0.019130)
feature 5 (0.016908)
feature 56 (0.015970)
feature 128 (0.015621)
feature 170 (0.015577)
feature 81 (0.015339)
feature 214 (0.015181)
feature 172 (0.014800)
feature 125 (0.014760)
feature 58 (0.014215)
feature 19 (0.014145)
feature 131 (0.013002)
feature 203 (0.012491)
feature 38 (0.012489)
feature 294 (0.012328)
feature 14 (0.012222)
feature 102 (0.012062)
feature 227 (0.011761)
feature 285 (0.011689)
feature 211 (0.011451)
feature 153 (0.011234)
feature 44 (0.011157)
feature 344 (0.010676)
feature 173 (0.010517)
feature 165 (0.010321)
inner fold=2
accuracy=0.644444444444
feature 171 (0.035730)
feature 110 (0.029823)
feature 156 (0.025125)
feature 84 (0.023883)
feature 166 (0.023811)
feature 134 (0.021155)
feature 101 (0.019927)
feature 168 (0.018785)
feature 148 (0.015122)
feature 188 (0.013731)
feature 210 (0.013624)
feature 33 (0.013490)
feature 344 (0.013467)
feature 412 (0.012611)
feature 211 (0.012354)
feature 144 (0.012230)
feature 158 (0.011893)
feature 52 (0.011254)
feature 114 (0.011145)
feature 125 (0.010940)
feature 42 (0.010890)
feature 8 (0.010719)
feature 126 (0.010527)
feature 129 (0.010360)
feature 173 (0.010251)
feature 131 (0.009897)
feature 194 (0.009846)
feature 235 (0.009416)
feature 130 (0.009383)
feature 51 (0.009182)
inner fold=3
accuracy=0.533333333333
feature 134 (0.028295)
feature 172 (0.027702)
feature 54 (0.022702)
feature 110 (0.020105)
feature 24 (0.019447)
feature 131 (0.019306)
feature 79 (0.018227)
feature 51 (0.016937)
feature 158 (0.015545)
feature 231 (0.015156)
feature 294 (0.014881)
feature 46 (0.014830)
feature 159 (0.014808)
feature 227 (0.013970)
feature 99 (0.013548)
feature 213 (0.013216)
feature 157 (0.013043)
feature 155 (0.012994)
feature 223 (0.012530)
feature 102 (0.012220)
feature 137 (0.012170)
feature 183 (0.011522)
feature 78 (0.011231)
feature 362 (0.011060)
feature 40 (0.011004)
feature 41 (0.010987)
feature 215 (0.010858)
feature 164 (0.010800)
feature 166 (0.010793)
feature 142 (0.010675)
inner fold=4
accuracy=0.622222222222
feature 336 (0.036464)
feature 56 (0.023636)
feature 136 (0.023307)
feature 131 (0.019852)
feature 8 (0.019789)
feature 128 (0.019497)
feature 109 (0.018642)
feature 153 (0.018457)
feature 138 (0.018106)
feature 125 (0.017967)
feature 294 (0.017213)
feature 127 (0.016512)
feature 84 (0.016492)
feature 85 (0.015852)
feature 163 (0.015799)
feature 174 (0.015652)
feature 155 (0.015455)
feature 101 (0.014865)
feature 77 (0.014219)
feature 110 (0.014066)
feature 62 (0.013503)
feature 140 (0.013279)
feature 29 (0.012515)
feature 54 (0.012489)
feature 12 (0.011919)
feature 81 (0.011795)
feature 231 (0.011370)
feature 1 (0.011074)
feature 142 (0.010982)
feature 105 (0.010967)
inner fold=0
accuracy=0.54347826087
feature 110 (0.028172)
feature 156 (0.024953)
feature 294 (0.024872)
feature 12 (0.024094)
feature 172 (0.021465)
feature 152 (0.020189)
feature 78 (0.019539)
feature 161 (0.019186)
feature 46 (0.019147)
feature 82 (0.017620)
feature 139 (0.016600)
feature 5 (0.016355)
feature 210 (0.016183)
feature 24 (0.015907)
feature 101 (0.015689)
feature 199 (0.015550)
feature 182 (0.015270)
feature 166 (0.015106)
feature 125 (0.015046)
feature 344 (0.014446)
feature 449 (0.014380)
feature 385 (0.014235)
feature 105 (0.013523)
feature 158 (0.013258)
feature 184 (0.012900)
feature 136 (0.012307)
feature 135 (0.012271)
feature 51 (0.012101)
feature 362 (0.011948)
feature 201 (0.010807)
inner fold=1
accuracy=0.673913043478
feature 142 (0.047239)
feature 115 (0.021211)
feature 175 (0.018718)
feature 107 (0.018554)
feature 164 (0.016660)
feature 101 (0.016228)
feature 46 (0.015805)
feature 18 (0.015705)
feature 152 (0.015618)
feature 84 (0.015337)
feature 79 (0.015048)
feature 120 (0.014538)
feature 110 (0.013923)
feature 139 (0.013773)
feature 157 (0.013720)
feature 54 (0.013504)
feature 4 (0.013216)
feature 44 (0.013107)
feature 160 (0.012536)
feature 303 (0.012389)
feature 180 (0.012281)
feature 172 (0.012244)
feature 14 (0.012045)
feature 203 (0.011925)
feature 188 (0.011567)
feature 275 (0.011496)
feature 55 (0.011119)
feature 173 (0.010738)
feature 35 (0.010263)
feature 128 (0.010101)
inner fold=2
accuracy=0.733333333333
feature 172 (0.037209)
feature 81 (0.035659)
feature 4 (0.028989)
feature 50 (0.025439)
feature 44 (0.025118)
feature 175 (0.022970)
feature 164 (0.022499)
feature 53 (0.021934)
feature 101 (0.021602)
feature 110 (0.019381)
feature 294 (0.015476)
feature 143 (0.015341)
feature 188 (0.014326)
feature 272 (0.014033)
feature 168 (0.013472)
feature 14 (0.013451)
feature 161 (0.013252)
feature 33 (0.012648)
feature 28 (0.012401)
feature 46 (0.012284)
feature 52 (0.011778)
feature 135 (0.011658)
feature 3 (0.011624)
feature 142 (0.011260)
feature 137 (0.011213)
feature 29 (0.010278)
feature 55 (0.010267)
feature 114 (0.010231)
feature 149 (0.010200)
feature 156 (0.009922)
inner fold=3
accuracy=0.644444444444
feature 227 (0.044648)
feature 158 (0.026638)
feature 55 (0.019567)
feature 136 (0.018400)
feature 77 (0.018108)
feature 53 (0.018085)
feature 44 (0.018077)
feature 101 (0.017527)
feature 38 (0.017244)
feature 0 (0.016650)
feature 138 (0.016230)
feature 81 (0.016129)
feature 171 (0.015991)
feature 161 (0.014313)
feature 48 (0.013560)
feature 142 (0.013505)
feature 36 (0.013228)
feature 202 (0.012148)
feature 21 (0.011851)
feature 134 (0.011770)
feature 157 (0.011748)
feature 208 (0.011267)
feature 174 (0.010519)
feature 110 (0.010506)
feature 140 (0.010453)
feature 13 (0.010370)
feature 52 (0.010328)
feature 12 (0.010197)
feature 199 (0.010079)
feature 30 (0.009965)
inner fold=4
accuracy=0.555555555556

lay_id=4
feature 109 (0.028320)
feature 4 (0.024435)
feature 294 (0.024320)
feature 120 (0.021195)
feature 78 (0.020223)
feature 152 (0.020144)
feature 81 (0.019432)
feature 123 (0.017854)
feature 57 (0.017750)
feature 107 (0.016926)
feature 44 (0.014917)
feature 159 (0.014728)
feature 211 (0.014288)
feature 53 (0.013930)
feature 151 (0.013821)
feature 171 (0.013571)
feature 301 (0.013333)
feature 52 (0.013262)
feature 222 (0.013244)
feature 55 (0.013140)
feature 114 (0.012947)
feature 127 (0.012572)
feature 199 (0.012433)
feature 166 (0.012299)
feature 85 (0.012181)
feature 33 (0.011484)
feature 72 (0.011362)
feature 122 (0.011255)
feature 163 (0.011237)
feature 383 (0.010902)
inner fold=0
accuracy=0.652173913043
feature 294 (0.029962)
feature 110 (0.022943)
feature 123 (0.019628)
feature 168 (0.019572)
feature 57 (0.017491)
feature 174 (0.017041)
feature 148 (0.016494)
feature 80 (0.016259)
feature 180 (0.016255)
feature 114 (0.016033)
feature 81 (0.015852)
feature 79 (0.015140)
feature 101 (0.014975)
feature 84 (0.014922)
feature 203 (0.014537)
feature 50 (0.014068)
feature 36 (0.013424)
feature 126 (0.012976)
feature 42 (0.012807)
feature 14 (0.012442)
feature 208 (0.012345)
feature 106 (0.012310)
feature 134 (0.012089)
feature 171 (0.012010)
feature 412 (0.011753)
feature 4 (0.011177)
feature 194 (0.010999)
feature 159 (0.010909)
feature 153 (0.010831)
feature 62 (0.010607)
inner fold=1
accuracy=0.630434782609
feature 107 (0.025967)
feature 201 (0.025715)
feature 42 (0.023744)
feature 172 (0.020477)
feature 344 (0.019514)
feature 12 (0.018755)
feature 62 (0.018566)
feature 104 (0.016981)
feature 102 (0.015822)
feature 285 (0.015696)
feature 110 (0.014323)
feature 82 (0.014170)
feature 33 (0.014128)
feature 383 (0.013573)
feature 156 (0.013334)
feature 227 (0.013112)
feature 122 (0.012903)
feature 294 (0.012613)
feature 137 (0.012519)
feature 18 (0.012464)
feature 158 (0.011980)
feature 165 (0.011350)
feature 5 (0.011116)
feature 129 (0.011001)
feature 135 (0.010907)
feature 43 (0.010890)
feature 184 (0.010591)
feature 222 (0.010114)
feature 175 (0.009456)
feature 3 (0.009420)
inner fold=2
accuracy=0.6
feature 120 (0.042249)
feature 44 (0.027056)
feature 168 (0.026305)
feature 1 (0.024028)
feature 134 (0.023688)
feature 167 (0.020382)
feature 214 (0.018040)
feature 38 (0.017953)
feature 203 (0.015255)
feature 142 (0.014920)
feature 141 (0.014553)
feature 126 (0.014447)
feature 222 (0.014363)
feature 125 (0.013800)
feature 24 (0.013158)
feature 158 (0.012962)
feature 294 (0.012734)
feature 82 (0.012620)
feature 211 (0.012566)
feature 385 (0.012007)
feature 78 (0.011599)
feature 123 (0.011548)
feature 181 (0.011346)
feature 154 (0.011195)
feature 199 (0.011134)
feature 51 (0.011110)
feature 183 (0.010776)
feature 231 (0.010767)
feature 169 (0.010620)
feature 102 (0.010403)
inner fold=3
accuracy=0.577777777778
feature 171 (0.032728)
feature 211 (0.024573)
feature 97 (0.021902)
feature 152 (0.019173)
feature 50 (0.018345)
feature 272 (0.018291)
feature 169 (0.017448)
feature 21 (0.016185)
feature 39 (0.016053)
feature 110 (0.015462)
feature 174 (0.015110)
feature 106 (0.014424)
feature 157 (0.014290)
feature 33 (0.013906)
feature 134 (0.013530)
feature 57 (0.013412)
feature 215 (0.012670)
feature 294 (0.012472)
feature 138 (0.012206)
feature 135 (0.012171)
feature 14 (0.011865)
feature 213 (0.011798)
feature 24 (0.011575)
feature 70 (0.011457)
feature 275 (0.011369)
feature 45 (0.011247)
feature 163 (0.010881)
feature 155 (0.010746)
feature 139 (0.010691)
feature 127 (0.010547)
inner fold=4
accuracy=0.666666666667
feature 166 (0.042963)
feature 203 (0.034102)
feature 171 (0.033111)
feature 14 (0.027663)
feature 275 (0.026667)
feature 63 (0.022154)
feature 109 (0.016889)
feature 52 (0.015913)
feature 122 (0.015619)
feature 175 (0.015254)
feature 213 (0.014997)
feature 161 (0.014118)
feature 0 (0.013875)
feature 214 (0.013525)
feature 107 (0.013083)
feature 196 (0.013019)
feature 30 (0.012511)
feature 454 (0.012494)
feature 129 (0.012419)
feature 43 (0.012271)
feature 173 (0.012224)
feature 157 (0.012132)
feature 71 (0.012065)
feature 128 (0.011753)
feature 285 (0.011679)
feature 134 (0.011676)
feature 211 (0.011545)
feature 137 (0.011151)
feature 51 (0.011004)
feature 131 (0.010849)
inner fold=0
accuracy=0.54347826087
feature 110 (0.031787)
feature 51 (0.024701)
feature 294 (0.023456)
feature 3 (0.021490)
feature 141 (0.020607)
feature 52 (0.020558)
feature 344 (0.019287)
feature 81 (0.018778)
feature 166 (0.018462)
feature 142 (0.017665)
feature 203 (0.016644)
feature 137 (0.015719)
feature 128 (0.014812)
feature 28 (0.014691)
feature 130 (0.014648)
feature 138 (0.014553)
feature 95 (0.014519)
feature 24 (0.014254)
feature 168 (0.014157)
feature 184 (0.013841)
feature 208 (0.012531)
feature 0 (0.012497)
feature 151 (0.012341)
feature 35 (0.012308)
feature 172 (0.012270)
feature 143 (0.012068)
feature 30 (0.011698)
feature 159 (0.011256)
feature 207 (0.011092)
feature 120 (0.010788)
inner fold=1
accuracy=0.673913043478
feature 166 (0.026633)
feature 134 (0.025644)
feature 39 (0.020845)
feature 172 (0.020558)
feature 43 (0.019608)
feature 125 (0.019407)
feature 129 (0.018859)
feature 156 (0.018019)
feature 214 (0.016250)
feature 294 (0.016088)
feature 34 (0.015999)
feature 115 (0.015871)
feature 158 (0.014781)
feature 18 (0.014124)
feature 202 (0.014005)
feature 168 (0.013710)
feature 42 (0.013475)
feature 126 (0.013464)
feature 12 (0.013426)
feature 364 (0.013095)
feature 60 (0.012912)
feature 136 (0.012902)
feature 55 (0.012587)
feature 142 (0.012385)
feature 155 (0.012180)
feature 143 (0.011634)
feature 285 (0.011192)
feature 344 (0.010860)
feature 260 (0.010830)
feature 153 (0.010231)
inner fold=2
accuracy=0.622222222222
feature 168 (0.039776)
feature 172 (0.036021)
feature 101 (0.029905)
feature 110 (0.024509)
feature 52 (0.022075)
feature 123 (0.020947)
feature 171 (0.020806)
feature 159 (0.019018)
feature 454 (0.017511)
feature 155 (0.016543)
feature 188 (0.015977)
feature 135 (0.015541)
feature 157 (0.014615)
feature 362 (0.014359)
feature 3 (0.014185)
feature 58 (0.013835)
feature 109 (0.013710)
feature 215 (0.013567)
feature 97 (0.012497)
feature 224 (0.011844)
feature 84 (0.011589)
feature 43 (0.010941)
feature 208 (0.010725)
feature 130 (0.010691)
feature 200 (0.010609)
feature 24 (0.010557)
feature 156 (0.010451)
feature 174 (0.010174)
feature 235 (0.010026)
feature 222 (0.009431)
inner fold=3
accuracy=0.644444444444
feature 157 (0.030344)
feature 227 (0.022007)
feature 70 (0.020617)
feature 184 (0.018672)
feature 213 (0.018375)
feature 168 (0.017718)
feature 130 (0.017285)
feature 46 (0.016568)
feature 211 (0.016414)
feature 43 (0.016187)
feature 135 (0.015687)
feature 155 (0.014947)
feature 166 (0.014568)
feature 161 (0.014447)
feature 81 (0.014095)
feature 34 (0.013805)
feature 202 (0.013747)
feature 62 (0.013685)
feature 275 (0.013468)
feature 207 (0.013323)
feature 344 (0.013252)
feature 181 (0.013055)
feature 464 (0.012856)
feature 47 (0.011852)
feature 109 (0.011661)
feature 45 (0.011201)
feature 80 (0.010989)
feature 122 (0.010529)
feature 79 (0.010502)
feature 199 (0.010462)
inner fold=4
accuracy=0.733333333333

lay_id=5
feature 80 (0.028377)
feature 227 (0.021354)
feature 171 (0.020912)
feature 153 (0.020257)
feature 44 (0.019678)
feature 110 (0.019358)
feature 136 (0.019306)
feature 24 (0.018598)
feature 46 (0.018118)
feature 83 (0.017300)
feature 167 (0.016904)
feature 152 (0.016411)
feature 120 (0.015736)
feature 127 (0.015463)
feature 81 (0.015347)
feature 29 (0.014667)
feature 235 (0.014099)
feature 107 (0.012404)
feature 126 (0.012290)
feature 231 (0.012281)
feature 148 (0.012101)
feature 2 (0.011976)
feature 0 (0.011357)
feature 164 (0.011286)
feature 82 (0.011269)
feature 165 (0.011260)
feature 42 (0.010838)
feature 294 (0.010480)
feature 18 (0.010294)
feature 344 (0.010114)
inner fold=0
accuracy=0.673913043478
feature 115 (0.030740)
feature 84 (0.030251)
feature 223 (0.025966)
feature 1 (0.024138)
feature 22 (0.022426)
feature 4 (0.021426)
feature 385 (0.020457)
feature 14 (0.018808)
feature 142 (0.018255)
feature 148 (0.015815)
feature 81 (0.014757)
feature 174 (0.014598)
feature 12 (0.014246)
feature 85 (0.013029)
feature 38 (0.013013)
feature 155 (0.012948)
feature 42 (0.012940)
feature 122 (0.012893)
feature 201 (0.012199)
feature 362 (0.012116)
feature 126 (0.011888)
feature 123 (0.011811)
feature 114 (0.011771)
feature 102 (0.011608)
feature 70 (0.011253)
feature 200 (0.011199)
feature 166 (0.010795)
feature 179 (0.010647)
feature 45 (0.010576)
feature 165 (0.010430)
inner fold=1
accuracy=0.608695652174
feature 110 (0.030486)
feature 158 (0.021833)
feature 77 (0.021082)
feature 97 (0.020993)
feature 173 (0.020817)
feature 151 (0.020267)
feature 344 (0.020264)
feature 78 (0.017516)
feature 62 (0.016473)
feature 134 (0.015861)
feature 46 (0.015684)
feature 157 (0.015367)
feature 129 (0.014993)
feature 227 (0.014233)
feature 165 (0.013863)
feature 383 (0.013809)
feature 390 (0.013719)
feature 285 (0.013307)
feature 142 (0.013247)
feature 161 (0.013020)
feature 139 (0.012919)
feature 14 (0.012292)
feature 60 (0.011832)
feature 101 (0.011388)
feature 222 (0.010961)
feature 44 (0.010686)
feature 61 (0.010582)
feature 3 (0.010484)
feature 84 (0.010363)
feature 362 (0.010218)
inner fold=2
accuracy=0.555555555556
feature 129 (0.026616)
feature 136 (0.024729)
feature 153 (0.023508)
feature 44 (0.022261)
feature 4 (0.020466)
feature 208 (0.018015)
feature 159 (0.017086)
feature 209 (0.016667)
feature 30 (0.015668)
feature 227 (0.015525)
feature 35 (0.014757)
feature 272 (0.014208)
feature 383 (0.013433)
feature 201 (0.013142)
feature 58 (0.013013)
feature 107 (0.012874)
feature 138 (0.012649)
feature 156 (0.012285)
feature 122 (0.011660)
feature 135 (0.011645)
feature 381 (0.011425)
feature 184 (0.011087)
feature 157 (0.010994)
feature 115 (0.010748)
feature 79 (0.010409)
feature 100 (0.010371)
feature 182 (0.010319)
feature 53 (0.010258)
feature 171 (0.010150)
feature 166 (0.010131)
inner fold=3
accuracy=0.533333333333
feature 227 (0.039557)
feature 173 (0.026406)
feature 1 (0.023225)
feature 285 (0.021489)
feature 294 (0.020497)
feature 209 (0.018556)
feature 136 (0.018476)
feature 202 (0.018007)
feature 169 (0.016387)
feature 167 (0.015609)
feature 160 (0.015234)
feature 115 (0.014583)
feature 157 (0.014355)
feature 168 (0.014175)
feature 219 (0.013669)
feature 216 (0.013010)
feature 171 (0.012934)
feature 44 (0.012857)
feature 120 (0.012694)
feature 182 (0.012636)
feature 12 (0.012612)
feature 2 (0.012517)
feature 210 (0.011825)
feature 71 (0.011767)
feature 28 (0.011152)
feature 155 (0.010459)
feature 9 (0.010359)
feature 29 (0.009828)
feature 125 (0.009827)
feature 464 (0.009276)
inner fold=4
accuracy=0.466666666667
feature 158 (0.025889)
feature 156 (0.025293)
feature 171 (0.022776)
feature 80 (0.019503)
feature 172 (0.019131)
feature 200 (0.019050)
feature 52 (0.017631)
feature 135 (0.017307)
feature 208 (0.017273)
feature 209 (0.017220)
feature 58 (0.016382)
feature 142 (0.016172)
feature 385 (0.015832)
feature 201 (0.015536)
feature 51 (0.015521)
feature 152 (0.015173)
feature 173 (0.014385)
feature 364 (0.014381)
feature 123 (0.014358)
feature 110 (0.012665)
feature 157 (0.012568)
feature 213 (0.012208)
feature 129 (0.011880)
feature 101 (0.011803)
feature 24 (0.011340)
feature 207 (0.010949)
feature 4 (0.010936)
feature 122 (0.010893)
feature 60 (0.010358)
feature 138 (0.009846)
inner fold=0
accuracy=0.630434782609
feature 344 (0.028484)
feature 203 (0.022718)
feature 211 (0.022450)
feature 53 (0.022191)
feature 12 (0.021381)
feature 81 (0.021379)
feature 171 (0.021294)
feature 159 (0.019638)
feature 78 (0.019498)
feature 138 (0.017952)
feature 30 (0.017532)
feature 168 (0.015644)
feature 294 (0.015573)
feature 156 (0.014632)
feature 130 (0.013499)
feature 231 (0.013443)
feature 122 (0.013190)
feature 40 (0.013147)
feature 202 (0.012956)
feature 287 (0.012362)
feature 108 (0.012193)
feature 62 (0.012141)
feature 158 (0.012031)
feature 145 (0.011606)
feature 207 (0.011592)
feature 151 (0.011300)
feature 140 (0.011100)
feature 176 (0.010434)
feature 14 (0.010387)
feature 4 (0.009886)
inner fold=1
accuracy=0.565217391304
feature 12 (0.034614)
feature 172 (0.030134)
feature 215 (0.027716)
feature 52 (0.024408)
feature 209 (0.020723)
feature 156 (0.020089)
feature 102 (0.018896)
feature 227 (0.017667)
feature 272 (0.017392)
feature 78 (0.016795)
feature 0 (0.016309)
feature 166 (0.016265)
feature 385 (0.014808)
feature 84 (0.014430)
feature 174 (0.014382)
feature 128 (0.013255)
feature 101 (0.011739)
feature 39 (0.011296)
feature 151 (0.011275)
feature 82 (0.011174)
feature 381 (0.011038)
feature 336 (0.010831)
feature 185 (0.010786)
feature 175 (0.010330)
feature 57 (0.010296)
feature 44 (0.009906)
feature 203 (0.009901)
feature 50 (0.009785)
feature 207 (0.009747)
feature 240 (0.009711)
inner fold=2
accuracy=0.644444444444
feature 171 (0.037490)
feature 294 (0.035473)
feature 142 (0.027632)
feature 82 (0.019321)
feature 172 (0.018274)
feature 138 (0.017822)
feature 385 (0.017600)
feature 223 (0.017578)
feature 156 (0.017500)
feature 130 (0.016426)
feature 30 (0.015723)
feature 134 (0.015639)
feature 110 (0.015224)
feature 78 (0.014593)
feature 56 (0.014233)
feature 53 (0.014037)
feature 158 (0.013917)
feature 173 (0.013904)
feature 62 (0.013673)
feature 33 (0.013359)
feature 136 (0.013084)
feature 222 (0.012702)
feature 235 (0.012521)
feature 103 (0.012440)
feature 8 (0.012368)
feature 131 (0.012183)
feature 73 (0.011743)
feature 214 (0.011586)
feature 203 (0.011546)
feature 231 (0.011222)
inner fold=3
accuracy=0.577777777778
feature 172 (0.041930)
feature 210 (0.025188)
feature 194 (0.022846)
feature 155 (0.021276)
feature 168 (0.020092)
feature 35 (0.019629)
feature 52 (0.019020)
feature 53 (0.016396)
feature 156 (0.015565)
feature 188 (0.015150)
feature 173 (0.014664)
feature 134 (0.014507)
feature 211 (0.014350)
feature 301 (0.014283)
feature 175 (0.014264)
feature 55 (0.014189)
feature 130 (0.013882)
feature 203 (0.013696)
feature 46 (0.013589)
feature 433 (0.012846)
feature 122 (0.011687)
feature 161 (0.011666)
feature 231 (0.011475)
feature 454 (0.011048)
feature 71 (0.010773)
feature 107 (0.010535)
feature 174 (0.010529)
feature 142 (0.010518)
feature 136 (0.010462)
feature 42 (0.010029)
inner fold=4
accuracy=0.688888888889

lay_id=6
feature 102 (0.031407)
feature 227 (0.026929)
feature 46 (0.025689)
feature 123 (0.022272)
feature 385 (0.019953)
feature 84 (0.018927)
feature 171 (0.017161)
feature 175 (0.016485)
feature 203 (0.016230)
feature 215 (0.015796)
feature 62 (0.014933)
feature 80 (0.014827)
feature 137 (0.014229)
feature 213 (0.014090)
feature 5 (0.013514)
feature 209 (0.013053)
feature 294 (0.012834)
feature 114 (0.012804)
feature 158 (0.012262)
feature 56 (0.012097)
feature 77 (0.011942)
feature 50 (0.011731)
feature 12 (0.011623)
feature 78 (0.011394)
feature 110 (0.011221)
feature 115 (0.011027)
feature 200 (0.010771)
feature 183 (0.010158)
feature 79 (0.010086)
feature 127 (0.010055)
inner fold=0
accuracy=0.673913043478
feature 5 (0.025873)
feature 344 (0.025361)
feature 128 (0.024002)
feature 454 (0.023171)
feature 8 (0.022590)
feature 129 (0.021978)
feature 77 (0.019181)
feature 58 (0.018399)
feature 172 (0.017963)
feature 203 (0.017518)
feature 78 (0.016811)
feature 152 (0.016321)
feature 142 (0.015479)
feature 105 (0.015373)
feature 148 (0.014623)
feature 215 (0.014380)
feature 134 (0.014274)
feature 184 (0.013444)
feature 106 (0.013363)
feature 216 (0.012675)
feature 43 (0.012122)
feature 174 (0.011921)
feature 166 (0.011750)
feature 114 (0.011671)
feature 294 (0.011550)
feature 24 (0.011510)
feature 63 (0.011477)
feature 72 (0.011140)
feature 130 (0.010784)
feature 199 (0.010539)
inner fold=1
accuracy=0.630434782609
feature 210 (0.030981)
feature 131 (0.022486)
feature 227 (0.021150)
feature 294 (0.019792)
feature 58 (0.018397)
feature 168 (0.015938)
feature 203 (0.015854)
feature 50 (0.015749)
feature 137 (0.015474)
feature 231 (0.015302)
feature 80 (0.014937)
feature 184 (0.014374)
feature 82 (0.014305)
feature 60 (0.014284)
feature 47 (0.013980)
feature 81 (0.013753)
feature 200 (0.013745)
feature 344 (0.013287)
feature 135 (0.013066)
feature 129 (0.013029)
feature 44 (0.012976)
feature 35 (0.012799)
feature 181 (0.012467)
feature 134 (0.012320)
feature 103 (0.011739)
feature 138 (0.011677)
feature 99 (0.011630)
feature 174 (0.011466)
feature 166 (0.011333)
feature 62 (0.011156)
inner fold=2
accuracy=0.622222222222
feature 171 (0.049538)
feature 129 (0.020069)
feature 222 (0.019257)
feature 158 (0.019092)
feature 137 (0.018756)
feature 209 (0.015433)
feature 211 (0.015322)
feature 131 (0.014753)
feature 127 (0.013947)
feature 4 (0.013728)
feature 79 (0.013704)
feature 395 (0.012889)
feature 161 (0.012743)
feature 210 (0.012460)
feature 57 (0.012434)
feature 143 (0.012207)
feature 104 (0.011863)
feature 12 (0.011547)
feature 84 (0.011411)
feature 58 (0.011212)
feature 188 (0.011020)
feature 159 (0.010867)
feature 55 (0.010758)
feature 63 (0.010173)
feature 82 (0.010123)
feature 62 (0.009758)
feature 134 (0.009635)
feature 50 (0.009623)
feature 128 (0.009557)
feature 358 (0.009405)
inner fold=3
accuracy=0.488888888889
feature 344 (0.032943)
feature 152 (0.032248)
feature 227 (0.028788)
feature 275 (0.022881)
feature 44 (0.020144)
feature 129 (0.019260)
feature 171 (0.019171)
feature 74 (0.018489)
feature 81 (0.016980)
feature 43 (0.016937)
feature 173 (0.016727)
feature 122 (0.015308)
feature 131 (0.014785)
feature 156 (0.014647)
feature 42 (0.014528)
feature 179 (0.013636)
feature 79 (0.013052)
feature 15 (0.012953)
feature 110 (0.012863)
feature 143 (0.012616)
feature 209 (0.012525)
feature 106 (0.012410)
feature 202 (0.012355)
feature 362 (0.012236)
feature 34 (0.012232)
feature 138 (0.011945)
feature 29 (0.011847)
feature 136 (0.011511)
feature 235 (0.010878)
feature 40 (0.010481)
inner fold=4
accuracy=0.622222222222
feature 294 (0.042522)
feature 203 (0.030562)
feature 148 (0.027360)
feature 58 (0.021038)
feature 12 (0.017727)
feature 171 (0.016179)
feature 175 (0.015824)
feature 215 (0.015578)
feature 166 (0.015272)
feature 123 (0.015158)
feature 46 (0.015046)
feature 128 (0.014049)
feature 77 (0.013751)
feature 105 (0.013140)
feature 82 (0.012873)
feature 188 (0.012583)
feature 420 (0.011808)
feature 30 (0.011647)
feature 155 (0.011477)
feature 125 (0.011476)
feature 208 (0.011469)
feature 156 (0.011468)
feature 164 (0.011322)
feature 336 (0.011010)
feature 136 (0.010943)
feature 0 (0.010890)
feature 227 (0.010843)
feature 120 (0.010413)
feature 60 (0.009615)
feature 181 (0.009478)
inner fold=0
accuracy=0.695652173913
feature 294 (0.038254)
feature 215 (0.029267)
feature 62 (0.021535)
feature 114 (0.021510)
feature 158 (0.019822)
feature 227 (0.019456)
feature 78 (0.018130)
feature 138 (0.016779)
feature 43 (0.016576)
feature 101 (0.016334)
feature 55 (0.016304)
feature 153 (0.015801)
feature 136 (0.014148)
feature 79 (0.013759)
feature 120 (0.013455)
feature 231 (0.013135)
feature 199 (0.013067)
feature 148 (0.012614)
feature 168 (0.012337)
feature 203 (0.010931)
feature 126 (0.010915)
feature 54 (0.010700)
feature 208 (0.010586)
feature 414 (0.010395)
feature 175 (0.010370)
feature 12 (0.010143)
feature 344 (0.009936)
feature 51 (0.009882)
feature 140 (0.009809)
feature 58 (0.009628)
inner fold=1
accuracy=0.608695652174
feature 294 (0.032303)
feature 81 (0.025938)
feature 139 (0.025577)
feature 208 (0.024825)
feature 174 (0.023081)
feature 143 (0.022075)
feature 137 (0.021348)
feature 123 (0.020124)
feature 227 (0.018122)
feature 128 (0.018120)
feature 160 (0.015086)
feature 197 (0.014191)
feature 105 (0.013895)
feature 56 (0.013828)
feature 101 (0.013068)
feature 136 (0.012842)
feature 129 (0.012813)
feature 172 (0.012670)
feature 54 (0.012142)
feature 130 (0.011555)
feature 40 (0.011418)
feature 340 (0.011009)
feature 12 (0.010660)
feature 14 (0.010635)
feature 159 (0.010267)
feature 47 (0.010142)
feature 78 (0.010139)
feature 62 (0.010041)
feature 138 (0.009849)
feature 155 (0.009765)
inner fold=2
accuracy=0.711111111111
feature 294 (0.040881)
feature 158 (0.023239)
feature 166 (0.017021)
feature 101 (0.016680)
feature 81 (0.016580)
feature 69 (0.016152)
feature 73 (0.015577)
feature 145 (0.015065)
feature 43 (0.015027)
feature 199 (0.014265)
feature 30 (0.013848)
feature 110 (0.012932)
feature 127 (0.012924)
feature 381 (0.012721)
feature 385 (0.012614)
feature 171 (0.012598)
feature 46 (0.012233)
feature 53 (0.011968)
feature 24 (0.011733)
feature 77 (0.011721)
feature 136 (0.011507)
feature 412 (0.011263)
feature 106 (0.011259)
feature 97 (0.011234)
feature 135 (0.010932)
feature 214 (0.010483)
feature 165 (0.010083)
feature 58 (0.010057)
feature 168 (0.009935)
feature 156 (0.009772)
inner fold=3
accuracy=0.533333333333
feature 55 (0.030708)
feature 136 (0.026748)
feature 153 (0.024332)
feature 208 (0.019453)
feature 3 (0.018993)
feature 69 (0.017788)
feature 123 (0.017752)
feature 385 (0.017624)
feature 60 (0.016693)
feature 174 (0.016483)
feature 172 (0.016025)
feature 168 (0.015696)
feature 58 (0.015545)
feature 157 (0.015429)
feature 294 (0.014687)
feature 101 (0.014007)
feature 214 (0.013933)
feature 70 (0.013876)
feature 129 (0.013362)
feature 166 (0.012737)
feature 137 (0.012462)
feature 110 (0.012366)
feature 138 (0.012198)
feature 183 (0.011935)
feature 201 (0.011548)
feature 171 (0.011270)
feature 50 (0.011184)
feature 97 (0.010637)
feature 135 (0.010515)
feature 78 (0.010461)
inner fold=4
accuracy=0.622222222222

lay_id=7
feature 171 (0.034556)
feature 383 (0.030491)
feature 344 (0.027803)
feature 227 (0.025872)
feature 231 (0.022816)
feature 385 (0.022038)
feature 168 (0.021721)
feature 158 (0.021584)
feature 110 (0.020027)
feature 81 (0.018426)
feature 35 (0.017780)
feature 272 (0.017655)
feature 107 (0.015714)
feature 165 (0.015358)
feature 14 (0.014983)
feature 42 (0.014898)
feature 362 (0.014439)
feature 0 (0.014255)
feature 120 (0.014126)
feature 174 (0.013930)
feature 97 (0.013204)
feature 85 (0.013087)
feature 53 (0.012833)
feature 101 (0.012471)
feature 45 (0.011831)
feature 151 (0.011440)
feature 207 (0.011181)
feature 163 (0.011050)
feature 99 (0.011047)
feature 372 (0.010512)
inner fold=0
accuracy=0.717391304348
feature 203 (0.032186)
feature 201 (0.031682)
feature 172 (0.030545)
feature 114 (0.025062)
feature 101 (0.021439)
feature 78 (0.020836)
feature 35 (0.020695)
feature 79 (0.019956)
feature 176 (0.019188)
feature 202 (0.017378)
feature 24 (0.016256)
feature 210 (0.015903)
feature 209 (0.014854)
feature 164 (0.014393)
feature 358 (0.013494)
feature 171 (0.013487)
feature 82 (0.013402)
feature 151 (0.012972)
feature 107 (0.012809)
feature 129 (0.012622)
feature 1 (0.012586)
feature 2 (0.012478)
feature 63 (0.011588)
feature 137 (0.011563)
feature 52 (0.011341)
feature 80 (0.011229)
feature 165 (0.011106)
feature 125 (0.010995)
feature 153 (0.010484)
feature 213 (0.010125)
inner fold=1
accuracy=0.586956521739
feature 171 (0.033453)
feature 203 (0.022661)
feature 62 (0.021945)
feature 209 (0.021392)
feature 168 (0.018566)
feature 14 (0.018398)
feature 172 (0.017579)
feature 127 (0.016257)
feature 101 (0.015608)
feature 97 (0.015502)
feature 344 (0.015425)
feature 130 (0.014527)
feature 54 (0.014192)
feature 213 (0.014010)
feature 184 (0.013957)
feature 69 (0.013887)
feature 235 (0.013613)
feature 24 (0.013389)
feature 294 (0.012835)
feature 164 (0.012673)
feature 390 (0.012165)
feature 167 (0.012013)
feature 107 (0.011992)
feature 129 (0.011891)
feature 51 (0.011887)
feature 46 (0.011531)
feature 82 (0.011110)
feature 5 (0.011108)
feature 55 (0.010717)
feature 210 (0.010468)
inner fold=2
accuracy=0.511111111111
feature 203 (0.038356)
feature 166 (0.038158)
feature 171 (0.028324)
feature 168 (0.021377)
feature 123 (0.020638)
feature 210 (0.019520)
feature 18 (0.019405)
feature 62 (0.014977)
feature 50 (0.014719)
feature 129 (0.014625)
feature 34 (0.014236)
feature 60 (0.014172)
feature 213 (0.014079)
feature 344 (0.013946)
feature 38 (0.013717)
feature 148 (0.013600)
feature 211 (0.013230)
feature 152 (0.012870)
feature 83 (0.012541)
feature 70 (0.012441)
feature 174 (0.012168)
feature 120 (0.011786)
feature 69 (0.011608)
feature 137 (0.011558)
feature 157 (0.011341)
feature 173 (0.011317)
feature 235 (0.011108)
feature 109 (0.010952)
feature 134 (0.010802)
feature 153 (0.010226)
inner fold=3
accuracy=0.577777777778
feature 294 (0.038100)
feature 84 (0.023971)
feature 344 (0.021574)
feature 172 (0.019428)
feature 61 (0.017922)
feature 19 (0.017068)
feature 77 (0.016986)
feature 3 (0.016858)
feature 53 (0.015892)
feature 157 (0.015864)
feature 141 (0.015476)
feature 30 (0.014399)
feature 143 (0.014299)
feature 209 (0.014228)
feature 275 (0.013694)
feature 82 (0.013669)
feature 215 (0.013413)
feature 129 (0.013323)
feature 46 (0.012999)
feature 80 (0.012911)
feature 197 (0.012873)
feature 173 (0.012744)
feature 166 (0.012614)
feature 171 (0.012418)
feature 138 (0.011866)
feature 54 (0.011794)
feature 142 (0.011519)
feature 151 (0.011496)
feature 135 (0.011370)
feature 81 (0.011138)
inner fold=4
accuracy=0.6
feature 110 (0.041257)
feature 294 (0.039950)
feature 55 (0.030220)
feature 227 (0.023613)
feature 38 (0.021044)
feature 156 (0.019572)
feature 134 (0.018539)
feature 136 (0.018144)
feature 166 (0.016239)
feature 12 (0.015263)
feature 96 (0.013804)
feature 79 (0.013322)
feature 44 (0.013276)
feature 454 (0.013161)
feature 48 (0.012756)
feature 211 (0.012607)
feature 164 (0.012298)
feature 34 (0.012208)
feature 161 (0.012005)
feature 102 (0.011867)
feature 168 (0.011854)
feature 231 (0.011733)
feature 207 (0.011289)
feature 200 (0.011007)
feature 385 (0.010905)
feature 109 (0.010371)
feature 101 (0.010170)
feature 78 (0.009957)
feature 160 (0.009903)
feature 70 (0.009894)
inner fold=0
accuracy=0.565217391304
feature 172 (0.025940)
feature 35 (0.024193)
feature 203 (0.019993)
feature 30 (0.018193)
feature 34 (0.017748)
feature 52 (0.017581)
feature 213 (0.017296)
feature 166 (0.016757)
feature 3 (0.016674)
feature 40 (0.014812)
feature 77 (0.014504)
feature 84 (0.014342)
feature 43 (0.014113)
feature 41 (0.013824)
feature 174 (0.013761)
feature 51 (0.013369)
feature 159 (0.013275)
feature 107 (0.013013)
feature 169 (0.012995)
feature 38 (0.012981)
feature 158 (0.012817)
feature 109 (0.012540)
feature 123 (0.012333)
feature 200 (0.012025)
feature 81 (0.011615)
feature 135 (0.011156)
feature 164 (0.010989)
feature 78 (0.010937)
feature 120 (0.010812)
feature 138 (0.010802)
inner fold=1
accuracy=0.630434782609
feature 110 (0.030010)
feature 227 (0.025540)
feature 213 (0.023879)
feature 147 (0.022144)
feature 272 (0.020558)
feature 344 (0.020448)
feature 171 (0.018929)
feature 166 (0.018871)
feature 159 (0.018533)
feature 126 (0.018512)
feature 68 (0.018185)
feature 102 (0.017748)
feature 131 (0.017385)
feature 139 (0.016061)
feature 184 (0.014429)
feature 129 (0.013622)
feature 164 (0.013430)
feature 454 (0.013330)
feature 137 (0.013256)
feature 294 (0.013169)
feature 63 (0.011837)
feature 215 (0.011609)
feature 53 (0.011516)
feature 214 (0.011514)
feature 97 (0.011474)
feature 55 (0.011445)
feature 135 (0.011221)
feature 175 (0.010637)
feature 188 (0.010615)
feature 57 (0.010568)
inner fold=2
accuracy=0.644444444444
feature 155 (0.031843)
feature 134 (0.024312)
feature 294 (0.023706)
feature 173 (0.022831)
feature 138 (0.020687)
feature 148 (0.020363)
feature 174 (0.020037)
feature 42 (0.019825)
feature 151 (0.019593)
feature 213 (0.019575)
feature 152 (0.019432)
feature 68 (0.018872)
feature 123 (0.017763)
feature 51 (0.016981)
feature 166 (0.016962)
feature 129 (0.016697)
feature 227 (0.015786)
feature 135 (0.014203)
feature 209 (0.014165)
feature 110 (0.013290)
feature 203 (0.013175)
feature 44 (0.012126)
feature 136 (0.011710)
feature 5 (0.011701)
feature 102 (0.011405)
feature 80 (0.010984)
feature 208 (0.010918)
feature 38 (0.010503)
feature 127 (0.010250)
feature 156 (0.010216)
inner fold=3
accuracy=0.422222222222
feature 109 (0.036115)
feature 211 (0.028057)
feature 203 (0.022839)
feature 137 (0.021140)
feature 52 (0.018121)
feature 2 (0.017532)
feature 81 (0.017264)
feature 77 (0.016239)
feature 172 (0.016118)
feature 120 (0.015896)
feature 138 (0.015401)
feature 385 (0.015321)
feature 209 (0.014999)
feature 62 (0.014985)
feature 102 (0.014965)
feature 201 (0.014783)
feature 4 (0.014485)
feature 78 (0.013686)
feature 38 (0.013233)
feature 30 (0.012555)
feature 110 (0.012267)
feature 152 (0.012227)
feature 135 (0.012200)
feature 82 (0.012137)
feature 157 (0.011683)
feature 160 (0.011641)
feature 85 (0.011376)
feature 223 (0.011284)
feature 181 (0.011201)
feature 188 (0.010354)
inner fold=4
accuracy=0.533333333333

lay_id=8
feature 171 (0.034438)
feature 172 (0.026680)
feature 203 (0.025169)
feature 43 (0.025018)
feature 207 (0.021835)
feature 30 (0.018891)
feature 168 (0.018623)
feature 55 (0.018390)
feature 120 (0.016968)
feature 123 (0.016949)
feature 138 (0.016668)
feature 44 (0.014595)
feature 173 (0.014296)
feature 156 (0.013909)
feature 81 (0.013364)
feature 46 (0.013129)
feature 38 (0.012745)
feature 21 (0.012694)
feature 211 (0.012647)
feature 77 (0.012500)
feature 107 (0.012310)
feature 152 (0.012017)
feature 53 (0.011939)
feature 56 (0.011781)
feature 128 (0.011635)
feature 213 (0.011345)
feature 54 (0.011271)
feature 109 (0.011072)
feature 39 (0.010579)
feature 69 (0.010257)
inner fold=0
accuracy=0.695652173913
feature 175 (0.030916)
feature 81 (0.025867)
feature 213 (0.025555)
feature 136 (0.025464)
feature 172 (0.023298)
feature 166 (0.021650)
feature 168 (0.021538)
feature 60 (0.018462)
feature 134 (0.018265)
feature 131 (0.017874)
feature 385 (0.016430)
feature 203 (0.015449)
feature 110 (0.015378)
feature 383 (0.015365)
feature 202 (0.015312)
feature 101 (0.015231)
feature 227 (0.014835)
feature 148 (0.014833)
feature 55 (0.014607)
feature 53 (0.014238)
feature 18 (0.013842)
feature 56 (0.013353)
feature 96 (0.013259)
feature 12 (0.012394)
feature 194 (0.012027)
feature 62 (0.011674)
feature 235 (0.011599)
feature 72 (0.010792)
feature 34 (0.010398)
feature 24 (0.010288)
inner fold=1
accuracy=0.478260869565
feature 44 (0.032038)
feature 235 (0.029161)
feature 57 (0.028927)
feature 155 (0.026043)
feature 172 (0.023184)
feature 127 (0.021146)
feature 385 (0.018443)
feature 60 (0.018231)
feature 210 (0.017083)
feature 134 (0.016852)
feature 203 (0.016821)
feature 50 (0.016449)
feature 109 (0.015026)
feature 98 (0.014274)
feature 168 (0.013913)
feature 135 (0.013631)
feature 165 (0.013417)
feature 110 (0.013292)
feature 33 (0.013273)
feature 163 (0.013238)
feature 35 (0.012841)
feature 28 (0.012817)
feature 120 (0.012204)
feature 24 (0.011659)
feature 139 (0.011499)
feature 142 (0.011441)
feature 138 (0.010993)
feature 185 (0.010926)
feature 34 (0.010852)
feature 115 (0.010695)
inner fold=2
accuracy=0.555555555556
feature 171 (0.044791)
feature 81 (0.043295)
feature 136 (0.024991)
feature 101 (0.024299)
feature 227 (0.021382)
feature 168 (0.021013)
feature 106 (0.018526)
feature 30 (0.017178)
feature 2 (0.015958)
feature 123 (0.015952)
feature 142 (0.015840)
feature 209 (0.015003)
feature 151 (0.014303)
feature 139 (0.013992)
feature 69 (0.012760)
feature 35 (0.012289)
feature 50 (0.012158)
feature 163 (0.011977)
feature 207 (0.011891)
feature 134 (0.011638)
feature 184 (0.011185)
feature 172 (0.011094)
feature 153 (0.010912)
feature 102 (0.010540)
feature 63 (0.010532)
feature 29 (0.010337)
feature 110 (0.010154)
feature 127 (0.009922)
feature 72 (0.009801)
feature 17 (0.009307)
inner fold=3
accuracy=0.555555555556
feature 174 (0.031325)
feature 120 (0.026955)
feature 110 (0.021025)
feature 138 (0.020858)
feature 172 (0.019834)
feature 44 (0.019693)
feature 142 (0.019416)
feature 294 (0.019116)
feature 203 (0.018794)
feature 129 (0.017149)
feature 166 (0.017117)
feature 207 (0.015774)
feature 344 (0.015355)
feature 55 (0.014930)
feature 56 (0.013904)
feature 81 (0.013378)
feature 60 (0.012935)
feature 137 (0.012881)
feature 82 (0.012707)
feature 18 (0.012696)
feature 173 (0.012264)
feature 151 (0.012033)
feature 171 (0.011493)
feature 287 (0.010861)
feature 127 (0.010752)
feature 80 (0.010450)
feature 215 (0.010433)
feature 224 (0.010371)
feature 202 (0.010123)
feature 339 (0.009876)
inner fold=4
accuracy=0.555555555556
feature 203 (0.025185)
feature 151 (0.020288)
feature 227 (0.019431)
feature 120 (0.018953)
feature 173 (0.018931)
feature 107 (0.015787)
feature 99 (0.015447)
feature 142 (0.015336)
feature 24 (0.014874)
feature 143 (0.014138)
feature 44 (0.014069)
feature 385 (0.013648)
feature 175 (0.013212)
feature 109 (0.012852)
feature 79 (0.012789)
feature 147 (0.012715)
feature 207 (0.012677)
feature 344 (0.012620)
feature 336 (0.012459)
feature 127 (0.012457)
feature 38 (0.012083)
feature 160 (0.011699)
feature 134 (0.011666)
feature 136 (0.011634)
feature 69 (0.011558)
feature 214 (0.011444)
feature 148 (0.011367)
feature 129 (0.010822)
feature 106 (0.010731)
feature 33 (0.010565)
inner fold=0
accuracy=0.695652173913
feature 44 (0.033637)
feature 173 (0.027201)
feature 99 (0.024632)
feature 210 (0.023489)
feature 46 (0.022985)
feature 156 (0.021892)
feature 73 (0.019984)
feature 56 (0.019788)
feature 155 (0.019557)
feature 164 (0.019400)
feature 105 (0.018854)
feature 344 (0.017848)
feature 69 (0.016341)
feature 148 (0.016169)
feature 78 (0.015767)
feature 122 (0.014770)
feature 24 (0.013877)
feature 26 (0.013491)
feature 211 (0.012681)
feature 294 (0.012485)
feature 28 (0.012119)
feature 63 (0.011817)
feature 135 (0.011433)
feature 110 (0.011397)
feature 38 (0.010935)
feature 163 (0.010751)
feature 17 (0.010682)
feature 107 (0.010255)
feature 146 (0.010069)
feature 152 (0.009451)
inner fold=1
accuracy=0.434782608696
feature 231 (0.023384)
feature 46 (0.020958)
feature 114 (0.020894)
feature 194 (0.019470)
feature 148 (0.018700)
feature 134 (0.016729)
feature 208 (0.016410)
feature 110 (0.016407)
feature 209 (0.016331)
feature 412 (0.014989)
feature 39 (0.014473)
feature 182 (0.014389)
feature 215 (0.014123)
feature 145 (0.014122)
feature 36 (0.013917)
feature 54 (0.013749)
feature 61 (0.013724)
feature 42 (0.013057)
feature 203 (0.012779)
feature 275 (0.012719)
feature 174 (0.012703)
feature 219 (0.011899)
feature 454 (0.011310)
feature 60 (0.011177)
feature 99 (0.011146)
feature 158 (0.011068)
feature 102 (0.011000)
feature 151 (0.010724)
feature 125 (0.010701)
feature 57 (0.010105)
inner fold=2
accuracy=0.533333333333
feature 201 (0.029802)
feature 383 (0.027727)
feature 120 (0.026046)
feature 101 (0.024029)
feature 227 (0.023332)
feature 158 (0.022242)
feature 43 (0.020402)
feature 127 (0.019491)
feature 24 (0.018848)
feature 46 (0.017082)
feature 210 (0.016329)
feature 110 (0.015915)
feature 166 (0.015232)
feature 34 (0.014649)
feature 84 (0.014481)
feature 209 (0.013828)
feature 152 (0.013331)
feature 102 (0.011845)
feature 143 (0.011772)
feature 207 (0.011375)
feature 12 (0.011297)
feature 57 (0.010988)
feature 215 (0.009801)
feature 172 (0.009489)
feature 131 (0.009411)
feature 18 (0.009280)
feature 141 (0.009151)
feature 148 (0.009057)
feature 171 (0.009053)
feature 161 (0.008896)
inner fold=3
accuracy=0.6
feature 294 (0.030341)
feature 30 (0.024317)
feature 160 (0.021193)
feature 202 (0.020468)
feature 110 (0.020348)
feature 53 (0.018636)
feature 169 (0.018552)
feature 173 (0.017935)
feature 168 (0.017699)
feature 152 (0.017159)
feature 81 (0.017013)
feature 34 (0.017001)
feature 123 (0.015894)
feature 151 (0.015501)
feature 174 (0.015360)
feature 157 (0.014312)
feature 60 (0.014007)
feature 171 (0.012493)
feature 200 (0.012315)
feature 79 (0.011580)
feature 63 (0.011464)
feature 50 (0.011422)
feature 80 (0.011389)
feature 275 (0.011194)
feature 137 (0.010912)
feature 181 (0.010692)
feature 128 (0.010339)
feature 142 (0.010316)
feature 203 (0.010261)
feature 224 (0.009971)
inner fold=4
accuracy=0.622222222222

lay_id=9
feature 172 (0.037810)
feature 129 (0.028012)
feature 464 (0.023972)
feature 294 (0.023338)
feature 110 (0.022697)
feature 166 (0.019635)
feature 138 (0.018051)
feature 0 (0.016809)
feature 4 (0.014685)
feature 38 (0.014082)
feature 275 (0.013923)
feature 208 (0.013595)
feature 134 (0.013418)
feature 71 (0.013258)
feature 209 (0.013147)
feature 44 (0.012968)
feature 127 (0.012596)
feature 390 (0.012184)
feature 83 (0.011629)
feature 82 (0.011620)
feature 383 (0.011376)
feature 46 (0.010894)
feature 203 (0.010569)
feature 198 (0.010407)
feature 122 (0.010179)
feature 58 (0.009798)
feature 168 (0.009793)
feature 200 (0.009446)
feature 128 (0.009337)
feature 106 (0.009172)
inner fold=0
accuracy=0.739130434783
feature 171 (0.027654)
feature 138 (0.025298)
feature 172 (0.022326)
feature 175 (0.021371)
feature 362 (0.020323)
feature 142 (0.015861)
feature 143 (0.015735)
feature 60 (0.015423)
feature 383 (0.015098)
feature 134 (0.014584)
feature 109 (0.013914)
feature 385 (0.013661)
feature 168 (0.013232)
feature 80 (0.013202)
feature 210 (0.012284)
feature 54 (0.012206)
feature 36 (0.011885)
feature 381 (0.011492)
feature 0 (0.011460)
feature 211 (0.011382)
feature 130 (0.011352)
feature 52 (0.011064)
feature 127 (0.010503)
feature 157 (0.010342)
feature 235 (0.010114)
feature 202 (0.010021)
feature 147 (0.009885)
feature 30 (0.009534)
feature 148 (0.009441)
feature 56 (0.009232)
inner fold=1
accuracy=0.565217391304
feature 172 (0.031331)
feature 134 (0.026217)
feature 201 (0.023497)
feature 128 (0.022962)
feature 56 (0.022491)
feature 55 (0.021105)
feature 294 (0.020855)
feature 142 (0.020155)
feature 227 (0.020108)
feature 35 (0.019555)
feature 171 (0.019523)
feature 138 (0.016905)
feature 168 (0.016682)
feature 102 (0.016505)
feature 136 (0.014238)
feature 127 (0.014001)
feature 141 (0.013708)
feature 152 (0.013502)
feature 147 (0.013084)
feature 58 (0.012878)
feature 18 (0.012752)
feature 80 (0.011725)
feature 21 (0.011706)
feature 166 (0.010987)
feature 381 (0.010614)
feature 184 (0.010470)
feature 24 (0.010202)
feature 272 (0.009024)
feature 213 (0.008980)
feature 362 (0.008722)
inner fold=2
accuracy=0.666666666667
feature 227 (0.031592)
feature 134 (0.022918)
feature 70 (0.021343)
feature 349 (0.021179)
feature 200 (0.020385)
feature 101 (0.019781)
feature 115 (0.019225)
feature 139 (0.017363)
feature 129 (0.016515)
feature 202 (0.016093)
feature 174 (0.016089)
feature 188 (0.015217)
feature 78 (0.015085)
feature 51 (0.014761)
feature 152 (0.014370)
feature 235 (0.014257)
feature 52 (0.013643)
feature 172 (0.013629)
feature 80 (0.013243)
feature 156 (0.013116)
feature 42 (0.013010)
feature 285 (0.012720)
feature 158 (0.012671)
feature 171 (0.012629)
feature 136 (0.012553)
feature 166 (0.011744)
feature 102 (0.011363)
feature 3 (0.011068)
feature 294 (0.010786)
feature 201 (0.010305)
inner fold=3
accuracy=0.555555555556
feature 208 (0.035638)
feature 362 (0.029441)
feature 78 (0.024273)
feature 35 (0.022748)
feature 294 (0.021030)
feature 106 (0.018968)
feature 48 (0.018749)
feature 122 (0.018095)
feature 173 (0.017334)
feature 138 (0.016377)
feature 46 (0.016328)
feature 128 (0.016147)
feature 109 (0.015887)
feature 188 (0.015706)
feature 165 (0.015166)
feature 231 (0.015056)
feature 110 (0.015008)
feature 125 (0.014283)
feature 114 (0.013891)
feature 52 (0.013463)
feature 50 (0.012823)
feature 60 (0.012207)
feature 142 (0.011958)
feature 172 (0.010960)
feature 97 (0.010943)
feature 135 (0.010688)
feature 383 (0.010578)
feature 349 (0.010547)
feature 26 (0.010452)
feature 151 (0.009971)
inner fold=4
accuracy=0.6
feature 168 (0.035426)
feature 81 (0.033486)
feature 173 (0.024676)
feature 102 (0.023347)
feature 174 (0.021537)
feature 138 (0.020363)
feature 161 (0.020127)
feature 155 (0.019234)
feature 171 (0.018888)
feature 209 (0.018512)
feature 214 (0.015688)
feature 50 (0.015583)
feature 84 (0.015320)
feature 57 (0.014934)
feature 73 (0.014916)
feature 82 (0.014783)
feature 46 (0.013221)
feature 377 (0.013196)
feature 109 (0.012949)
feature 131 (0.012043)
feature 164 (0.011983)
feature 42 (0.011946)
feature 294 (0.011946)
feature 385 (0.011776)
feature 137 (0.011762)
feature 412 (0.011206)
feature 12 (0.011115)
feature 133 (0.010683)
feature 130 (0.010374)
feature 222 (0.010268)
inner fold=0
accuracy=0.54347826087
feature 167 (0.031479)
feature 172 (0.020486)
feature 81 (0.018853)
feature 58 (0.018690)
feature 442 (0.018666)
feature 175 (0.017315)
feature 208 (0.016896)
feature 340 (0.015740)
feature 43 (0.015163)
feature 147 (0.014277)
feature 33 (0.014232)
feature 0 (0.013490)
feature 30 (0.013455)
feature 101 (0.013137)
feature 46 (0.012760)
feature 106 (0.012533)
feature 385 (0.011961)
feature 344 (0.011696)
feature 5 (0.011450)
feature 102 (0.011405)
feature 41 (0.011235)
feature 224 (0.011226)
feature 134 (0.011225)
feature 166 (0.011155)
feature 51 (0.011104)
feature 164 (0.010887)
feature 215 (0.010878)
feature 105 (0.010679)
feature 219 (0.009752)
feature 372 (0.009730)
inner fold=1
accuracy=0.586956521739
feature 272 (0.028720)
feature 168 (0.027646)
feature 156 (0.023008)
feature 54 (0.022526)
feature 152 (0.020328)
feature 129 (0.018812)
feature 143 (0.018349)
feature 110 (0.018334)
feature 227 (0.016676)
feature 81 (0.015927)
feature 173 (0.015889)
feature 174 (0.015786)
feature 30 (0.015394)
feature 385 (0.015236)
feature 63 (0.015015)
feature 172 (0.014336)
feature 215 (0.013356)
feature 24 (0.012885)
feature 33 (0.012650)
feature 142 (0.012608)
feature 123 (0.012272)
feature 55 (0.012094)
feature 100 (0.011981)
feature 35 (0.011858)
feature 68 (0.011793)
feature 78 (0.011750)
feature 211 (0.011496)
feature 74 (0.011384)
feature 210 (0.011205)
feature 202 (0.010991)
inner fold=2
accuracy=0.688888888889
feature 101 (0.025037)
feature 55 (0.024337)
feature 156 (0.022538)
feature 53 (0.022051)
feature 202 (0.021722)
feature 294 (0.021722)
feature 166 (0.021430)
feature 134 (0.017871)
feature 174 (0.017612)
feature 51 (0.016177)
feature 160 (0.015653)
feature 42 (0.015599)
feature 38 (0.015482)
feature 135 (0.015270)
feature 120 (0.015256)
feature 136 (0.014875)
feature 46 (0.013259)
feature 24 (0.012978)
feature 2 (0.012295)
feature 45 (0.012166)
feature 79 (0.012021)
feature 131 (0.011857)
feature 36 (0.011733)
feature 44 (0.011701)
feature 81 (0.011523)
feature 109 (0.011380)
feature 152 (0.011068)
feature 231 (0.010831)
feature 30 (0.010808)
feature 148 (0.010447)
inner fold=3
accuracy=0.688888888889
feature 294 (0.046766)
feature 60 (0.030377)
feature 12 (0.021791)
feature 344 (0.020964)
feature 159 (0.018184)
feature 24 (0.016343)
feature 138 (0.015932)
feature 44 (0.014472)
feature 143 (0.014261)
feature 136 (0.013542)
feature 166 (0.013395)
feature 50 (0.013309)
feature 97 (0.012684)
feature 35 (0.012351)
feature 163 (0.012103)
feature 16 (0.011897)
feature 385 (0.011856)
feature 210 (0.011555)
feature 227 (0.011512)
feature 80 (0.011328)
feature 182 (0.010861)
feature 137 (0.010718)
feature 173 (0.010564)
feature 125 (0.010548)
feature 222 (0.009716)
feature 0 (0.009692)
feature 168 (0.009680)
feature 21 (0.009576)
feature 70 (0.009350)
feature 134 (0.008953)
inner fold=4
accuracy=0.644444444444

lay_id=10
feature 172 (0.034989)
feature 138 (0.025002)
feature 44 (0.023180)
feature 84 (0.022920)
feature 152 (0.022110)
feature 55 (0.021639)
feature 193 (0.021397)
feature 211 (0.020435)
feature 215 (0.019051)
feature 110 (0.018315)
feature 131 (0.017520)
feature 222 (0.016334)
feature 129 (0.015870)
feature 123 (0.015256)
feature 58 (0.014472)
feature 199 (0.014456)
feature 173 (0.014266)
feature 294 (0.014023)
feature 174 (0.013758)
feature 33 (0.013193)
feature 151 (0.013035)
feature 53 (0.012587)
feature 143 (0.012267)
feature 52 (0.011210)
feature 234 (0.011190)
feature 74 (0.011002)
feature 141 (0.010865)
feature 224 (0.010215)
feature 4 (0.010088)
feature 28 (0.009712)
inner fold=0
accuracy=0.760869565217
feature 110 (0.034661)
feature 211 (0.033056)
feature 174 (0.031006)
feature 294 (0.023219)
feature 78 (0.023054)
feature 136 (0.021104)
feature 171 (0.020766)
feature 44 (0.019307)
feature 167 (0.017052)
feature 138 (0.016125)
feature 127 (0.015817)
feature 377 (0.014660)
feature 231 (0.014260)
feature 164 (0.014232)
feature 35 (0.013985)
feature 362 (0.013538)
feature 235 (0.013413)
feature 54 (0.012445)
feature 0 (0.012324)
feature 12 (0.011840)
feature 134 (0.011773)
feature 141 (0.011523)
feature 128 (0.011300)
feature 161 (0.011282)
feature 133 (0.011195)
feature 165 (0.010899)
feature 51 (0.010728)
feature 172 (0.010510)
feature 300 (0.010350)
feature 166 (0.010100)
inner fold=1
accuracy=0.45652173913
feature 153 (0.030514)
feature 172 (0.027478)
feature 165 (0.025626)
feature 159 (0.025028)
feature 73 (0.024233)
feature 174 (0.023748)
feature 14 (0.020908)
feature 209 (0.020521)
feature 152 (0.019480)
feature 385 (0.018150)
feature 166 (0.018147)
feature 97 (0.016874)
feature 108 (0.015891)
feature 50 (0.014911)
feature 81 (0.014125)
feature 96 (0.014115)
feature 213 (0.013775)
feature 155 (0.013738)
feature 71 (0.013257)
feature 3 (0.013037)
feature 16 (0.012724)
feature 200 (0.012724)
feature 21 (0.012465)
feature 46 (0.012146)
feature 207 (0.011870)
feature 55 (0.011727)
feature 142 (0.011569)
feature 294 (0.011409)
feature 34 (0.011406)
feature 63 (0.010435)
inner fold=2
accuracy=0.644444444444
feature 1 (0.029345)
feature 172 (0.028873)
feature 46 (0.027991)
feature 33 (0.026565)
feature 73 (0.020243)
feature 235 (0.020094)
feature 109 (0.019735)
feature 213 (0.019286)
feature 181 (0.017156)
feature 137 (0.016897)
feature 81 (0.015248)
feature 385 (0.015221)
feature 101 (0.015043)
feature 35 (0.014848)
feature 55 (0.014149)
feature 188 (0.014122)
feature 45 (0.013076)
feature 44 (0.012896)
feature 210 (0.012099)
feature 164 (0.011913)
feature 186 (0.011518)
feature 129 (0.011351)
feature 464 (0.011164)
feature 80 (0.011150)
feature 30 (0.010684)
feature 131 (0.010364)
feature 3 (0.010293)
feature 145 (0.010129)
feature 152 (0.010007)
feature 208 (0.009856)
inner fold=3
accuracy=0.622222222222
feature 44 (0.026241)
feature 60 (0.024450)
feature 172 (0.022222)
feature 166 (0.020004)
feature 173 (0.019727)
feature 156 (0.019525)
feature 202 (0.018627)
feature 227 (0.018535)
feature 81 (0.018523)
feature 174 (0.018516)
feature 129 (0.017341)
feature 79 (0.016356)
feature 54 (0.016002)
feature 148 (0.014601)
feature 358 (0.014086)
feature 78 (0.014011)
feature 163 (0.013852)
feature 50 (0.013844)
feature 171 (0.013547)
feature 128 (0.013194)
feature 109 (0.012822)
feature 42 (0.012421)
feature 38 (0.012217)
feature 164 (0.012068)
feature 139 (0.011906)
feature 120 (0.011869)
feature 46 (0.011603)
feature 135 (0.011555)
feature 97 (0.011495)
feature 131 (0.011392)
inner fold=4
accuracy=0.577777777778
feature 171 (0.042353)
feature 131 (0.022270)
feature 148 (0.018301)
feature 81 (0.016925)
feature 58 (0.016880)
feature 294 (0.016860)
feature 208 (0.016706)
feature 395 (0.016651)
feature 136 (0.016572)
feature 227 (0.016543)
feature 213 (0.016241)
feature 52 (0.015247)
feature 135 (0.015180)
feature 173 (0.012981)
feature 55 (0.012924)
feature 39 (0.012823)
feature 62 (0.012598)
feature 203 (0.012395)
feature 21 (0.012391)
feature 247 (0.011942)
feature 134 (0.011922)
feature 157 (0.011436)
feature 156 (0.011369)
feature 151 (0.011295)
feature 214 (0.011220)
feature 129 (0.011209)
feature 155 (0.011190)
feature 100 (0.011097)
feature 73 (0.011030)
feature 138 (0.010891)
inner fold=0
accuracy=0.54347826087
feature 97 (0.038968)
feature 166 (0.028298)
feature 172 (0.024482)
feature 175 (0.022478)
feature 231 (0.019702)
feature 168 (0.019135)
feature 208 (0.015899)
feature 211 (0.015475)
feature 61 (0.015317)
feature 171 (0.015162)
feature 156 (0.014468)
feature 294 (0.013838)
feature 442 (0.013823)
feature 159 (0.013501)
feature 38 (0.012938)
feature 44 (0.012790)
feature 122 (0.012170)
feature 454 (0.012168)
feature 101 (0.011565)
feature 70 (0.011491)
feature 14 (0.011400)
feature 131 (0.011150)
feature 136 (0.011051)
feature 55 (0.010924)
feature 62 (0.010869)
feature 109 (0.010410)
feature 100 (0.010070)
feature 5 (0.009952)
feature 372 (0.009724)
feature 99 (0.009466)
inner fold=1
accuracy=0.54347826087
feature 50 (0.035604)
feature 136 (0.027456)
feature 78 (0.023626)
feature 172 (0.023470)
feature 55 (0.022215)
feature 165 (0.019962)
feature 171 (0.019394)
feature 44 (0.018999)
feature 385 (0.018747)
feature 110 (0.018641)
feature 227 (0.018157)
feature 170 (0.018083)
feature 36 (0.015921)
feature 102 (0.014731)
feature 137 (0.013640)
feature 152 (0.013369)
feature 33 (0.013172)
feature 30 (0.012922)
feature 184 (0.012817)
feature 74 (0.012385)
feature 138 (0.012336)
feature 188 (0.012293)
feature 122 (0.012064)
feature 81 (0.011689)
feature 106 (0.011613)
feature 134 (0.011249)
feature 1 (0.010751)
feature 222 (0.010430)
feature 114 (0.010396)
feature 183 (0.010266)
inner fold=2
accuracy=0.644444444444
feature 44 (0.025295)
feature 129 (0.023114)
feature 171 (0.022486)
feature 207 (0.020935)
feature 122 (0.019745)
feature 128 (0.018670)
feature 189 (0.018111)
feature 152 (0.017814)
feature 21 (0.016001)
feature 235 (0.014811)
feature 208 (0.014564)
feature 142 (0.014287)
feature 143 (0.014257)
feature 52 (0.014176)
feature 126 (0.014033)
feature 209 (0.013402)
feature 46 (0.013030)
feature 193 (0.012933)
feature 138 (0.012855)
feature 110 (0.012737)
feature 158 (0.012440)
feature 166 (0.011936)
feature 412 (0.011491)
feature 159 (0.011433)
feature 165 (0.011081)
feature 84 (0.011006)
feature 43 (0.010857)
feature 157 (0.010766)
feature 216 (0.010664)
feature 301 (0.010572)
inner fold=3
accuracy=0.533333333333
feature 172 (0.046021)
feature 2 (0.028271)
feature 175 (0.023107)
feature 231 (0.021027)
feature 151 (0.020259)
feature 148 (0.015910)
feature 85 (0.015826)
feature 135 (0.015582)
feature 129 (0.014368)
feature 33 (0.013993)
feature 8 (0.013858)
feature 46 (0.013463)
feature 143 (0.012938)
feature 29 (0.012795)
feature 14 (0.012727)
feature 210 (0.012380)
feature 21 (0.012327)
feature 157 (0.012307)
feature 24 (0.012194)
feature 99 (0.012043)
feature 44 (0.011792)
feature 227 (0.011374)
feature 83 (0.011340)
feature 187 (0.010825)
feature 81 (0.010816)
feature 56 (0.010607)
feature 106 (0.010289)
feature 72 (0.010165)
feature 35 (0.009877)
feature 55 (0.009705)
inner fold=4
accuracy=0.488888888889

lay_id=11
feature 168 (0.027881)
feature 78 (0.022420)
feature 211 (0.020264)
feature 152 (0.018768)
feature 203 (0.018319)
feature 159 (0.018226)
feature 210 (0.018020)
feature 142 (0.016765)
feature 172 (0.016614)
feature 167 (0.015781)
feature 301 (0.014499)
feature 50 (0.014286)
feature 103 (0.013626)
feature 46 (0.013429)
feature 127 (0.013362)
feature 123 (0.013193)
feature 344 (0.013154)
feature 81 (0.013011)
feature 145 (0.012935)
feature 33 (0.012497)
feature 137 (0.012392)
feature 114 (0.011470)
feature 216 (0.011183)
feature 26 (0.010808)
feature 47 (0.010704)
feature 53 (0.010557)
feature 231 (0.010481)
feature 174 (0.010334)
feature 442 (0.010319)
feature 79 (0.010145)
inner fold=0
accuracy=0.673913043478
feature 173 (0.036367)
feature 172 (0.034903)
feature 136 (0.024938)
feature 208 (0.024200)
feature 148 (0.022863)
feature 175 (0.020583)
feature 166 (0.017707)
feature 168 (0.017108)
feature 55 (0.016971)
feature 145 (0.016945)
feature 14 (0.015118)
feature 171 (0.014176)
feature 381 (0.014037)
feature 174 (0.013622)
feature 151 (0.012836)
feature 152 (0.012425)
feature 209 (0.012392)
feature 77 (0.012386)
feature 56 (0.011964)
feature 394 (0.011899)
feature 24 (0.011711)
feature 207 (0.011171)
feature 3 (0.011123)
feature 131 (0.010963)
feature 160 (0.010785)
feature 135 (0.010473)
feature 188 (0.010282)
feature 122 (0.010228)
feature 78 (0.009753)
feature 58 (0.009534)
inner fold=1
accuracy=0.54347826087
feature 172 (0.036780)
feature 129 (0.025718)
feature 200 (0.023984)
feature 35 (0.020262)
feature 110 (0.018975)
feature 52 (0.017652)
feature 134 (0.017595)
feature 101 (0.015256)
feature 213 (0.014954)
feature 152 (0.014646)
feature 123 (0.012850)
feature 222 (0.012825)
feature 207 (0.012481)
feature 127 (0.012196)
feature 46 (0.011937)
feature 216 (0.011358)
feature 73 (0.011326)
feature 272 (0.011272)
feature 156 (0.011167)
feature 166 (0.010897)
feature 84 (0.010893)
feature 21 (0.010889)
feature 160 (0.010680)
feature 5 (0.010514)
feature 184 (0.010430)
feature 70 (0.010212)
feature 58 (0.010047)
feature 209 (0.010044)
feature 44 (0.009969)
feature 157 (0.009843)
inner fold=2
accuracy=0.688888888889
feature 172 (0.027271)
feature 148 (0.026930)
feature 46 (0.025366)
feature 199 (0.024919)
feature 56 (0.023714)
feature 4 (0.017620)
feature 52 (0.017077)
feature 156 (0.016698)
feature 153 (0.016475)
feature 158 (0.016024)
feature 174 (0.015986)
feature 157 (0.015979)
feature 454 (0.015659)
feature 135 (0.014436)
feature 294 (0.014088)
feature 72 (0.013057)
feature 129 (0.012602)
feature 209 (0.012264)
feature 107 (0.011763)
feature 128 (0.011572)
feature 411 (0.011517)
feature 200 (0.011073)
feature 171 (0.010814)
feature 166 (0.010715)
feature 213 (0.010571)
feature 141 (0.010180)
feature 165 (0.010133)
feature 38 (0.010115)
feature 159 (0.010100)
feature 24 (0.009946)
inner fold=3
accuracy=0.688888888889
feature 294 (0.024776)
feature 134 (0.023662)
feature 171 (0.023302)
feature 131 (0.022246)
feature 81 (0.020196)
feature 155 (0.018350)
feature 203 (0.017875)
feature 103 (0.017488)
feature 57 (0.015529)
feature 46 (0.015528)
feature 138 (0.014858)
feature 43 (0.014522)
feature 219 (0.014511)
feature 142 (0.014267)
feature 109 (0.014189)
feature 159 (0.013946)
feature 151 (0.013891)
feature 168 (0.013807)
feature 231 (0.012943)
feature 193 (0.012906)
feature 40 (0.012849)
feature 164 (0.012553)
feature 166 (0.012276)
feature 172 (0.012172)
feature 128 (0.011334)
feature 28 (0.011198)
feature 110 (0.010981)
feature 464 (0.010875)
feature 167 (0.010573)
feature 61 (0.010074)
inner fold=4
accuracy=0.666666666667
feature 101 (0.034246)
feature 97 (0.025406)
feature 294 (0.024227)
feature 174 (0.020227)
feature 42 (0.019756)
feature 208 (0.019499)
feature 139 (0.016672)
feature 46 (0.016508)
feature 83 (0.016073)
feature 12 (0.015644)
feature 157 (0.015439)
feature 18 (0.015335)
feature 132 (0.014172)
feature 184 (0.013595)
feature 173 (0.013563)
feature 214 (0.013481)
feature 159 (0.013406)
feature 81 (0.013122)
feature 44 (0.012913)
feature 80 (0.012904)
feature 104 (0.012683)
feature 231 (0.012239)
feature 99 (0.012196)
feature 137 (0.012015)
feature 56 (0.011406)
feature 133 (0.011027)
feature 136 (0.010733)
feature 58 (0.010670)
feature 33 (0.010216)
feature 55 (0.010208)
inner fold=0
accuracy=0.565217391304
feature 44 (0.039514)
feature 110 (0.029661)
feature 159 (0.028131)
feature 172 (0.023477)
feature 454 (0.022586)
feature 142 (0.021401)
feature 294 (0.021192)
feature 203 (0.019433)
feature 143 (0.019367)
feature 14 (0.018074)
feature 56 (0.016327)
feature 202 (0.014492)
feature 107 (0.013922)
feature 24 (0.013881)
feature 167 (0.013827)
feature 35 (0.013020)
feature 362 (0.012989)
feature 81 (0.012502)
feature 387 (0.012307)
feature 1 (0.011674)
feature 131 (0.011297)
feature 272 (0.011254)
feature 79 (0.011230)
feature 105 (0.011228)
feature 168 (0.011022)
feature 157 (0.011011)
feature 40 (0.010475)
feature 123 (0.010161)
feature 344 (0.010146)
feature 285 (0.009955)
inner fold=1
accuracy=0.586956521739
feature 134 (0.031798)
feature 199 (0.031681)
feature 168 (0.029701)
feature 44 (0.027560)
feature 157 (0.018484)
feature 30 (0.018109)
feature 131 (0.016827)
feature 203 (0.015703)
feature 209 (0.015513)
feature 136 (0.014245)
feature 210 (0.014096)
feature 82 (0.013783)
feature 349 (0.013753)
feature 152 (0.013727)
feature 60 (0.012445)
feature 169 (0.011741)
feature 139 (0.011510)
feature 183 (0.011301)
feature 158 (0.011127)
feature 208 (0.011060)
feature 14 (0.011000)
feature 111 (0.010895)
feature 385 (0.010845)
feature 294 (0.010465)
feature 200 (0.010253)
feature 165 (0.010072)
feature 381 (0.009955)
feature 123 (0.009954)
feature 127 (0.009755)
feature 170 (0.009130)
inner fold=2
accuracy=0.511111111111
feature 172 (0.037906)
feature 175 (0.024610)
feature 44 (0.024520)
feature 166 (0.021911)
feature 168 (0.021749)
feature 78 (0.019211)
feature 110 (0.018436)
feature 153 (0.017636)
feature 24 (0.017198)
feature 122 (0.017111)
feature 180 (0.016658)
feature 383 (0.016357)
feature 200 (0.016269)
feature 131 (0.015600)
feature 27 (0.014947)
feature 199 (0.014435)
feature 169 (0.013789)
feature 63 (0.013311)
feature 60 (0.012794)
feature 151 (0.011649)
feature 171 (0.011649)
feature 12 (0.010902)
feature 216 (0.010724)
feature 231 (0.010643)
feature 388 (0.010577)
feature 22 (0.010491)
feature 14 (0.010484)
feature 285 (0.010361)
feature 97 (0.010351)
feature 123 (0.009825)
inner fold=3
accuracy=0.6
feature 168 (0.023884)
feature 152 (0.021482)
feature 72 (0.020422)
feature 84 (0.020247)
feature 60 (0.017003)
feature 213 (0.015675)
feature 120 (0.015023)
feature 157 (0.014378)
feature 78 (0.014224)
feature 56 (0.013899)
feature 223 (0.013803)
feature 4 (0.013729)
feature 158 (0.013666)
feature 203 (0.013634)
feature 227 (0.013376)
feature 145 (0.013292)
feature 80 (0.012991)
feature 181 (0.012696)
feature 71 (0.012290)
feature 129 (0.012244)
feature 40 (0.012210)
feature 21 (0.012073)
feature 79 (0.012049)
feature 166 (0.012004)
feature 131 (0.011269)
feature 128 (0.011203)
feature 123 (0.011067)
feature 159 (0.010948)
feature 122 (0.010890)
feature 51 (0.010681)
inner fold=4
accuracy=0.622222222222

lay_id=12
feature 30 (0.030902)
feature 158 (0.027221)
feature 81 (0.024944)
feature 97 (0.020599)
feature 51 (0.019564)
feature 152 (0.018721)
feature 12 (0.016571)
feature 207 (0.015037)
feature 130 (0.014989)
feature 29 (0.014975)
feature 160 (0.014971)
feature 137 (0.014264)
feature 109 (0.013832)
feature 36 (0.013734)
feature 120 (0.013651)
feature 54 (0.013274)
feature 4 (0.013027)
feature 62 (0.013016)
feature 56 (0.012842)
feature 53 (0.012271)
feature 123 (0.012143)
feature 159 (0.011757)
feature 136 (0.011140)
feature 169 (0.010585)
feature 142 (0.010478)
feature 202 (0.010417)
feature 141 (0.010246)
feature 430 (0.010026)
feature 215 (0.009925)
feature 294 (0.009874)
inner fold=0
accuracy=0.630434782609
feature 294 (0.032854)
feature 168 (0.024916)
feature 35 (0.022479)
feature 165 (0.019445)
feature 136 (0.018716)
feature 138 (0.018461)
feature 57 (0.017972)
feature 81 (0.017179)
feature 155 (0.016753)
feature 148 (0.015227)
feature 156 (0.015138)
feature 142 (0.014707)
feature 53 (0.013744)
feature 1 (0.013722)
feature 145 (0.012985)
feature 172 (0.012969)
feature 44 (0.012937)
feature 344 (0.012539)
feature 182 (0.012519)
feature 99 (0.012216)
feature 301 (0.012166)
feature 158 (0.011957)
feature 45 (0.011926)
feature 170 (0.011649)
feature 173 (0.011586)
feature 160 (0.011568)
feature 78 (0.011371)
feature 55 (0.011258)
feature 275 (0.011248)
feature 82 (0.011091)
inner fold=1
accuracy=0.630434782609
feature 201 (0.028387)
feature 123 (0.024763)
feature 344 (0.023563)
feature 110 (0.023365)
feature 156 (0.022364)
feature 1 (0.022361)
feature 227 (0.021812)
feature 55 (0.020209)
feature 294 (0.018888)
feature 74 (0.016851)
feature 131 (0.015103)
feature 155 (0.013951)
feature 183 (0.013947)
feature 138 (0.013654)
feature 38 (0.013514)
feature 172 (0.013201)
feature 151 (0.012582)
feature 171 (0.012573)
feature 78 (0.012411)
feature 84 (0.012252)
feature 158 (0.012013)
feature 174 (0.011865)
feature 173 (0.011744)
feature 223 (0.011567)
feature 385 (0.011406)
feature 215 (0.010897)
feature 130 (0.010887)
feature 275 (0.010030)
feature 51 (0.009813)
feature 35 (0.009374)
inner fold=2
accuracy=0.622222222222
feature 168 (0.034025)
feature 110 (0.025723)
feature 166 (0.025002)
feature 131 (0.023972)
feature 79 (0.022309)
feature 464 (0.020644)
feature 137 (0.019007)
feature 173 (0.017553)
feature 199 (0.017215)
feature 272 (0.016606)
feature 53 (0.016503)
feature 78 (0.016279)
feature 44 (0.016067)
feature 188 (0.016031)
feature 122 (0.015764)
feature 161 (0.015171)
feature 385 (0.015060)
feature 125 (0.013935)
feature 52 (0.013412)
feature 12 (0.013401)
feature 133 (0.013261)
feature 123 (0.013027)
feature 129 (0.012963)
feature 203 (0.012755)
feature 50 (0.012287)
feature 84 (0.012279)
feature 148 (0.012068)
feature 159 (0.012028)
feature 27 (0.011858)
feature 60 (0.011338)
inner fold=3
accuracy=0.711111111111
feature 81 (0.039560)
feature 168 (0.034229)
feature 73 (0.025638)
feature 231 (0.023273)
feature 171 (0.021195)
feature 166 (0.019937)
feature 62 (0.016529)
feature 152 (0.016399)
feature 153 (0.016074)
feature 70 (0.015348)
feature 44 (0.014988)
feature 107 (0.014944)
feature 0 (0.014809)
feature 109 (0.013990)
feature 143 (0.013938)
feature 29 (0.013843)
feature 294 (0.013623)
feature 183 (0.013492)
feature 131 (0.012956)
feature 169 (0.012847)
feature 54 (0.012443)
feature 176 (0.012415)
feature 358 (0.012130)
feature 213 (0.012043)
feature 15 (0.011906)
feature 148 (0.011729)
feature 55 (0.011597)
feature 227 (0.011359)
feature 381 (0.011188)
feature 235 (0.011177)
inner fold=4
accuracy=0.533333333333
feature 122 (0.032893)
feature 12 (0.029724)
feature 14 (0.024652)
feature 208 (0.023816)
feature 57 (0.022331)
feature 362 (0.021393)
feature 131 (0.020925)
feature 107 (0.020510)
feature 227 (0.019763)
feature 294 (0.019247)
feature 200 (0.018264)
feature 0 (0.017850)
feature 1 (0.017792)
feature 39 (0.016915)
feature 130 (0.016328)
feature 33 (0.016309)
feature 78 (0.016149)
feature 207 (0.015932)
feature 174 (0.015877)
feature 136 (0.013951)
feature 30 (0.013300)
feature 60 (0.012962)
feature 344 (0.012805)
feature 110 (0.012577)
feature 155 (0.011968)
feature 101 (0.011625)
feature 140 (0.011326)
feature 134 (0.011163)
feature 151 (0.011037)
feature 383 (0.010497)
inner fold=0
accuracy=0.608695652174
feature 172 (0.036685)
feature 110 (0.032549)
feature 38 (0.023427)
feature 168 (0.020566)
feature 80 (0.020005)
feature 97 (0.017750)
feature 4 (0.017283)
feature 209 (0.016879)
feature 122 (0.016872)
feature 30 (0.016813)
feature 43 (0.016455)
feature 181 (0.016199)
feature 33 (0.016122)
feature 227 (0.015744)
feature 143 (0.015509)
feature 142 (0.014935)
feature 81 (0.014914)
feature 84 (0.014841)
feature 175 (0.014407)
feature 18 (0.014216)
feature 210 (0.014045)
feature 156 (0.014005)
feature 129 (0.013679)
feature 385 (0.012568)
feature 137 (0.012505)
feature 158 (0.012314)
feature 35 (0.011749)
feature 60 (0.011384)
feature 169 (0.011105)
feature 174 (0.010473)
inner fold=1
accuracy=0.695652173913
feature 14 (0.025589)
feature 172 (0.025510)
feature 272 (0.024556)
feature 207 (0.022429)
feature 102 (0.019648)
feature 349 (0.018775)
feature 55 (0.018199)
feature 135 (0.018151)
feature 344 (0.017913)
feature 167 (0.016517)
feature 30 (0.015592)
feature 131 (0.014098)
feature 155 (0.013418)
feature 464 (0.013339)
feature 63 (0.013121)
feature 181 (0.013086)
feature 101 (0.012962)
feature 138 (0.012904)
feature 46 (0.012394)
feature 34 (0.012312)
feature 62 (0.012167)
feature 208 (0.012085)
feature 81 (0.012025)
feature 163 (0.011605)
feature 152 (0.011464)
feature 294 (0.011349)
feature 223 (0.010783)
feature 29 (0.010618)
feature 202 (0.010616)
feature 84 (0.010407)
inner fold=2
accuracy=0.622222222222
feature 171 (0.034227)
feature 134 (0.028883)
feature 156 (0.026233)
feature 164 (0.024984)
feature 43 (0.021992)
feature 157 (0.021469)
feature 33 (0.021208)
feature 169 (0.020750)
feature 173 (0.020399)
feature 208 (0.017475)
feature 231 (0.016930)
feature 1 (0.016127)
feature 161 (0.015475)
feature 58 (0.014695)
feature 53 (0.014407)
feature 142 (0.014082)
feature 110 (0.013886)
feature 223 (0.013668)
feature 294 (0.013324)
feature 44 (0.013184)
feature 209 (0.012764)
feature 36 (0.012682)
feature 344 (0.012185)
feature 102 (0.011922)
feature 62 (0.011563)
feature 172 (0.011522)
feature 215 (0.010509)
feature 213 (0.010166)
feature 240 (0.010128)
feature 207 (0.010123)
inner fold=3
accuracy=0.555555555556
feature 44 (0.042699)
feature 344 (0.038778)
feature 171 (0.029120)
feature 168 (0.021974)
feature 109 (0.018969)
feature 227 (0.018578)
feature 131 (0.017972)
feature 231 (0.016396)
feature 202 (0.016039)
feature 152 (0.015585)
feature 62 (0.015327)
feature 181 (0.015148)
feature 199 (0.014982)
feature 174 (0.014278)
feature 134 (0.013911)
feature 127 (0.013715)
feature 209 (0.013652)
feature 151 (0.012860)
feature 201 (0.012725)
feature 121 (0.011543)
feature 29 (0.011264)
feature 79 (0.011040)
feature 53 (0.010842)
feature 78 (0.010803)
feature 114 (0.010671)
feature 50 (0.010392)
feature 183 (0.010302)
feature 135 (0.010209)
feature 166 (0.010098)
feature 164 (0.010075)
inner fold=4
accuracy=0.733333333333

outer fold 3
lay_id=0
feature 290 (0.046036)
feature 438 (0.023466)
feature 231 (0.021412)
feature 133 (0.018227)
feature 77 (0.017278)
feature 29 (0.016755)
feature 155 (0.016702)
feature 381 (0.016691)
feature 149 (0.016550)
feature 8 (0.016284)
feature 164 (0.015955)
feature 42 (0.015718)
feature 268 (0.014817)
feature 184 (0.014735)
feature 75 (0.014152)
feature 31 (0.013750)
feature 74 (0.013627)
feature 167 (0.013186)
feature 106 (0.012389)
feature 195 (0.012350)
feature 204 (0.012119)
feature 218 (0.012075)
feature 196 (0.011762)
feature 51 (0.011700)
feature 205 (0.011383)
feature 386 (0.011373)
feature 59 (0.011139)
feature 168 (0.011099)
feature 119 (0.010814)
feature 48 (0.010788)
inner fold=0
accuracy=0.673913043478
feature 212 (0.031784)
feature 167 (0.029959)
feature 231 (0.027827)
feature 220 (0.025281)
feature 170 (0.023450)
feature 132 (0.022046)
feature 268 (0.019255)
feature 26 (0.018863)
feature 77 (0.016341)
feature 168 (0.016245)
feature 133 (0.016097)
feature 125 (0.015323)
feature 38 (0.014248)
feature 30 (0.013497)
feature 54 (0.012814)
feature 169 (0.012755)
feature 119 (0.012632)
feature 51 (0.012500)
feature 46 (0.012483)
feature 103 (0.012450)
feature 97 (0.012358)
feature 160 (0.012101)
feature 180 (0.011941)
feature 196 (0.011926)
feature 118 (0.011589)
feature 295 (0.011270)
feature 151 (0.011126)
feature 49 (0.010961)
feature 223 (0.010857)
feature 56 (0.010699)
inner fold=1
accuracy=0.54347826087
feature 51 (0.039255)
feature 138 (0.026283)
feature 0 (0.025523)
feature 149 (0.022870)
feature 290 (0.020921)
feature 116 (0.019392)
feature 122 (0.018697)
feature 102 (0.018618)
feature 98 (0.017399)
feature 110 (0.016214)
feature 212 (0.015893)
feature 137 (0.015691)
feature 78 (0.015082)
feature 48 (0.014529)
feature 49 (0.013819)
feature 40 (0.013348)
feature 50 (0.012940)
feature 178 (0.012634)
feature 77 (0.011788)
feature 180 (0.011455)
feature 143 (0.011327)
feature 257 (0.011205)
feature 154 (0.011106)
feature 152 (0.010622)
feature 76 (0.010237)
feature 18 (0.010151)
feature 127 (0.009893)
feature 33 (0.009814)
feature 106 (0.009778)
feature 377 (0.009643)
inner fold=2
accuracy=0.6
feature 51 (0.033815)
feature 42 (0.028181)
feature 31 (0.020917)
feature 204 (0.020261)
feature 40 (0.019978)
feature 151 (0.019851)
feature 8 (0.017215)
feature 58 (0.016622)
feature 52 (0.016321)
feature 77 (0.015525)
feature 20 (0.013468)
feature 162 (0.013317)
feature 171 (0.012766)
feature 17 (0.012556)
feature 49 (0.012227)
feature 98 (0.012090)
feature 123 (0.011730)
feature 170 (0.011579)
feature 354 (0.011476)
feature 69 (0.011453)
feature 125 (0.011441)
feature 156 (0.011067)
feature 110 (0.010787)
feature 133 (0.010612)
feature 136 (0.010575)
feature 29 (0.010466)
feature 80 (0.010290)
feature 75 (0.010273)
feature 189 (0.010261)
feature 132 (0.010192)
inner fold=3
accuracy=0.622222222222
feature 26 (0.029669)
feature 132 (0.026859)
feature 169 (0.026080)
feature 51 (0.025529)
feature 74 (0.024137)
feature 25 (0.020675)
feature 231 (0.020411)
feature 377 (0.020138)
feature 77 (0.018874)
feature 103 (0.018603)
feature 125 (0.017984)
feature 144 (0.016688)
feature 147 (0.015938)
feature 42 (0.015736)
feature 210 (0.014622)
feature 205 (0.013875)
feature 38 (0.013565)
feature 54 (0.013517)
feature 381 (0.013389)
feature 138 (0.013318)
feature 408 (0.012931)
feature 290 (0.012856)
feature 161 (0.012339)
feature 204 (0.012260)
feature 340 (0.011715)
feature 212 (0.011353)
feature 168 (0.011170)
feature 95 (0.010839)
feature 227 (0.009997)
feature 157 (0.009744)
inner fold=4
accuracy=0.533333333333
feature 167 (0.027835)
feature 227 (0.026782)
feature 124 (0.024084)
feature 151 (0.023592)
feature 212 (0.022229)
feature 149 (0.021542)
feature 163 (0.017414)
feature 290 (0.017377)
feature 223 (0.016966)
feature 155 (0.016757)
feature 39 (0.016335)
feature 196 (0.016154)
feature 123 (0.016030)
feature 56 (0.015744)
feature 20 (0.014104)
feature 74 (0.013924)
feature 144 (0.013794)
feature 48 (0.012861)
feature 161 (0.012342)
feature 97 (0.011774)
feature 51 (0.011694)
feature 125 (0.011477)
feature 91 (0.011270)
feature 450 (0.011251)
feature 122 (0.011230)
feature 153 (0.011226)
feature 206 (0.011063)
feature 164 (0.010576)
feature 42 (0.010197)
feature 98 (0.010079)
inner fold=0
accuracy=0.586956521739
feature 125 (0.031638)
feature 134 (0.030482)
feature 138 (0.023673)
feature 30 (0.023335)
feature 290 (0.020925)
feature 98 (0.020259)
feature 227 (0.019263)
feature 8 (0.018270)
feature 223 (0.018101)
feature 205 (0.017624)
feature 131 (0.017517)
feature 164 (0.017306)
feature 408 (0.016613)
feature 49 (0.016130)
feature 149 (0.015521)
feature 74 (0.015421)
feature 358 (0.015172)
feature 167 (0.014618)
feature 42 (0.013592)
feature 129 (0.012669)
feature 135 (0.012185)
feature 168 (0.012134)
feature 77 (0.011928)
feature 50 (0.011582)
feature 148 (0.011358)
feature 212 (0.011202)
feature 354 (0.011165)
feature 48 (0.010846)
feature 195 (0.010768)
feature 51 (0.010582)
inner fold=1
accuracy=0.565217391304
feature 196 (0.028444)
feature 77 (0.026951)
feature 227 (0.025548)
feature 290 (0.024577)
feature 156 (0.020094)
feature 135 (0.019283)
feature 169 (0.018701)
feature 167 (0.018306)
feature 170 (0.017933)
feature 168 (0.017899)
feature 119 (0.017302)
feature 42 (0.015304)
feature 110 (0.014588)
feature 195 (0.014029)
feature 1 (0.013892)
feature 445 (0.013787)
feature 124 (0.013718)
feature 206 (0.013470)
feature 223 (0.013249)
feature 48 (0.013156)
feature 381 (0.013091)
feature 180 (0.012590)
feature 8 (0.012504)
feature 78 (0.011904)
feature 125 (0.011457)
feature 151 (0.011275)
feature 210 (0.011209)
feature 162 (0.011195)
feature 51 (0.010758)
feature 148 (0.010559)
inner fold=2
accuracy=0.622222222222
feature 42 (0.031614)
feature 290 (0.021852)
feature 54 (0.021786)
feature 126 (0.020343)
feature 167 (0.020005)
feature 96 (0.019913)
feature 134 (0.018052)
feature 199 (0.017742)
feature 100 (0.017728)
feature 97 (0.016558)
feature 127 (0.016455)
feature 47 (0.016231)
feature 51 (0.015824)
feature 157 (0.015376)
feature 66 (0.014986)
feature 169 (0.014968)
feature 119 (0.014924)
feature 130 (0.014270)
feature 178 (0.013596)
feature 227 (0.013579)
feature 34 (0.013142)
feature 164 (0.012476)
feature 40 (0.011897)
feature 58 (0.010476)
feature 163 (0.010379)
feature 69 (0.010195)
feature 131 (0.010181)
feature 218 (0.010117)
feature 26 (0.010115)
feature 150 (0.009987)
inner fold=3
accuracy=0.577777777778
feature 40 (0.043487)
feature 20 (0.029316)
feature 169 (0.028659)
feature 131 (0.028651)
feature 69 (0.026283)
feature 199 (0.025429)
feature 164 (0.023849)
feature 162 (0.020896)
feature 44 (0.019584)
feature 119 (0.019067)
feature 54 (0.018246)
feature 77 (0.016895)
feature 154 (0.016789)
feature 126 (0.015092)
feature 223 (0.014443)
feature 98 (0.013797)
feature 147 (0.013726)
feature 42 (0.013164)
feature 1 (0.013035)
feature 25 (0.011656)
feature 78 (0.010830)
feature 75 (0.010789)
feature 46 (0.010642)
feature 153 (0.010286)
feature 163 (0.010262)
feature 227 (0.010239)
feature 65 (0.009870)
feature 67 (0.009773)
feature 218 (0.009748)
feature 167 (0.009652)
inner fold=4
accuracy=0.622222222222

lay_id=1
feature 44 (0.032278)
feature 172 (0.024410)
feature 81 (0.021296)
feature 102 (0.020266)
feature 122 (0.019356)
feature 160 (0.019085)
feature 145 (0.017857)
feature 69 (0.016447)
feature 209 (0.016377)
feature 57 (0.016336)
feature 128 (0.016265)
feature 235 (0.015343)
feature 134 (0.015301)
feature 173 (0.015138)
feature 83 (0.014917)
feature 129 (0.014412)
feature 211 (0.013766)
feature 231 (0.013335)
feature 127 (0.013277)
feature 35 (0.012945)
feature 152 (0.012757)
feature 143 (0.012634)
feature 114 (0.011591)
feature 174 (0.011470)
feature 78 (0.011395)
feature 344 (0.011036)
feature 62 (0.010998)
feature 203 (0.010997)
feature 167 (0.010869)
feature 214 (0.010696)
inner fold=0
accuracy=0.565217391304
feature 131 (0.027255)
feature 99 (0.026292)
feature 181 (0.022386)
feature 46 (0.021541)
feature 231 (0.020484)
feature 52 (0.020364)
feature 128 (0.019972)
feature 163 (0.018977)
feature 81 (0.018541)
feature 57 (0.017716)
feature 122 (0.017519)
feature 51 (0.015891)
feature 126 (0.015356)
feature 167 (0.014985)
feature 153 (0.013719)
feature 71 (0.013000)
feature 165 (0.012713)
feature 107 (0.012142)
feature 48 (0.012130)
feature 80 (0.011926)
feature 157 (0.011418)
feature 17 (0.011378)
feature 105 (0.011143)
feature 35 (0.011081)
feature 381 (0.011061)
feature 201 (0.010948)
feature 12 (0.010850)
feature 156 (0.010849)
feature 56 (0.010673)
feature 151 (0.010288)
inner fold=1
accuracy=0.652173913043
feature 203 (0.027275)
feature 227 (0.027025)
feature 141 (0.023980)
feature 16 (0.023745)
feature 58 (0.021944)
feature 155 (0.019090)
feature 135 (0.018986)
feature 80 (0.018285)
feature 168 (0.016755)
feature 231 (0.016409)
feature 169 (0.016158)
feature 173 (0.016065)
feature 159 (0.015815)
feature 46 (0.015724)
feature 201 (0.015588)
feature 52 (0.015012)
feature 184 (0.014433)
feature 180 (0.014103)
feature 142 (0.013750)
feature 209 (0.012171)
feature 36 (0.011727)
feature 18 (0.011636)
feature 161 (0.011331)
feature 38 (0.010878)
feature 104 (0.010726)
feature 157 (0.010598)
feature 294 (0.010477)
feature 110 (0.009926)
feature 84 (0.009694)
feature 15 (0.009692)
inner fold=2
accuracy=0.555555555556
feature 174 (0.027141)
feature 171 (0.026621)
feature 168 (0.023984)
feature 33 (0.023692)
feature 12 (0.022809)
feature 79 (0.022793)
feature 51 (0.021126)
feature 172 (0.019885)
feature 35 (0.018225)
feature 134 (0.016501)
feature 126 (0.015903)
feature 209 (0.015413)
feature 63 (0.015093)
feature 143 (0.014928)
feature 151 (0.014794)
feature 34 (0.014304)
feature 165 (0.013975)
feature 38 (0.013893)
feature 43 (0.013753)
feature 383 (0.013094)
feature 84 (0.012943)
feature 449 (0.012892)
feature 55 (0.012808)
feature 294 (0.012656)
feature 182 (0.012334)
feature 125 (0.012304)
feature 83 (0.011662)
feature 69 (0.011525)
feature 203 (0.011322)
feature 207 (0.011285)
inner fold=3
accuracy=0.666666666667
feature 12 (0.032139)
feature 172 (0.024822)
feature 294 (0.023290)
feature 156 (0.021962)
feature 46 (0.021414)
feature 174 (0.021329)
feature 183 (0.020482)
feature 50 (0.020306)
feature 103 (0.019510)
feature 152 (0.016987)
feature 157 (0.015598)
feature 28 (0.015411)
feature 381 (0.015027)
feature 18 (0.014417)
feature 387 (0.013985)
feature 155 (0.013843)
feature 208 (0.013712)
feature 135 (0.013061)
feature 128 (0.012986)
feature 110 (0.012511)
feature 21 (0.012274)
feature 44 (0.011543)
feature 83 (0.011356)
feature 3 (0.011210)
feature 60 (0.011195)
feature 2 (0.010811)
feature 123 (0.010639)
feature 202 (0.010346)
feature 136 (0.010304)
feature 199 (0.010258)
inner fold=4
accuracy=0.511111111111
feature 12 (0.042350)
feature 160 (0.029059)
feature 222 (0.022219)
feature 389 (0.019971)
feature 171 (0.018947)
feature 69 (0.017470)
feature 227 (0.017199)
feature 381 (0.017009)
feature 81 (0.016949)
feature 102 (0.016831)
feature 143 (0.016431)
feature 395 (0.016223)
feature 82 (0.015953)
feature 42 (0.015630)
feature 44 (0.015204)
feature 199 (0.014997)
feature 120 (0.014118)
feature 105 (0.013997)
feature 231 (0.013947)
feature 41 (0.013194)
feature 168 (0.012803)
feature 122 (0.012385)
feature 18 (0.011786)
feature 294 (0.011747)
feature 165 (0.011361)
feature 148 (0.011091)
feature 442 (0.010947)
feature 30 (0.010898)
feature 55 (0.010614)
feature 28 (0.010587)
inner fold=0
accuracy=0.586956521739
feature 172 (0.034578)
feature 42 (0.027818)
feature 155 (0.025448)
feature 174 (0.024605)
feature 231 (0.023952)
feature 46 (0.021146)
feature 45 (0.018620)
feature 24 (0.016917)
feature 14 (0.016804)
feature 54 (0.016599)
feature 235 (0.016089)
feature 38 (0.015940)
feature 104 (0.015928)
feature 80 (0.015595)
feature 135 (0.014879)
feature 60 (0.014860)
feature 129 (0.013848)
feature 33 (0.013801)
feature 224 (0.013717)
feature 107 (0.013123)
feature 127 (0.012134)
feature 167 (0.012115)
feature 21 (0.011927)
feature 143 (0.011796)
feature 134 (0.011423)
feature 184 (0.011181)
feature 171 (0.010917)
feature 101 (0.010280)
feature 166 (0.010135)
feature 78 (0.010114)
inner fold=1
accuracy=0.652173913043
feature 81 (0.039906)
feature 44 (0.027160)
feature 139 (0.024568)
feature 131 (0.022150)
feature 78 (0.021330)
feature 79 (0.020880)
feature 18 (0.020424)
feature 53 (0.018844)
feature 201 (0.018672)
feature 114 (0.018662)
feature 151 (0.017101)
feature 156 (0.017067)
feature 128 (0.015731)
feature 135 (0.015375)
feature 133 (0.014459)
feature 1 (0.013820)
feature 84 (0.013461)
feature 185 (0.013280)
feature 126 (0.012947)
feature 115 (0.012693)
feature 235 (0.012565)
feature 4 (0.012558)
feature 223 (0.012505)
feature 138 (0.012357)
feature 69 (0.011944)
feature 188 (0.011692)
feature 184 (0.011416)
feature 57 (0.011060)
feature 182 (0.010946)
feature 74 (0.010917)
inner fold=2
accuracy=0.555555555556
feature 55 (0.029542)
feature 12 (0.027081)
feature 155 (0.022890)
feature 172 (0.022298)
feature 77 (0.021904)
feature 81 (0.021176)
feature 166 (0.020932)
feature 101 (0.019120)
feature 52 (0.017276)
feature 14 (0.016294)
feature 127 (0.015751)
feature 235 (0.015307)
feature 110 (0.015036)
feature 97 (0.014754)
feature 188 (0.014097)
feature 78 (0.014096)
feature 171 (0.013743)
feature 102 (0.012718)
feature 122 (0.012044)
feature 46 (0.011871)
feature 167 (0.011525)
feature 36 (0.011379)
feature 53 (0.011316)
feature 164 (0.010908)
feature 168 (0.010680)
feature 90 (0.010358)
feature 68 (0.010197)
feature 165 (0.009973)
feature 50 (0.009938)
feature 131 (0.009610)
inner fold=3
accuracy=0.644444444444
feature 172 (0.032481)
feature 142 (0.022604)
feature 166 (0.022433)
feature 152 (0.021195)
feature 156 (0.020700)
feature 227 (0.018628)
feature 58 (0.017069)
feature 127 (0.016377)
feature 110 (0.016304)
feature 45 (0.015406)
feature 1 (0.015031)
feature 40 (0.014928)
feature 46 (0.014419)
feature 200 (0.014141)
feature 17 (0.013836)
feature 134 (0.013246)
feature 151 (0.013182)
feature 207 (0.013171)
feature 135 (0.012579)
feature 36 (0.012246)
feature 138 (0.012209)
feature 60 (0.011914)
feature 211 (0.011905)
feature 148 (0.011715)
feature 272 (0.011460)
feature 146 (0.011151)
feature 12 (0.010912)
feature 33 (0.010875)
feature 126 (0.010616)
feature 210 (0.010588)
inner fold=4
accuracy=0.622222222222

lay_id=2
feature 275 (0.026340)
feature 136 (0.022866)
feature 211 (0.021343)
feature 184 (0.019174)
feature 43 (0.019136)
feature 158 (0.018642)
feature 166 (0.017536)
feature 126 (0.017389)
feature 123 (0.017088)
feature 362 (0.017052)
feature 152 (0.016789)
feature 80 (0.015951)
feature 145 (0.015803)
feature 129 (0.015687)
feature 139 (0.015578)
feature 44 (0.014284)
feature 39 (0.013826)
feature 164 (0.012483)
feature 174 (0.012449)
feature 30 (0.011903)
feature 227 (0.011886)
feature 135 (0.011341)
feature 127 (0.010903)
feature 165 (0.010769)
feature 134 (0.010601)
feature 55 (0.010486)
feature 157 (0.010255)
feature 181 (0.010245)
feature 83 (0.010216)
feature 21 (0.010146)
inner fold=0
accuracy=0.652173913043
feature 81 (0.037628)
feature 136 (0.036262)
feature 172 (0.025018)
feature 46 (0.023228)
feature 171 (0.020323)
feature 3 (0.019721)
feature 84 (0.019355)
feature 14 (0.019282)
feature 62 (0.016081)
feature 129 (0.015658)
feature 160 (0.015216)
feature 167 (0.013685)
feature 120 (0.012665)
feature 38 (0.012427)
feature 54 (0.012231)
feature 70 (0.012219)
feature 156 (0.011480)
feature 358 (0.011259)
feature 125 (0.011087)
feature 202 (0.010887)
feature 151 (0.010747)
feature 27 (0.010547)
feature 127 (0.010518)
feature 208 (0.010393)
feature 158 (0.010367)
feature 209 (0.010249)
feature 139 (0.010209)
feature 115 (0.010190)
feature 224 (0.009507)
feature 114 (0.009496)
inner fold=1
accuracy=0.565217391304
feature 153 (0.034676)
feature 38 (0.025370)
feature 176 (0.022431)
feature 55 (0.018554)
feature 126 (0.018444)
feature 30 (0.017354)
feature 174 (0.017240)
feature 157 (0.016921)
feature 77 (0.016609)
feature 183 (0.015715)
feature 12 (0.015076)
feature 208 (0.014593)
feature 148 (0.013077)
feature 97 (0.012863)
feature 110 (0.012807)
feature 14 (0.012779)
feature 227 (0.012430)
feature 131 (0.012348)
feature 395 (0.012112)
feature 165 (0.011301)
feature 134 (0.011239)
feature 184 (0.010984)
feature 3 (0.010960)
feature 56 (0.010918)
feature 172 (0.010575)
feature 138 (0.010405)
feature 143 (0.010399)
feature 160 (0.010281)
feature 140 (0.009910)
feature 216 (0.009857)
inner fold=2
accuracy=0.622222222222
feature 30 (0.024678)
feature 362 (0.023816)
feature 29 (0.023296)
feature 101 (0.022814)
feature 110 (0.021600)
feature 123 (0.020043)
feature 199 (0.018465)
feature 55 (0.017149)
feature 168 (0.014453)
feature 46 (0.014110)
feature 130 (0.013074)
feature 148 (0.013007)
feature 41 (0.012823)
feature 249 (0.012784)
feature 4 (0.012372)
feature 138 (0.012147)
feature 151 (0.011922)
feature 164 (0.011856)
feature 129 (0.011603)
feature 155 (0.011394)
feature 73 (0.011333)
feature 44 (0.011254)
feature 56 (0.011238)
feature 120 (0.010971)
feature 95 (0.010656)
feature 141 (0.010355)
feature 167 (0.010228)
feature 38 (0.010128)
feature 211 (0.010070)
feature 100 (0.009971)
inner fold=3
accuracy=0.622222222222
feature 81 (0.029017)
feature 106 (0.025364)
feature 362 (0.025008)
feature 169 (0.022046)
feature 110 (0.020606)
feature 184 (0.019970)
feature 44 (0.019796)
feature 122 (0.018006)
feature 134 (0.017920)
feature 199 (0.017914)
feature 231 (0.017676)
feature 203 (0.017259)
feature 12 (0.016847)
feature 56 (0.016724)
feature 222 (0.016715)
feature 182 (0.016638)
feature 125 (0.016436)
feature 52 (0.016109)
feature 46 (0.015135)
feature 38 (0.015019)
feature 128 (0.014497)
feature 107 (0.014393)
feature 136 (0.014154)
feature 82 (0.013893)
feature 109 (0.011927)
feature 3 (0.011418)
feature 442 (0.011324)
feature 18 (0.011197)
feature 78 (0.011052)
feature 43 (0.010880)
inner fold=4
accuracy=0.6
feature 203 (0.033687)
feature 157 (0.033562)
feature 151 (0.026193)
feature 97 (0.024218)
feature 272 (0.022264)
feature 172 (0.021659)
feature 44 (0.020758)
feature 22 (0.015698)
feature 123 (0.015409)
feature 42 (0.014236)
feature 58 (0.013831)
feature 208 (0.013509)
feature 213 (0.012822)
feature 173 (0.012796)
feature 35 (0.012440)
feature 294 (0.012401)
feature 216 (0.011314)
feature 24 (0.011124)
feature 443 (0.010964)
feature 12 (0.010872)
feature 152 (0.010756)
feature 55 (0.010665)
feature 115 (0.010653)
feature 104 (0.010562)
feature 138 (0.010411)
feature 156 (0.010192)
feature 74 (0.010011)
feature 181 (0.009860)
feature 349 (0.009704)
feature 40 (0.009565)
inner fold=0
accuracy=0.565217391304
feature 155 (0.022277)
feature 129 (0.020360)
feature 24 (0.019631)
feature 12 (0.017915)
feature 156 (0.017798)
feature 216 (0.017521)
feature 123 (0.017279)
feature 454 (0.017269)
feature 412 (0.016163)
feature 153 (0.015676)
feature 222 (0.015555)
feature 81 (0.015539)
feature 114 (0.014812)
feature 14 (0.014732)
feature 139 (0.014325)
feature 51 (0.013438)
feature 100 (0.013283)
feature 235 (0.013122)
feature 208 (0.012692)
feature 165 (0.012514)
feature 344 (0.012352)
feature 21 (0.012137)
feature 174 (0.011941)
feature 71 (0.011907)
feature 44 (0.011609)
feature 142 (0.011566)
feature 215 (0.011241)
feature 203 (0.011136)
feature 209 (0.011051)
feature 210 (0.010890)
inner fold=1
accuracy=0.630434782609
feature 129 (0.031770)
feature 171 (0.028848)
feature 173 (0.024607)
feature 53 (0.022309)
feature 203 (0.021188)
feature 141 (0.020787)
feature 136 (0.019065)
feature 152 (0.017705)
feature 122 (0.016813)
feature 172 (0.016573)
feature 123 (0.015970)
feature 227 (0.014991)
feature 2 (0.014779)
feature 77 (0.014211)
feature 34 (0.014028)
feature 46 (0.013577)
feature 210 (0.013540)
feature 216 (0.013307)
feature 209 (0.013196)
feature 165 (0.012876)
feature 50 (0.012740)
feature 155 (0.012723)
feature 167 (0.012118)
feature 235 (0.011933)
feature 70 (0.011865)
feature 184 (0.011008)
feature 29 (0.010736)
feature 156 (0.010721)
feature 231 (0.010524)
feature 199 (0.010427)
inner fold=2
accuracy=0.6
feature 42 (0.025336)
feature 80 (0.022499)
feature 153 (0.022414)
feature 294 (0.021666)
feature 44 (0.020934)
feature 203 (0.020342)
feature 12 (0.019650)
feature 24 (0.018391)
feature 148 (0.017698)
feature 199 (0.017217)
feature 114 (0.014383)
feature 207 (0.013987)
feature 142 (0.013698)
feature 110 (0.013359)
feature 127 (0.013249)
feature 36 (0.013175)
feature 143 (0.013173)
feature 79 (0.013092)
feature 231 (0.012979)
feature 137 (0.012343)
feature 136 (0.012159)
feature 103 (0.011422)
feature 14 (0.011109)
feature 390 (0.011079)
feature 235 (0.011057)
feature 167 (0.010648)
feature 121 (0.010455)
feature 58 (0.010429)
feature 408 (0.010376)
feature 62 (0.010311)
inner fold=3
accuracy=0.6
feature 81 (0.027704)
feature 136 (0.027642)
feature 171 (0.026323)
feature 97 (0.019847)
feature 134 (0.018977)
feature 157 (0.018260)
feature 110 (0.017128)
feature 216 (0.016878)
feature 63 (0.015531)
feature 12 (0.014201)
feature 344 (0.014197)
feature 3 (0.014164)
feature 60 (0.014072)
feature 294 (0.013904)
feature 2 (0.013222)
feature 285 (0.013059)
feature 109 (0.012481)
feature 442 (0.012249)
feature 202 (0.012147)
feature 55 (0.011481)
feature 143 (0.011228)
feature 101 (0.011115)
feature 167 (0.010917)
feature 126 (0.010892)
feature 207 (0.010562)
feature 369 (0.010395)
feature 214 (0.010355)
feature 33 (0.010082)
feature 235 (0.009934)
feature 95 (0.009888)
inner fold=4
accuracy=0.644444444444

lay_id=3
feature 172 (0.037127)
feature 135 (0.033202)
feature 78 (0.025459)
feature 166 (0.024822)
feature 99 (0.018736)
feature 56 (0.017716)
feature 155 (0.017120)
feature 81 (0.015812)
feature 82 (0.015786)
feature 168 (0.015708)
feature 209 (0.015178)
feature 130 (0.014844)
feature 129 (0.014331)
feature 97 (0.013755)
feature 156 (0.013701)
feature 148 (0.013679)
feature 3 (0.013596)
feature 175 (0.012965)
feature 157 (0.012478)
feature 389 (0.012372)
feature 107 (0.012221)
feature 74 (0.011780)
feature 4 (0.011654)
feature 80 (0.011053)
feature 104 (0.010932)
feature 385 (0.010218)
feature 44 (0.009963)
feature 71 (0.009871)
feature 103 (0.009567)
feature 48 (0.009459)
inner fold=0
accuracy=0.695652173913
feature 156 (0.024185)
feature 231 (0.023380)
feature 81 (0.023203)
feature 135 (0.022424)
feature 172 (0.021699)
feature 173 (0.019571)
feature 171 (0.018390)
feature 84 (0.015971)
feature 99 (0.015538)
feature 104 (0.015261)
feature 68 (0.015018)
feature 105 (0.014547)
feature 101 (0.014331)
feature 213 (0.013908)
feature 127 (0.013862)
feature 37 (0.013452)
feature 207 (0.013106)
feature 152 (0.013037)
feature 50 (0.012815)
feature 126 (0.012107)
feature 153 (0.011814)
feature 227 (0.011811)
feature 85 (0.010987)
feature 223 (0.010821)
feature 235 (0.010816)
feature 164 (0.010596)
feature 123 (0.010123)
feature 71 (0.010118)
feature 174 (0.010096)
feature 56 (0.009865)
inner fold=1
accuracy=0.5
feature 14 (0.036040)
feature 294 (0.025850)
feature 81 (0.024668)
feature 166 (0.024080)
feature 131 (0.022566)
feature 215 (0.021454)
feature 153 (0.020896)
feature 158 (0.019467)
feature 55 (0.019302)
feature 110 (0.016870)
feature 235 (0.016179)
feature 57 (0.015359)
feature 165 (0.015269)
feature 84 (0.014822)
feature 121 (0.014389)
feature 172 (0.013955)
feature 344 (0.013837)
feature 203 (0.013457)
feature 156 (0.013289)
feature 157 (0.013172)
feature 138 (0.012445)
feature 51 (0.012354)
feature 53 (0.012008)
feature 4 (0.011979)
feature 128 (0.011929)
feature 231 (0.011921)
feature 159 (0.011552)
feature 38 (0.011484)
feature 208 (0.011005)
feature 151 (0.010999)
inner fold=2
accuracy=0.533333333333
feature 175 (0.020616)
feature 395 (0.019387)
feature 166 (0.018538)
feature 29 (0.018433)
feature 201 (0.018086)
feature 8 (0.017802)
feature 26 (0.017449)
feature 156 (0.016463)
feature 231 (0.016369)
feature 138 (0.016088)
feature 385 (0.016045)
feature 235 (0.015316)
feature 174 (0.014591)
feature 78 (0.014086)
feature 12 (0.014060)
feature 42 (0.013844)
feature 69 (0.013310)
feature 33 (0.013243)
feature 114 (0.012674)
feature 30 (0.012502)
feature 412 (0.012411)
feature 62 (0.012309)
feature 104 (0.011978)
feature 173 (0.011847)
feature 58 (0.011120)
feature 157 (0.011053)
feature 188 (0.010904)
feature 130 (0.010691)
feature 151 (0.010452)
feature 4 (0.010355)
inner fold=3
accuracy=0.511111111111
feature 151 (0.030595)
feature 127 (0.026831)
feature 175 (0.023072)
feature 215 (0.022022)
feature 152 (0.020568)
feature 46 (0.019549)
feature 216 (0.018999)
feature 158 (0.018898)
feature 79 (0.018154)
feature 81 (0.018027)
feature 24 (0.017690)
feature 222 (0.017636)
feature 78 (0.017335)
feature 235 (0.016152)
feature 5 (0.014627)
feature 159 (0.014539)
feature 165 (0.014167)
feature 71 (0.013265)
feature 38 (0.012271)
feature 223 (0.012177)
feature 104 (0.012022)
feature 12 (0.011962)
feature 60 (0.011690)
feature 0 (0.011330)
feature 74 (0.011202)
feature 164 (0.010943)
feature 213 (0.010685)
feature 172 (0.010580)
feature 454 (0.010569)
feature 155 (0.010559)
inner fold=4
accuracy=0.577777777778
feature 138 (0.037633)
feature 14 (0.026535)
feature 78 (0.024327)
feature 294 (0.023732)
feature 227 (0.023081)
feature 70 (0.021737)
feature 157 (0.021433)
feature 385 (0.020348)
feature 15 (0.020003)
feature 84 (0.018088)
feature 153 (0.018031)
feature 164 (0.016384)
feature 136 (0.015987)
feature 104 (0.015956)
feature 24 (0.015198)
feature 109 (0.015029)
feature 200 (0.014736)
feature 114 (0.014320)
feature 115 (0.014227)
feature 166 (0.013394)
feature 40 (0.013226)
feature 272 (0.013147)
feature 71 (0.012378)
feature 30 (0.010777)
feature 29 (0.010772)
feature 8 (0.010060)
feature 101 (0.009918)
feature 224 (0.009859)
feature 39 (0.009787)
feature 194 (0.009564)
inner fold=0
accuracy=0.54347826087
feature 129 (0.051465)
feature 390 (0.029666)
feature 101 (0.028530)
feature 135 (0.023444)
feature 231 (0.021541)
feature 77 (0.020425)
feature 211 (0.020206)
feature 168 (0.019185)
feature 158 (0.018575)
feature 1 (0.018368)
feature 161 (0.018157)
feature 175 (0.017297)
feature 78 (0.016249)
feature 12 (0.016141)
feature 152 (0.015534)
feature 3 (0.015067)
feature 107 (0.014833)
feature 172 (0.014697)
feature 54 (0.014628)
feature 110 (0.014522)
feature 160 (0.014058)
feature 215 (0.013380)
feature 4 (0.012722)
feature 125 (0.011332)
feature 235 (0.011331)
feature 80 (0.011235)
feature 199 (0.011109)
feature 156 (0.011018)
feature 202 (0.010746)
feature 69 (0.010389)
inner fold=1
accuracy=0.630434782609
feature 81 (0.031250)
feature 172 (0.027500)
feature 173 (0.026481)
feature 201 (0.018894)
feature 275 (0.018258)
feature 115 (0.018016)
feature 84 (0.017635)
feature 126 (0.017466)
feature 120 (0.016555)
feature 52 (0.016431)
feature 362 (0.015948)
feature 175 (0.015529)
feature 272 (0.015005)
feature 14 (0.014983)
feature 44 (0.014934)
feature 227 (0.014499)
feature 53 (0.012897)
feature 71 (0.012231)
feature 131 (0.012102)
feature 77 (0.012089)
feature 60 (0.011591)
feature 3 (0.011285)
feature 158 (0.011254)
feature 142 (0.011062)
feature 159 (0.010997)
feature 38 (0.010974)
feature 50 (0.010964)
feature 344 (0.010850)
feature 99 (0.010648)
feature 114 (0.010199)
inner fold=2
accuracy=0.755555555556
feature 235 (0.031861)
feature 129 (0.024179)
feature 81 (0.022183)
feature 272 (0.020566)
feature 137 (0.020529)
feature 184 (0.019004)
feature 138 (0.018056)
feature 211 (0.018056)
feature 168 (0.017634)
feature 123 (0.017435)
feature 172 (0.016533)
feature 134 (0.015478)
feature 110 (0.015197)
feature 52 (0.013349)
feature 163 (0.012864)
feature 60 (0.012082)
feature 142 (0.011873)
feature 385 (0.011654)
feature 215 (0.011653)
feature 82 (0.011630)
feature 28 (0.011373)
feature 201 (0.011366)
feature 294 (0.010863)
feature 108 (0.010471)
feature 202 (0.010458)
feature 213 (0.010442)
feature 182 (0.010052)
feature 54 (0.010036)
feature 3 (0.009946)
feature 188 (0.009945)
inner fold=3
accuracy=0.644444444444
feature 80 (0.032217)
feature 172 (0.028028)
feature 158 (0.027648)
feature 101 (0.026596)
feature 44 (0.020920)
feature 134 (0.019705)
feature 129 (0.017953)
feature 24 (0.017778)
feature 102 (0.017622)
feature 196 (0.017312)
feature 84 (0.017262)
feature 135 (0.017228)
feature 109 (0.016984)
feature 35 (0.016644)
feature 139 (0.016364)
feature 168 (0.015317)
feature 155 (0.012849)
feature 151 (0.011810)
feature 46 (0.011745)
feature 344 (0.011716)
feature 396 (0.011602)
feature 283 (0.011040)
feature 385 (0.010989)
feature 214 (0.010917)
feature 182 (0.010848)
feature 56 (0.010721)
feature 141 (0.010402)
feature 157 (0.009990)
feature 79 (0.009711)
feature 14 (0.009554)
inner fold=4
accuracy=0.6

lay_id=4
feature 390 (0.028912)
feature 104 (0.027883)
feature 81 (0.024961)
feature 50 (0.024910)
feature 294 (0.023748)
feature 222 (0.019976)
feature 114 (0.019747)
feature 152 (0.018465)
feature 55 (0.018255)
feature 78 (0.016792)
feature 153 (0.016517)
feature 101 (0.016473)
feature 157 (0.016400)
feature 167 (0.014610)
feature 159 (0.014116)
feature 173 (0.013153)
feature 203 (0.012884)
feature 187 (0.012599)
feature 247 (0.012102)
feature 38 (0.011948)
feature 142 (0.011734)
feature 131 (0.011367)
feature 349 (0.011364)
feature 2 (0.011314)
feature 35 (0.011128)
feature 109 (0.011088)
feature 138 (0.010955)
feature 168 (0.010504)
feature 46 (0.010211)
feature 21 (0.010113)
inner fold=0
accuracy=0.54347826087
feature 81 (0.027415)
feature 57 (0.026219)
feature 42 (0.026089)
feature 114 (0.020972)
feature 122 (0.020635)
feature 103 (0.020114)
feature 294 (0.019564)
feature 175 (0.017869)
feature 412 (0.016809)
feature 148 (0.016297)
feature 52 (0.016104)
feature 33 (0.014511)
feature 54 (0.013956)
feature 35 (0.013788)
feature 110 (0.013570)
feature 125 (0.013204)
feature 203 (0.012827)
feature 4 (0.012824)
feature 60 (0.012763)
feature 136 (0.012681)
feature 164 (0.012624)
feature 78 (0.011761)
feature 99 (0.011511)
feature 138 (0.011236)
feature 159 (0.011171)
feature 46 (0.010773)
feature 171 (0.010714)
feature 115 (0.010628)
feature 385 (0.010492)
feature 153 (0.010472)
inner fold=1
accuracy=0.695652173913
feature 81 (0.024012)
feature 199 (0.020419)
feature 138 (0.018254)
feature 122 (0.017255)
feature 33 (0.017026)
feature 126 (0.016476)
feature 35 (0.016090)
feature 110 (0.015985)
feature 301 (0.015948)
feature 130 (0.015325)
feature 52 (0.015032)
feature 131 (0.015017)
feature 215 (0.014891)
feature 235 (0.013819)
feature 172 (0.013806)
feature 182 (0.013510)
feature 58 (0.013479)
feature 55 (0.013052)
feature 34 (0.013016)
feature 114 (0.012881)
feature 208 (0.012809)
feature 168 (0.012234)
feature 107 (0.012175)
feature 152 (0.011964)
feature 16 (0.011632)
feature 143 (0.011256)
feature 70 (0.011067)
feature 151 (0.010708)
feature 14 (0.010704)
feature 48 (0.010548)
inner fold=2
accuracy=0.6
feature 120 (0.036035)
feature 152 (0.032712)
feature 168 (0.025271)
feature 43 (0.024429)
feature 358 (0.021999)
feature 175 (0.021194)
feature 81 (0.018304)
feature 142 (0.018046)
feature 138 (0.017176)
feature 157 (0.016706)
feature 135 (0.015751)
feature 211 (0.015652)
feature 172 (0.015518)
feature 235 (0.015185)
feature 123 (0.014992)
feature 194 (0.014327)
feature 50 (0.014237)
feature 134 (0.014132)
feature 114 (0.014007)
feature 272 (0.013744)
feature 141 (0.013324)
feature 122 (0.012906)
feature 44 (0.012766)
feature 153 (0.012139)
feature 164 (0.012080)
feature 48 (0.011852)
feature 129 (0.011756)
feature 156 (0.011240)
feature 167 (0.010936)
feature 46 (0.010840)
inner fold=3
accuracy=0.511111111111
feature 171 (0.028005)
feature 134 (0.024985)
feature 123 (0.023965)
feature 102 (0.022525)
feature 181 (0.018737)
feature 151 (0.018413)
feature 138 (0.018173)
feature 101 (0.018172)
feature 43 (0.018038)
feature 33 (0.016259)
feature 208 (0.015910)
feature 81 (0.015529)
feature 454 (0.015328)
feature 115 (0.014604)
feature 135 (0.014557)
feature 174 (0.014484)
feature 155 (0.013178)
feature 12 (0.013137)
feature 48 (0.012863)
feature 68 (0.012424)
feature 131 (0.012366)
feature 126 (0.012086)
feature 166 (0.011515)
feature 139 (0.011486)
feature 46 (0.011466)
feature 70 (0.010883)
feature 147 (0.010876)
feature 336 (0.010719)
feature 142 (0.010668)
feature 168 (0.010525)
inner fold=4
accuracy=0.666666666667
feature 166 (0.036582)
feature 14 (0.024949)
feature 12 (0.023800)
feature 34 (0.022345)
feature 131 (0.022163)
feature 101 (0.021570)
feature 155 (0.019662)
feature 160 (0.018169)
feature 109 (0.015157)
feature 69 (0.014943)
feature 202 (0.014789)
feature 134 (0.014501)
feature 78 (0.014173)
feature 213 (0.014079)
feature 153 (0.013460)
feature 103 (0.012973)
feature 110 (0.012361)
feature 24 (0.011452)
feature 61 (0.011245)
feature 5 (0.011135)
feature 172 (0.010705)
feature 184 (0.010676)
feature 223 (0.010644)
feature 122 (0.010637)
feature 48 (0.010556)
feature 188 (0.010446)
feature 183 (0.010254)
feature 138 (0.009892)
feature 54 (0.009721)
feature 115 (0.009645)
inner fold=0
accuracy=0.565217391304
feature 12 (0.037868)
feature 81 (0.026114)
feature 181 (0.024609)
feature 344 (0.023551)
feature 44 (0.020794)
feature 222 (0.020712)
feature 34 (0.018145)
feature 107 (0.017259)
feature 174 (0.017243)
feature 55 (0.016855)
feature 153 (0.016473)
feature 235 (0.016293)
feature 57 (0.015629)
feature 157 (0.015376)
feature 131 (0.015202)
feature 24 (0.014936)
feature 46 (0.014666)
feature 156 (0.013968)
feature 151 (0.013907)
feature 80 (0.012200)
feature 114 (0.011992)
feature 164 (0.011683)
feature 101 (0.011491)
feature 110 (0.011225)
feature 143 (0.010888)
feature 454 (0.010887)
feature 170 (0.010789)
feature 123 (0.010718)
feature 227 (0.010520)
feature 138 (0.010406)
inner fold=1
accuracy=0.54347826087
feature 159 (0.031045)
feature 156 (0.019869)
feature 184 (0.019797)
feature 29 (0.019302)
feature 213 (0.018242)
feature 153 (0.016125)
feature 294 (0.015547)
feature 70 (0.015246)
feature 129 (0.014404)
feature 125 (0.014344)
feature 79 (0.013546)
feature 134 (0.013237)
feature 172 (0.013166)
feature 222 (0.013063)
feature 170 (0.013054)
feature 82 (0.012948)
feature 216 (0.012946)
feature 34 (0.012630)
feature 161 (0.012208)
feature 148 (0.011902)
feature 127 (0.011809)
feature 105 (0.011670)
feature 165 (0.011606)
feature 144 (0.011575)
feature 18 (0.011553)
feature 110 (0.011483)
feature 207 (0.011464)
feature 166 (0.011368)
feature 81 (0.011212)
feature 84 (0.010895)
inner fold=2
accuracy=0.711111111111
feature 159 (0.034464)
feature 171 (0.027751)
feature 207 (0.024423)
feature 101 (0.023179)
feature 153 (0.023150)
feature 174 (0.021294)
feature 202 (0.019888)
feature 56 (0.018965)
feature 46 (0.018751)
feature 235 (0.017471)
feature 24 (0.016999)
feature 34 (0.016333)
feature 104 (0.015484)
feature 184 (0.015430)
feature 81 (0.014851)
feature 97 (0.014428)
feature 160 (0.013939)
feature 395 (0.012413)
feature 122 (0.012141)
feature 139 (0.012072)
feature 449 (0.011744)
feature 42 (0.011553)
feature 115 (0.011168)
feature 164 (0.010989)
feature 103 (0.010882)
feature 131 (0.010698)
feature 344 (0.010207)
feature 114 (0.009964)
feature 442 (0.009912)
feature 105 (0.009804)
inner fold=3
accuracy=0.6
feature 81 (0.034966)
feature 46 (0.026309)
feature 56 (0.024376)
feature 203 (0.022983)
feature 227 (0.021744)
feature 110 (0.020319)
feature 159 (0.020281)
feature 77 (0.019537)
feature 156 (0.018996)
feature 78 (0.017259)
feature 14 (0.017016)
feature 114 (0.015964)
feature 148 (0.014861)
feature 160 (0.014825)
feature 79 (0.014119)
feature 213 (0.014034)
feature 294 (0.013318)
feature 155 (0.013218)
feature 166 (0.012772)
feature 53 (0.012494)
feature 164 (0.012166)
feature 174 (0.012129)
feature 130 (0.011920)
feature 102 (0.011792)
feature 173 (0.011173)
feature 128 (0.010997)
feature 142 (0.010927)
feature 139 (0.010816)
feature 129 (0.010676)
feature 141 (0.010584)
inner fold=4
accuracy=0.533333333333

outer fold 4
lay_id=0
feature 290 (0.029567)
feature 51 (0.025463)
feature 164 (0.024370)
feature 31 (0.018250)
feature 131 (0.017114)
feature 340 (0.015122)
feature 160 (0.014916)
feature 211 (0.014627)
feature 49 (0.014445)
feature 103 (0.014406)
feature 130 (0.014375)
feature 148 (0.014334)
feature 138 (0.014078)
feature 161 (0.014037)
feature 101 (0.013666)
feature 121 (0.013280)
feature 223 (0.013278)
feature 207 (0.013259)
feature 8 (0.013244)
feature 297 (0.013167)
feature 102 (0.012847)
feature 26 (0.012776)
feature 381 (0.012510)
feature 77 (0.012420)
feature 168 (0.011997)
feature 30 (0.011989)
feature 98 (0.011902)
feature 118 (0.011608)
feature 227 (0.011395)
feature 137 (0.011239)
inner fold=0
accuracy=0.630434782609
feature 54 (0.029738)
feature 227 (0.023063)
feature 80 (0.022826)
feature 149 (0.022044)
feature 268 (0.021451)
feature 53 (0.019634)
feature 74 (0.019279)
feature 38 (0.018877)
feature 117 (0.018472)
feature 97 (0.017216)
feature 133 (0.017101)
feature 168 (0.016964)
feature 223 (0.016794)
feature 138 (0.015143)
feature 48 (0.015031)
feature 42 (0.014759)
feature 116 (0.013608)
feature 125 (0.012669)
feature 271 (0.012333)
feature 77 (0.012225)
feature 151 (0.012011)
feature 197 (0.011077)
feature 56 (0.011061)
feature 122 (0.010790)
feature 155 (0.010660)
feature 75 (0.010323)
feature 212 (0.010312)
feature 136 (0.010304)
feature 4 (0.010073)
feature 17 (0.009968)
inner fold=1
accuracy=0.608695652174
feature 106 (0.033315)
feature 290 (0.028533)
feature 100 (0.026080)
feature 73 (0.025902)
feature 138 (0.023840)
feature 42 (0.020634)
feature 51 (0.020176)
feature 13 (0.020094)
feature 171 (0.017492)
feature 116 (0.016618)
feature 209 (0.016517)
feature 127 (0.014777)
feature 52 (0.014726)
feature 119 (0.014684)
feature 139 (0.014651)
feature 170 (0.014319)
feature 54 (0.014195)
feature 268 (0.014097)
feature 130 (0.013856)
feature 206 (0.012879)
feature 79 (0.012455)
feature 408 (0.012409)
feature 381 (0.012126)
feature 223 (0.011955)
feature 145 (0.011738)
feature 157 (0.011032)
feature 20 (0.011028)
feature 151 (0.010917)
feature 77 (0.010707)
feature 11 (0.010517)
inner fold=2
accuracy=0.6
feature 227 (0.024611)
feature 171 (0.024023)
feature 138 (0.022550)
feature 31 (0.018136)
feature 25 (0.017994)
feature 169 (0.016987)
feature 354 (0.016461)
feature 152 (0.016455)
feature 439 (0.015784)
feature 137 (0.015439)
feature 14 (0.015353)
feature 180 (0.015255)
feature 77 (0.014241)
feature 40 (0.013922)
feature 39 (0.013610)
feature 111 (0.012862)
feature 131 (0.012363)
feature 336 (0.012076)
feature 407 (0.011938)
feature 75 (0.011609)
feature 167 (0.011068)
feature 170 (0.011038)
feature 41 (0.010961)
feature 154 (0.010900)
feature 153 (0.010899)
feature 48 (0.010638)
feature 155 (0.010540)
feature 105 (0.010530)
feature 128 (0.010355)
feature 127 (0.010214)
inner fold=3
accuracy=0.666666666667
feature 119 (0.035617)
feature 46 (0.027994)
feature 125 (0.023551)
feature 132 (0.023351)
feature 26 (0.022944)
feature 223 (0.020467)
feature 167 (0.019770)
feature 377 (0.018745)
feature 151 (0.017706)
feature 130 (0.016276)
feature 212 (0.015917)
feature 290 (0.015014)
feature 30 (0.014641)
feature 134 (0.014348)
feature 42 (0.014339)
feature 131 (0.014142)
feature 138 (0.014068)
feature 51 (0.013942)
feature 218 (0.013664)
feature 141 (0.012617)
feature 53 (0.012419)
feature 209 (0.011767)
feature 170 (0.011631)
feature 381 (0.011506)
feature 78 (0.011454)
feature 0 (0.011255)
feature 204 (0.011253)
feature 121 (0.011016)
feature 104 (0.010833)
feature 164 (0.010809)
inner fold=4
accuracy=0.644444444444
feature 164 (0.050308)
feature 290 (0.026866)
feature 132 (0.022948)
feature 54 (0.022137)
feature 167 (0.021220)
feature 155 (0.019172)
feature 169 (0.018519)
feature 196 (0.018276)
feature 209 (0.016974)
feature 195 (0.016598)
feature 125 (0.016329)
feature 38 (0.016164)
feature 170 (0.015041)
feature 34 (0.014966)
feature 123 (0.014241)
feature 205 (0.013889)
feature 227 (0.013535)
feature 22 (0.013330)
feature 138 (0.013128)
feature 268 (0.013053)
feature 231 (0.012096)
feature 143 (0.011608)
feature 162 (0.011486)
feature 168 (0.011164)
feature 165 (0.010995)
feature 122 (0.010804)
feature 26 (0.010566)
feature 31 (0.010325)
feature 77 (0.010242)
feature 67 (0.009953)
inner fold=0
accuracy=0.565217391304
feature 42 (0.036205)
feature 212 (0.021545)
feature 4 (0.020419)
feature 164 (0.020274)
feature 148 (0.020083)
feature 8 (0.020028)
feature 203 (0.018692)
feature 199 (0.018061)
feature 14 (0.017576)
feature 155 (0.017376)
feature 223 (0.017325)
feature 51 (0.017011)
feature 0 (0.016585)
feature 137 (0.016581)
feature 34 (0.015694)
feature 75 (0.015199)
feature 209 (0.014758)
feature 77 (0.014652)
feature 157 (0.014608)
feature 26 (0.013064)
feature 163 (0.012862)
feature 100 (0.012852)
feature 46 (0.012741)
feature 168 (0.012729)
feature 59 (0.012343)
feature 74 (0.011582)
feature 279 (0.010642)
feature 206 (0.010603)
feature 167 (0.010354)
feature 111 (0.010324)
inner fold=1
accuracy=0.608695652174
feature 77 (0.031942)
feature 168 (0.031819)
feature 227 (0.029058)
feature 162 (0.027597)
feature 167 (0.024492)
feature 54 (0.020829)
feature 148 (0.019785)
feature 119 (0.019188)
feature 42 (0.016198)
feature 171 (0.014511)
feature 180 (0.014383)
feature 133 (0.013886)
feature 152 (0.012733)
feature 170 (0.012313)
feature 47 (0.011900)
feature 125 (0.011802)
feature 179 (0.011669)
feature 121 (0.011645)
feature 139 (0.011225)
feature 65 (0.011139)
feature 50 (0.010781)
feature 36 (0.010696)
feature 153 (0.010456)
feature 155 (0.010430)
feature 204 (0.010064)
feature 198 (0.009989)
feature 131 (0.009863)
feature 164 (0.009360)
feature 30 (0.009262)
feature 290 (0.008939)
inner fold=2
accuracy=0.577777777778
feature 164 (0.037791)
feature 290 (0.027185)
feature 130 (0.023769)
feature 76 (0.023444)
feature 152 (0.023211)
feature 77 (0.022539)
feature 131 (0.020592)
feature 199 (0.019743)
feature 148 (0.018192)
feature 134 (0.017142)
feature 125 (0.015378)
feature 209 (0.015018)
feature 218 (0.014940)
feature 10 (0.014682)
feature 58 (0.014130)
feature 210 (0.014118)
feature 340 (0.013234)
feature 168 (0.012980)
feature 56 (0.012793)
feature 118 (0.012679)
feature 81 (0.012312)
feature 151 (0.012219)
feature 184 (0.012075)
feature 180 (0.011207)
feature 135 (0.010628)
feature 165 (0.010576)
feature 66 (0.010552)
feature 80 (0.010444)
feature 14 (0.010198)
feature 79 (0.009925)
inner fold=3
accuracy=0.555555555556
feature 126 (0.038639)
feature 154 (0.025076)
feature 73 (0.024578)
feature 35 (0.023185)
feature 125 (0.022271)
feature 164 (0.021294)
feature 53 (0.019613)
feature 26 (0.017209)
feature 40 (0.016946)
feature 123 (0.016478)
feature 67 (0.015357)
feature 151 (0.014638)
feature 111 (0.014489)
feature 51 (0.014374)
feature 218 (0.013124)
feature 77 (0.013027)
feature 50 (0.011980)
feature 8 (0.011786)
feature 118 (0.011377)
feature 138 (0.011170)
feature 25 (0.010677)
feature 56 (0.010643)
feature 52 (0.010632)
feature 135 (0.010547)
feature 145 (0.010485)
feature 48 (0.010403)
feature 148 (0.010381)
feature 210 (0.010147)
feature 209 (0.009916)
feature 13 (0.009782)
inner fold=4
accuracy=0.4

lay_id=1
feature 84 (0.029044)
feature 110 (0.027419)
feature 173 (0.026861)
feature 231 (0.025526)
feature 155 (0.024272)
feature 172 (0.022075)
feature 30 (0.022012)
feature 77 (0.021351)
feature 60 (0.020872)
feature 5 (0.020671)
feature 82 (0.020124)
feature 222 (0.020053)
feature 81 (0.019705)
feature 344 (0.018612)
feature 171 (0.018013)
feature 126 (0.018003)
feature 157 (0.017315)
feature 208 (0.016467)
feature 129 (0.015444)
feature 134 (0.014684)
feature 294 (0.014334)
feature 235 (0.013410)
feature 127 (0.013265)
feature 109 (0.013140)
feature 4 (0.012500)
feature 148 (0.011751)
feature 122 (0.011747)
feature 176 (0.011528)
feature 166 (0.011250)
feature 181 (0.010606)
inner fold=0
accuracy=0.652173913043
feature 142 (0.029893)
feature 174 (0.022186)
feature 222 (0.022110)
feature 123 (0.021840)
feature 166 (0.021300)
feature 294 (0.021169)
feature 153 (0.020947)
feature 135 (0.020335)
feature 129 (0.019689)
feature 77 (0.019423)
feature 165 (0.018362)
feature 21 (0.017832)
feature 164 (0.017693)
feature 199 (0.017244)
feature 171 (0.016498)
feature 156 (0.016363)
feature 122 (0.015554)
feature 172 (0.014828)
feature 194 (0.013926)
feature 148 (0.013805)
feature 231 (0.013508)
feature 183 (0.012971)
feature 275 (0.012414)
feature 139 (0.012332)
feature 209 (0.011504)
feature 203 (0.011111)
feature 14 (0.011107)
feature 173 (0.010897)
feature 120 (0.010418)
feature 215 (0.009929)
inner fold=1
accuracy=0.739130434783
feature 203 (0.027453)
feature 142 (0.026853)
feature 213 (0.022411)
feature 84 (0.021779)
feature 227 (0.020930)
feature 127 (0.020309)
feature 174 (0.020012)
feature 215 (0.017340)
feature 46 (0.017287)
feature 129 (0.015518)
feature 151 (0.015491)
feature 69 (0.014914)
feature 12 (0.014613)
feature 385 (0.014199)
feature 172 (0.013926)
feature 135 (0.013659)
feature 202 (0.013340)
feature 77 (0.013335)
feature 235 (0.012911)
feature 30 (0.012876)
feature 41 (0.012773)
feature 53 (0.012247)
feature 294 (0.012123)
feature 207 (0.011709)
feature 52 (0.011705)
feature 61 (0.011145)
feature 62 (0.010845)
feature 153 (0.010379)
feature 194 (0.010244)
feature 81 (0.010157)
inner fold=2
accuracy=0.533333333333
feature 38 (0.031253)
feature 43 (0.027304)
feature 12 (0.025724)
feature 209 (0.024104)
feature 216 (0.022556)
feature 26 (0.021834)
feature 129 (0.020910)
feature 152 (0.019538)
feature 156 (0.017748)
feature 57 (0.017446)
feature 84 (0.016867)
feature 110 (0.016564)
feature 231 (0.016327)
feature 138 (0.016013)
feature 168 (0.015395)
feature 196 (0.014657)
feature 172 (0.014045)
feature 208 (0.013949)
feature 294 (0.013819)
feature 174 (0.013431)
feature 62 (0.013145)
feature 71 (0.013036)
feature 213 (0.013031)
feature 182 (0.012892)
feature 35 (0.012892)
feature 203 (0.012108)
feature 3 (0.011998)
feature 142 (0.011995)
feature 175 (0.011466)
feature 52 (0.011376)
inner fold=3
accuracy=0.755555555556
feature 172 (0.029059)
feature 84 (0.027894)
feature 199 (0.020917)
feature 33 (0.020881)
feature 130 (0.020640)
feature 12 (0.020320)
feature 171 (0.019066)
feature 294 (0.018682)
feature 174 (0.018151)
feature 208 (0.017910)
feature 123 (0.017345)
feature 151 (0.016610)
feature 126 (0.015991)
feature 73 (0.014476)
feature 122 (0.014098)
feature 160 (0.014025)
feature 101 (0.013631)
feature 110 (0.013600)
feature 28 (0.013408)
feature 235 (0.013270)
feature 63 (0.013215)
feature 152 (0.012948)
feature 42 (0.012217)
feature 210 (0.011963)
feature 381 (0.011507)
feature 98 (0.011202)
feature 182 (0.010936)
feature 82 (0.010751)
feature 78 (0.010535)
feature 169 (0.010517)
inner fold=4
accuracy=0.444444444444
feature 171 (0.027111)
feature 81 (0.026363)
feature 78 (0.022508)
feature 130 (0.022422)
feature 12 (0.021611)
feature 172 (0.019028)
feature 28 (0.015754)
feature 84 (0.015280)
feature 106 (0.014938)
feature 165 (0.014685)
feature 168 (0.014574)
feature 38 (0.013515)
feature 126 (0.013338)
feature 208 (0.012839)
feature 142 (0.012833)
feature 129 (0.012285)
feature 156 (0.012131)
feature 344 (0.012037)
feature 193 (0.011651)
feature 3 (0.011369)
feature 121 (0.010315)
feature 368 (0.010057)
feature 161 (0.009981)
feature 381 (0.009953)
feature 207 (0.009618)
feature 137 (0.009465)
feature 127 (0.009414)
feature 151 (0.009131)
feature 15 (0.009130)
feature 42 (0.009124)
inner fold=0
accuracy=0.565217391304
feature 168 (0.027597)
feature 184 (0.025170)
feature 211 (0.024327)
feature 222 (0.022007)
feature 174 (0.021287)
feature 172 (0.019738)
feature 46 (0.019112)
feature 78 (0.018534)
feature 34 (0.018028)
feature 145 (0.016848)
feature 123 (0.015645)
feature 38 (0.015441)
feature 235 (0.014706)
feature 102 (0.014660)
feature 81 (0.014391)
feature 157 (0.014186)
feature 21 (0.014051)
feature 385 (0.013591)
feature 213 (0.013167)
feature 390 (0.012594)
feature 214 (0.011996)
feature 12 (0.011912)
feature 377 (0.011870)
feature 231 (0.011739)
feature 53 (0.011142)
feature 14 (0.011087)
feature 125 (0.010710)
feature 54 (0.010652)
feature 79 (0.010460)
feature 166 (0.010188)
inner fold=1
accuracy=0.586956521739
feature 143 (0.024774)
feature 166 (0.022782)
feature 46 (0.021330)
feature 77 (0.018705)
feature 168 (0.018599)
feature 222 (0.017247)
feature 103 (0.017016)
feature 24 (0.016622)
feature 152 (0.016393)
feature 171 (0.016101)
feature 164 (0.014259)
feature 81 (0.014012)
feature 131 (0.013708)
feature 340 (0.013668)
feature 44 (0.013135)
feature 110 (0.012484)
feature 209 (0.012143)
feature 126 (0.012140)
feature 235 (0.012052)
feature 14 (0.012027)
feature 161 (0.011961)
feature 148 (0.011698)
feature 199 (0.011695)
feature 172 (0.011579)
feature 231 (0.011546)
feature 167 (0.011277)
feature 247 (0.011143)
feature 52 (0.011065)
feature 43 (0.010982)
feature 73 (0.010945)
inner fold=2
accuracy=0.622222222222
feature 81 (0.039913)
feature 55 (0.033913)
feature 53 (0.028502)
feature 213 (0.020522)
feature 78 (0.020490)
feature 18 (0.019812)
feature 156 (0.018182)
feature 33 (0.017841)
feature 80 (0.016947)
feature 122 (0.016736)
feature 155 (0.016577)
feature 135 (0.015994)
feature 106 (0.014856)
feature 142 (0.014505)
feature 79 (0.013753)
feature 105 (0.013586)
feature 385 (0.013258)
feature 34 (0.013224)
feature 12 (0.013095)
feature 136 (0.012763)
feature 173 (0.012595)
feature 129 (0.011991)
feature 14 (0.011870)
feature 57 (0.011411)
feature 172 (0.011305)
feature 27 (0.010867)
feature 188 (0.010774)
feature 166 (0.010612)
feature 109 (0.010475)
feature 21 (0.010427)
inner fold=3
accuracy=0.555555555556
feature 81 (0.022007)
feature 122 (0.021280)
feature 80 (0.020494)
feature 18 (0.019453)
feature 231 (0.018252)
feature 155 (0.017952)
feature 43 (0.017577)
feature 110 (0.016577)
feature 209 (0.016308)
feature 58 (0.015454)
feature 126 (0.014664)
feature 21 (0.014445)
feature 34 (0.014068)
feature 169 (0.013746)
feature 70 (0.013703)
feature 125 (0.013598)
feature 165 (0.013393)
feature 128 (0.012881)
feature 0 (0.012815)
feature 40 (0.012552)
feature 199 (0.011651)
feature 79 (0.011605)
feature 168 (0.011597)
feature 294 (0.011392)
feature 46 (0.010715)
feature 152 (0.010673)
feature 45 (0.010477)
feature 182 (0.010428)
feature 151 (0.010011)
feature 142 (0.009942)
inner fold=4
accuracy=0.488888888889

lay_id=2
feature 81 (0.026873)
feature 46 (0.025597)
feature 155 (0.023943)
feature 30 (0.023246)
feature 142 (0.022463)
feature 164 (0.021452)
feature 173 (0.020542)
feature 168 (0.020474)
feature 158 (0.020332)
feature 172 (0.019494)
feature 235 (0.018962)
feature 129 (0.016631)
feature 35 (0.016394)
feature 171 (0.015042)
feature 110 (0.014501)
feature 115 (0.014477)
feature 126 (0.014185)
feature 137 (0.014106)
feature 215 (0.013727)
feature 209 (0.013380)
feature 40 (0.013122)
feature 208 (0.012989)
feature 4 (0.012629)
feature 55 (0.012000)
feature 123 (0.011879)
feature 56 (0.011676)
feature 108 (0.011548)
feature 44 (0.011495)
feature 43 (0.010878)
feature 169 (0.009889)
inner fold=0
accuracy=0.565217391304
feature 231 (0.025674)
feature 171 (0.024581)
feature 173 (0.023358)
feature 30 (0.023325)
feature 81 (0.021695)
feature 129 (0.019815)
feature 42 (0.019159)
feature 152 (0.018629)
feature 33 (0.017860)
feature 14 (0.017496)
feature 110 (0.016820)
feature 3 (0.016265)
feature 222 (0.016064)
feature 156 (0.015096)
feature 78 (0.015065)
feature 120 (0.014869)
feature 216 (0.014637)
feature 285 (0.014513)
feature 46 (0.013883)
feature 136 (0.013648)
feature 38 (0.013430)
feature 13 (0.012993)
feature 138 (0.011197)
feature 174 (0.010814)
feature 169 (0.010729)
feature 344 (0.010308)
feature 82 (0.010244)
feature 272 (0.009984)
feature 214 (0.009895)
feature 62 (0.009660)
inner fold=1
accuracy=0.586956521739
feature 153 (0.037001)
feature 152 (0.027950)
feature 149 (0.020555)
feature 62 (0.019452)
feature 208 (0.018225)
feature 130 (0.017987)
feature 171 (0.017549)
feature 58 (0.016858)
feature 128 (0.014636)
feature 44 (0.014393)
feature 81 (0.014289)
feature 207 (0.014156)
feature 157 (0.013701)
feature 131 (0.013579)
feature 183 (0.013342)
feature 222 (0.012721)
feature 55 (0.012587)
feature 77 (0.012320)
feature 78 (0.012287)
feature 34 (0.012114)
feature 159 (0.011948)
feature 8 (0.011618)
feature 4 (0.011609)
feature 56 (0.011534)
feature 84 (0.011483)
feature 47 (0.011284)
feature 70 (0.010508)
feature 54 (0.010508)
feature 181 (0.010466)
feature 46 (0.009947)
inner fold=2
accuracy=0.555555555556
feature 123 (0.028623)
feature 172 (0.023388)
feature 78 (0.022433)
feature 34 (0.021278)
feature 55 (0.019706)
feature 362 (0.019587)
feature 171 (0.017310)
feature 168 (0.017211)
feature 128 (0.016444)
feature 79 (0.016064)
feature 42 (0.015588)
feature 46 (0.015456)
feature 182 (0.013704)
feature 101 (0.012870)
feature 165 (0.012743)
feature 5 (0.012321)
feature 227 (0.012215)
feature 48 (0.012158)
feature 174 (0.012062)
feature 139 (0.011975)
feature 138 (0.011654)
feature 213 (0.011609)
feature 100 (0.011321)
feature 201 (0.010934)
feature 82 (0.010795)
feature 30 (0.010532)
feature 102 (0.009865)
feature 199 (0.009842)
feature 214 (0.009841)
feature 106 (0.009323)
inner fold=3
accuracy=0.533333333333
feature 55 (0.032321)
feature 199 (0.022170)
feature 362 (0.021745)
feature 134 (0.021465)
feature 171 (0.020734)
feature 182 (0.018879)
feature 30 (0.018791)
feature 42 (0.018133)
feature 168 (0.016998)
feature 110 (0.016739)
feature 81 (0.016129)
feature 128 (0.015825)
feature 83 (0.014760)
feature 1 (0.014270)
feature 165 (0.014069)
feature 114 (0.013723)
feature 121 (0.013284)
feature 145 (0.012435)
feature 12 (0.012417)
feature 56 (0.012161)
feature 157 (0.012041)
feature 130 (0.011973)
feature 106 (0.011931)
feature 123 (0.011737)
feature 4 (0.011498)
feature 184 (0.011313)
feature 43 (0.011107)
feature 222 (0.010855)
feature 142 (0.010441)
feature 39 (0.010157)
inner fold=4
accuracy=0.577777777778
feature 294 (0.047722)
feature 12 (0.024201)
feature 207 (0.022997)
feature 155 (0.021264)
feature 34 (0.020635)
feature 385 (0.019968)
feature 123 (0.019014)
feature 137 (0.018725)
feature 128 (0.018414)
feature 78 (0.017309)
feature 110 (0.016384)
feature 193 (0.016153)
feature 210 (0.015936)
feature 77 (0.013905)
feature 129 (0.013852)
feature 156 (0.013503)
feature 79 (0.013432)
feature 56 (0.013301)
feature 235 (0.013024)
feature 138 (0.012764)
feature 148 (0.012677)
feature 38 (0.012384)
feature 164 (0.011739)
feature 222 (0.011412)
feature 81 (0.010687)
feature 70 (0.010488)
feature 211 (0.010463)
feature 151 (0.010434)
feature 200 (0.010091)
feature 80 (0.009859)
inner fold=0
accuracy=0.630434782609
feature 173 (0.032367)
feature 46 (0.031356)
feature 52 (0.024037)
feature 175 (0.022297)
feature 129 (0.019916)
feature 134 (0.017324)
feature 207 (0.016061)
feature 5 (0.015768)
feature 107 (0.015552)
feature 300 (0.014747)
feature 208 (0.014582)
feature 171 (0.014499)
feature 0 (0.014319)
feature 14 (0.013763)
feature 138 (0.013519)
feature 216 (0.013460)
feature 38 (0.011999)
feature 168 (0.011988)
feature 142 (0.011980)
feature 148 (0.011857)
feature 24 (0.011477)
feature 126 (0.011471)
feature 43 (0.011324)
feature 80 (0.011114)
feature 275 (0.011079)
feature 128 (0.011071)
feature 110 (0.010720)
feature 44 (0.010566)
feature 135 (0.010508)
feature 211 (0.010441)
inner fold=1
accuracy=0.521739130435
feature 172 (0.030258)
feature 134 (0.026502)
feature 129 (0.025199)
feature 43 (0.023382)
feature 231 (0.018737)
feature 145 (0.017414)
feature 33 (0.017059)
feature 41 (0.016341)
feature 28 (0.015638)
feature 203 (0.015417)
feature 77 (0.015399)
feature 110 (0.015317)
feature 208 (0.014965)
feature 213 (0.014580)
feature 55 (0.014497)
feature 56 (0.013892)
feature 188 (0.013838)
feature 137 (0.013472)
feature 207 (0.012872)
feature 127 (0.012648)
feature 152 (0.012580)
feature 156 (0.012188)
feature 160 (0.011909)
feature 170 (0.011875)
feature 34 (0.011870)
feature 135 (0.011776)
feature 123 (0.011735)
feature 128 (0.011257)
feature 126 (0.011062)
feature 210 (0.011024)
inner fold=2
accuracy=0.577777777778
feature 80 (0.026722)
feature 130 (0.024297)
feature 46 (0.023480)
feature 155 (0.021175)
feature 213 (0.021066)
feature 210 (0.019916)
feature 123 (0.019850)
feature 340 (0.018746)
feature 231 (0.018710)
feature 159 (0.017304)
feature 156 (0.016516)
feature 202 (0.016499)
feature 199 (0.016063)
feature 151 (0.015715)
feature 142 (0.015661)
feature 208 (0.015092)
feature 81 (0.014324)
feature 44 (0.014067)
feature 52 (0.013872)
feature 164 (0.012827)
feature 201 (0.012699)
feature 34 (0.012652)
feature 171 (0.010979)
feature 102 (0.010734)
feature 175 (0.010719)
feature 193 (0.010668)
feature 173 (0.010272)
feature 109 (0.010238)
feature 63 (0.010236)
feature 203 (0.010128)
inner fold=3
accuracy=0.622222222222
feature 135 (0.024323)
feature 172 (0.019783)
feature 182 (0.019551)
feature 151 (0.019450)
feature 138 (0.018440)
feature 214 (0.016846)
feature 142 (0.016568)
feature 40 (0.016269)
feature 14 (0.016167)
feature 139 (0.016016)
feature 129 (0.015515)
feature 464 (0.015220)
feature 166 (0.014733)
feature 275 (0.014540)
feature 171 (0.013994)
feature 164 (0.013824)
feature 21 (0.013171)
feature 42 (0.012901)
feature 159 (0.012467)
feature 175 (0.012158)
feature 24 (0.012073)
feature 208 (0.011980)
feature 41 (0.011499)
feature 173 (0.011404)
feature 62 (0.011217)
feature 5 (0.011137)
feature 141 (0.011054)
feature 194 (0.010953)
feature 130 (0.010788)
feature 157 (0.010738)
inner fold=4
accuracy=0.555555555556

lay_id=3
feature 130 (0.032088)
feature 152 (0.026781)
feature 222 (0.022012)
feature 156 (0.020907)
feature 174 (0.019959)
feature 135 (0.019544)
feature 81 (0.019125)
feature 215 (0.018059)
feature 122 (0.017081)
feature 46 (0.016406)
feature 171 (0.016103)
feature 128 (0.015457)
feature 104 (0.014841)
feature 43 (0.014617)
feature 165 (0.014114)
feature 38 (0.013267)
feature 294 (0.012764)
feature 126 (0.012231)
feature 184 (0.011710)
feature 142 (0.011496)
feature 18 (0.011488)
feature 164 (0.011453)
feature 166 (0.011232)
feature 77 (0.010672)
feature 149 (0.010575)
feature 24 (0.010534)
feature 144 (0.009946)
feature 56 (0.009862)
feature 389 (0.009222)
feature 69 (0.009215)
inner fold=0
accuracy=0.521739130435
feature 43 (0.030677)
feature 84 (0.027242)
feature 46 (0.020532)
feature 29 (0.020464)
feature 81 (0.019481)
feature 30 (0.018749)
feature 103 (0.018075)
feature 157 (0.017895)
feature 28 (0.016324)
feature 51 (0.015830)
feature 139 (0.015485)
feature 80 (0.014905)
feature 136 (0.014404)
feature 151 (0.014386)
feature 231 (0.013302)
feature 166 (0.013049)
feature 172 (0.012675)
feature 104 (0.012616)
feature 73 (0.012267)
feature 156 (0.011452)
feature 58 (0.011171)
feature 362 (0.010964)
feature 140 (0.010796)
feature 141 (0.010716)
feature 56 (0.010674)
feature 14 (0.010479)
feature 152 (0.010320)
feature 142 (0.010283)
feature 215 (0.010027)
feature 164 (0.009938)
inner fold=1
accuracy=0.586956521739
feature 214 (0.027440)
feature 211 (0.025690)
feature 158 (0.022674)
feature 234 (0.021540)
feature 159 (0.021391)
feature 81 (0.021173)
feature 166 (0.020061)
feature 156 (0.019869)
feature 135 (0.018952)
feature 165 (0.018355)
feature 172 (0.018241)
feature 161 (0.017596)
feature 78 (0.017532)
feature 21 (0.017121)
feature 84 (0.016110)
feature 122 (0.015406)
feature 294 (0.014600)
feature 129 (0.014049)
feature 46 (0.014020)
feature 137 (0.013589)
feature 181 (0.013127)
feature 196 (0.013017)
feature 152 (0.012645)
feature 180 (0.011900)
feature 168 (0.011811)
feature 227 (0.011285)
feature 57 (0.010736)
feature 127 (0.010549)
feature 56 (0.010533)
feature 50 (0.010308)
inner fold=2
accuracy=0.488888888889
feature 81 (0.047127)
feature 172 (0.038234)
feature 166 (0.024224)
feature 231 (0.021289)
feature 174 (0.021035)
feature 171 (0.019374)
feature 29 (0.018386)
feature 14 (0.016357)
feature 188 (0.015612)
feature 175 (0.014667)
feature 194 (0.014599)
feature 168 (0.014268)
feature 12 (0.013980)
feature 152 (0.013584)
feature 18 (0.013502)
feature 156 (0.013412)
feature 120 (0.013404)
feature 78 (0.013375)
feature 77 (0.012814)
feature 141 (0.012558)
feature 123 (0.012492)
feature 160 (0.012386)
feature 125 (0.012120)
feature 199 (0.012061)
feature 209 (0.011842)
feature 222 (0.011531)
feature 381 (0.011221)
feature 28 (0.010051)
feature 208 (0.009879)
feature 84 (0.009869)
inner fold=3
accuracy=0.577777777778
feature 168 (0.026969)
feature 123 (0.023655)
feature 166 (0.022500)
feature 24 (0.022306)
feature 134 (0.020486)
feature 126 (0.017842)
feature 145 (0.017796)
feature 349 (0.016834)
feature 165 (0.016832)
feature 199 (0.016785)
feature 160 (0.016773)
feature 175 (0.016022)
feature 81 (0.015838)
feature 211 (0.015580)
feature 35 (0.014351)
feature 55 (0.014347)
feature 215 (0.014297)
feature 78 (0.013583)
feature 156 (0.013445)
feature 171 (0.012524)
feature 83 (0.012084)
feature 40 (0.011953)
feature 129 (0.011878)
feature 33 (0.011593)
feature 170 (0.011481)
feature 408 (0.011159)
feature 38 (0.011057)
feature 110 (0.010294)
feature 51 (0.010155)
feature 139 (0.010052)
inner fold=4
accuracy=0.533333333333
feature 168 (0.034981)
feature 172 (0.027300)
feature 58 (0.025684)
feature 142 (0.021597)
feature 110 (0.021151)
feature 167 (0.021124)
feature 203 (0.018195)
feature 120 (0.017817)
feature 175 (0.017606)
feature 227 (0.016763)
feature 69 (0.016447)
feature 115 (0.016390)
feature 171 (0.016239)
feature 138 (0.016220)
feature 151 (0.015395)
feature 136 (0.014687)
feature 104 (0.014551)
feature 158 (0.014318)
feature 174 (0.014271)
feature 213 (0.013661)
feature 80 (0.013626)
feature 208 (0.013615)
feature 14 (0.012888)
feature 275 (0.012819)
feature 27 (0.012456)
feature 15 (0.012256)
feature 100 (0.012183)
feature 82 (0.012152)
feature 77 (0.011534)
feature 33 (0.011393)
inner fold=0
accuracy=0.565217391304
feature 168 (0.027288)
feature 44 (0.021494)
feature 294 (0.021097)
feature 164 (0.021072)
feature 110 (0.019101)
feature 33 (0.017555)
feature 78 (0.015921)
feature 149 (0.015675)
feature 166 (0.014935)
feature 145 (0.013211)
feature 84 (0.013185)
feature 52 (0.013167)
feature 213 (0.012997)
feature 161 (0.012972)
feature 137 (0.012896)
feature 152 (0.012664)
feature 46 (0.012333)
feature 55 (0.012134)
feature 39 (0.011865)
feature 21 (0.011459)
feature 53 (0.011404)
feature 30 (0.011396)
feature 160 (0.011234)
feature 246 (0.010869)
feature 173 (0.010680)
feature 58 (0.010587)
feature 81 (0.010403)
feature 12 (0.010401)
feature 362 (0.010355)
feature 172 (0.010165)
inner fold=1
accuracy=0.652173913043
feature 58 (0.033249)
feature 129 (0.030921)
feature 38 (0.028801)
feature 152 (0.026763)
feature 181 (0.020252)
feature 142 (0.019203)
feature 159 (0.018588)
feature 54 (0.018097)
feature 46 (0.017727)
feature 172 (0.015835)
feature 2 (0.015830)
feature 213 (0.015622)
feature 224 (0.014888)
feature 164 (0.014570)
feature 210 (0.013767)
feature 35 (0.013696)
feature 156 (0.012941)
feature 82 (0.012863)
feature 52 (0.012423)
feature 28 (0.012323)
feature 128 (0.011901)
feature 344 (0.011810)
feature 139 (0.011637)
feature 174 (0.011326)
feature 120 (0.011114)
feature 208 (0.010985)
feature 216 (0.010852)
feature 171 (0.010724)
feature 43 (0.010349)
feature 126 (0.010315)
inner fold=2
accuracy=0.6
feature 42 (0.029719)
feature 172 (0.027093)
feature 81 (0.026594)
feature 142 (0.026521)
feature 272 (0.025192)
feature 46 (0.019437)
feature 231 (0.018946)
feature 77 (0.018584)
feature 4 (0.018018)
feature 294 (0.017751)
feature 173 (0.016897)
feature 14 (0.016740)
feature 161 (0.016276)
feature 128 (0.016229)
feature 171 (0.015882)
feature 235 (0.015753)
feature 182 (0.015482)
feature 73 (0.015283)
feature 12 (0.015249)
feature 213 (0.014826)
feature 129 (0.014679)
feature 207 (0.014058)
feature 227 (0.011902)
feature 169 (0.011290)
feature 175 (0.011167)
feature 174 (0.010994)
feature 134 (0.010930)
feature 58 (0.010909)
feature 165 (0.010684)
feature 194 (0.010157)
inner fold=3
accuracy=0.644444444444
feature 227 (0.023345)
feature 294 (0.023099)
feature 80 (0.019792)
feature 134 (0.019149)
feature 158 (0.018921)
feature 123 (0.018916)
feature 151 (0.017793)
feature 172 (0.017083)
feature 12 (0.016485)
feature 110 (0.016413)
feature 166 (0.014832)
feature 44 (0.014567)
feature 54 (0.014511)
feature 14 (0.014325)
feature 168 (0.014078)
feature 231 (0.013872)
feature 175 (0.013605)
feature 43 (0.013430)
feature 188 (0.013284)
feature 60 (0.013041)
feature 33 (0.013017)
feature 201 (0.012556)
feature 142 (0.012516)
feature 385 (0.011900)
feature 214 (0.011814)
feature 55 (0.011425)
feature 128 (0.011368)
feature 165 (0.011327)
feature 4 (0.011116)
feature 24 (0.010905)
inner fold=4
accuracy=0.466666666667

lay_id=4
feature 30 (0.038171)
feature 55 (0.031544)
feature 81 (0.028011)
feature 174 (0.025609)
feature 156 (0.021563)
feature 151 (0.020893)
feature 46 (0.020664)
feature 294 (0.018528)
feature 168 (0.017482)
feature 147 (0.016613)
feature 135 (0.016445)
feature 130 (0.015579)
feature 73 (0.015150)
feature 200 (0.014800)
feature 136 (0.014009)
feature 107 (0.013130)
feature 171 (0.013091)
feature 114 (0.012887)
feature 235 (0.012371)
feature 58 (0.011868)
feature 125 (0.011447)
feature 172 (0.011321)
feature 140 (0.011181)
feature 381 (0.011160)
feature 231 (0.010750)
feature 142 (0.010734)
feature 78 (0.010650)
feature 60 (0.010189)
feature 127 (0.010141)
feature 372 (0.009998)
inner fold=0
accuracy=0.652173913043
feature 142 (0.036754)
feature 171 (0.030600)
feature 139 (0.023381)
feature 102 (0.021991)
feature 213 (0.021232)
feature 174 (0.020718)
feature 79 (0.017659)
feature 107 (0.017418)
feature 81 (0.016416)
feature 57 (0.015893)
feature 127 (0.015826)
feature 152 (0.014869)
feature 167 (0.014319)
feature 134 (0.013821)
feature 157 (0.013686)
feature 126 (0.013615)
feature 123 (0.013375)
feature 133 (0.013152)
feature 55 (0.012566)
feature 172 (0.012462)
feature 182 (0.012312)
feature 33 (0.012245)
feature 385 (0.012117)
feature 129 (0.012094)
feature 143 (0.011935)
feature 137 (0.011660)
feature 176 (0.011634)
feature 151 (0.010880)
feature 344 (0.010756)
feature 145 (0.010725)
inner fold=1
accuracy=0.652173913043
feature 122 (0.030755)
feature 142 (0.028037)
feature 18 (0.027287)
feature 168 (0.021620)
feature 161 (0.020686)
feature 42 (0.019937)
feature 81 (0.018650)
feature 172 (0.018175)
feature 30 (0.018142)
feature 156 (0.017878)
feature 12 (0.016990)
feature 110 (0.015978)
feature 57 (0.015358)
feature 294 (0.014407)
feature 73 (0.014219)
feature 128 (0.013712)
feature 301 (0.013683)
feature 77 (0.013560)
feature 153 (0.012910)
feature 203 (0.012500)
feature 166 (0.011823)
feature 126 (0.011731)
feature 0 (0.011696)
feature 121 (0.011049)
feature 80 (0.011047)
feature 200 (0.011035)
feature 105 (0.010805)
feature 395 (0.010621)
feature 107 (0.010579)
feature 139 (0.010509)
inner fold=2
accuracy=0.6
feature 172 (0.025455)
feature 3 (0.020732)
feature 82 (0.020318)
feature 135 (0.019523)
feature 134 (0.017806)
feature 120 (0.017248)
feature 168 (0.016795)
feature 123 (0.016545)
feature 44 (0.016326)
feature 213 (0.014899)
feature 171 (0.014794)
feature 101 (0.014499)
feature 443 (0.014188)
feature 201 (0.014118)
feature 81 (0.014002)
feature 42 (0.013818)
feature 222 (0.013380)
feature 166 (0.012753)
feature 102 (0.012567)
feature 165 (0.012549)
feature 77 (0.012495)
feature 167 (0.012222)
feature 385 (0.012106)
feature 285 (0.012026)
feature 184 (0.011980)
feature 46 (0.011970)
feature 62 (0.011869)
feature 158 (0.011617)
feature 24 (0.011606)
feature 169 (0.011604)
inner fold=3
accuracy=0.533333333333
feature 81 (0.038178)
feature 294 (0.034684)
feature 44 (0.024284)
feature 135 (0.024274)
feature 159 (0.019069)
feature 110 (0.018306)
feature 57 (0.018257)
feature 134 (0.017794)
feature 79 (0.017378)
feature 102 (0.017335)
feature 155 (0.015950)
feature 18 (0.015668)
feature 14 (0.015513)
feature 129 (0.015481)
feature 30 (0.015444)
feature 80 (0.014676)
feature 171 (0.014202)
feature 78 (0.013828)
feature 62 (0.013363)
feature 211 (0.013121)
feature 70 (0.012710)
feature 170 (0.012610)
feature 200 (0.012420)
feature 215 (0.011777)
feature 126 (0.011719)
feature 275 (0.011584)
feature 152 (0.011320)
feature 127 (0.010938)
feature 139 (0.010605)
feature 131 (0.010247)
inner fold=4
accuracy=0.511111111111
feature 134 (0.025559)
feature 159 (0.025322)
feature 166 (0.025053)
feature 213 (0.021045)
feature 165 (0.019620)
feature 168 (0.019458)
feature 46 (0.018574)
feature 231 (0.017658)
feature 160 (0.017423)
feature 122 (0.015531)
feature 131 (0.015075)
feature 157 (0.014289)
feature 161 (0.013523)
feature 153 (0.013407)
feature 129 (0.013407)
feature 156 (0.013347)
feature 223 (0.012870)
feature 97 (0.011983)
feature 155 (0.011594)
feature 104 (0.011537)
feature 227 (0.011324)
feature 44 (0.011194)
feature 272 (0.011095)
feature 103 (0.010486)
feature 209 (0.010452)
feature 14 (0.010400)
feature 222 (0.010318)
feature 152 (0.010161)
feature 167 (0.009625)
feature 30 (0.009211)
inner fold=0
accuracy=0.673913043478
feature 166 (0.035117)
feature 73 (0.034170)
feature 171 (0.031333)
feature 57 (0.029627)
feature 62 (0.026174)
feature 78 (0.020592)
feature 153 (0.020069)
feature 53 (0.017424)
feature 114 (0.017306)
feature 12 (0.016645)
feature 81 (0.016600)
feature 29 (0.015440)
feature 199 (0.014707)
feature 21 (0.013747)
feature 30 (0.013582)
feature 14 (0.013502)
feature 128 (0.013239)
feature 156 (0.013087)
feature 142 (0.012173)
feature 80 (0.012149)
feature 145 (0.012148)
feature 4 (0.012100)
feature 385 (0.011638)
feature 170 (0.011494)
feature 135 (0.011456)
feature 157 (0.010957)
feature 43 (0.010912)
feature 125 (0.010838)
feature 203 (0.010804)
feature 107 (0.009844)
inner fold=1
accuracy=0.586956521739
feature 107 (0.029646)
feature 123 (0.027542)
feature 139 (0.021607)
feature 42 (0.019660)
feature 129 (0.019107)
feature 79 (0.018223)
feature 63 (0.016701)
feature 213 (0.016146)
feature 166 (0.015777)
feature 138 (0.015751)
feature 77 (0.015060)
feature 34 (0.014571)
feature 142 (0.014198)
feature 171 (0.013742)
feature 173 (0.013738)
feature 187 (0.013667)
feature 40 (0.013476)
feature 148 (0.013329)
feature 81 (0.012906)
feature 4 (0.012791)
feature 90 (0.012670)
feature 235 (0.012527)
feature 30 (0.012294)
feature 122 (0.012101)
feature 170 (0.011452)
feature 18 (0.011429)
feature 272 (0.011193)
feature 12 (0.010990)
feature 358 (0.010877)
feature 209 (0.010678)
inner fold=2
accuracy=0.6
feature 216 (0.027932)
feature 166 (0.026714)
feature 272 (0.022059)
feature 152 (0.020337)
feature 140 (0.019370)
feature 153 (0.019370)
feature 171 (0.019369)
feature 362 (0.018287)
feature 464 (0.017035)
feature 109 (0.015933)
feature 101 (0.015931)
feature 454 (0.015812)
feature 143 (0.015577)
feature 168 (0.014950)
feature 161 (0.014657)
feature 128 (0.014246)
feature 106 (0.013925)
feature 213 (0.013482)
feature 110 (0.013327)
feature 46 (0.013117)
feature 139 (0.012643)
feature 82 (0.011707)
feature 102 (0.011055)
feature 200 (0.010804)
feature 122 (0.010758)
feature 193 (0.010739)
feature 182 (0.010204)
feature 155 (0.010156)
feature 224 (0.010044)
feature 134 (0.009914)
inner fold=3
accuracy=0.688888888889
feature 46 (0.038672)
feature 183 (0.026186)
feature 156 (0.025704)
feature 24 (0.025474)
feature 81 (0.024213)
feature 208 (0.021999)
feature 12 (0.020266)
feature 166 (0.019740)
feature 152 (0.017936)
feature 199 (0.017518)
feature 159 (0.017406)
feature 222 (0.017328)
feature 151 (0.016995)
feature 227 (0.016908)
feature 129 (0.016024)
feature 231 (0.015511)
feature 144 (0.015353)
feature 275 (0.015322)
feature 157 (0.014659)
feature 172 (0.014536)
feature 63 (0.014406)
feature 5 (0.014369)
feature 38 (0.014263)
feature 34 (0.014223)
feature 53 (0.014104)
feature 168 (0.013601)
feature 155 (0.012380)
feature 110 (0.011807)
feature 149 (0.011398)
feature 106 (0.011379)
inner fold=4
accuracy=0.577777777778

lay_id=5
feature 53 (0.031272)
feature 35 (0.026079)
feature 157 (0.024164)
feature 84 (0.021320)
feature 182 (0.020080)
feature 4 (0.019292)
feature 202 (0.018613)
feature 46 (0.017965)
feature 358 (0.017210)
feature 227 (0.017000)
feature 272 (0.016556)
feature 173 (0.016289)
feature 155 (0.015379)
feature 81 (0.014254)
feature 172 (0.014174)
feature 169 (0.014078)
feature 175 (0.013641)
feature 153 (0.013147)
feature 148 (0.012542)
feature 68 (0.012360)
feature 55 (0.012340)
feature 141 (0.011822)
feature 464 (0.011227)
feature 203 (0.010718)
feature 79 (0.010555)
feature 210 (0.010465)
feature 152 (0.009485)
feature 224 (0.009192)
feature 168 (0.008463)
feature 145 (0.008337)
inner fold=0
accuracy=0.652173913043
feature 84 (0.026686)
feature 168 (0.025027)
feature 227 (0.023020)
feature 152 (0.023000)
feature 110 (0.022101)
feature 40 (0.021765)
feature 214 (0.018436)
feature 120 (0.018335)
feature 123 (0.017636)
feature 166 (0.015907)
feature 143 (0.015607)
feature 78 (0.015408)
feature 22 (0.014938)
feature 126 (0.014394)
feature 381 (0.014346)
feature 81 (0.014090)
feature 24 (0.013357)
feature 4 (0.012450)
feature 131 (0.012109)
feature 128 (0.011969)
feature 142 (0.011598)
feature 10 (0.011591)
feature 174 (0.011583)
feature 216 (0.011374)
feature 115 (0.011356)
feature 294 (0.011102)
feature 60 (0.011021)
feature 103 (0.010890)
feature 344 (0.010759)
feature 175 (0.010696)
inner fold=1
accuracy=0.565217391304
feature 30 (0.041972)
feature 84 (0.025919)
feature 14 (0.024936)
feature 101 (0.022324)
feature 12 (0.021600)
feature 69 (0.021401)
feature 159 (0.020508)
feature 129 (0.019287)
feature 56 (0.019242)
feature 156 (0.017512)
feature 106 (0.016354)
feature 110 (0.015777)
feature 208 (0.015280)
feature 62 (0.014691)
feature 130 (0.014618)
feature 81 (0.014207)
feature 28 (0.013978)
feature 77 (0.013612)
feature 152 (0.013416)
feature 166 (0.012570)
feature 151 (0.012527)
feature 275 (0.012401)
feature 139 (0.012110)
feature 3 (0.011792)
feature 385 (0.011695)
feature 362 (0.011524)
feature 163 (0.011040)
feature 2 (0.010990)
feature 97 (0.010965)
feature 46 (0.010618)
inner fold=2
accuracy=0.622222222222
feature 171 (0.030543)
feature 172 (0.023059)
feature 38 (0.022967)
feature 209 (0.020096)
feature 193 (0.018211)
feature 129 (0.015861)
feature 16 (0.015202)
feature 208 (0.014521)
feature 42 (0.013588)
feature 134 (0.013341)
feature 110 (0.013332)
feature 130 (0.013152)
feature 12 (0.013097)
feature 101 (0.013087)
feature 175 (0.012733)
feature 80 (0.012597)
feature 385 (0.012573)
feature 4 (0.012573)
feature 201 (0.011955)
feature 383 (0.011932)
feature 58 (0.011807)
feature 85 (0.011461)
feature 24 (0.011397)
feature 81 (0.011044)
feature 377 (0.010967)
feature 168 (0.010889)
feature 126 (0.010536)
feature 131 (0.010388)
feature 235 (0.010172)
feature 127 (0.009980)
inner fold=3
accuracy=0.6
feature 171 (0.028222)
feature 168 (0.026606)
feature 173 (0.026155)
feature 18 (0.022134)
feature 158 (0.020529)
feature 126 (0.019141)
feature 2 (0.018696)
feature 42 (0.018434)
feature 41 (0.017738)
feature 84 (0.017396)
feature 172 (0.016082)
feature 30 (0.015864)
feature 142 (0.015439)
feature 56 (0.014537)
feature 29 (0.014336)
feature 120 (0.014263)
feature 129 (0.013142)
feature 166 (0.013139)
feature 53 (0.013087)
feature 12 (0.012922)
feature 101 (0.012884)
feature 231 (0.012359)
feature 123 (0.011389)
feature 28 (0.011324)
feature 105 (0.011041)
feature 203 (0.010983)
feature 227 (0.010776)
feature 81 (0.010663)
feature 125 (0.010577)
feature 128 (0.010561)
inner fold=4
accuracy=0.666666666667
feature 235 (0.032577)
feature 156 (0.032537)
feature 33 (0.028033)
feature 171 (0.027983)
feature 122 (0.023187)
feature 135 (0.022399)
feature 44 (0.021102)
feature 164 (0.020293)
feature 216 (0.018326)
feature 125 (0.018188)
feature 8 (0.018100)
feature 142 (0.018047)
feature 123 (0.017276)
feature 175 (0.016889)
feature 173 (0.016832)
feature 46 (0.016071)
feature 174 (0.015308)
feature 166 (0.015204)
feature 199 (0.014932)
feature 222 (0.014570)
feature 136 (0.013854)
feature 213 (0.013474)
feature 294 (0.013048)
feature 126 (0.012753)
feature 364 (0.011694)
feature 214 (0.011287)
feature 34 (0.010715)
feature 24 (0.010384)
feature 209 (0.010317)
feature 211 (0.009876)
inner fold=0
accuracy=0.717391304348
feature 12 (0.045236)
feature 30 (0.032909)
feature 78 (0.027212)
feature 215 (0.024413)
feature 141 (0.024017)
feature 131 (0.022942)
feature 364 (0.022131)
feature 122 (0.018791)
feature 213 (0.018228)
feature 164 (0.017211)
feature 24 (0.016757)
feature 294 (0.016254)
feature 194 (0.015245)
feature 126 (0.015173)
feature 200 (0.014048)
feature 53 (0.013448)
feature 140 (0.013339)
feature 125 (0.013192)
feature 203 (0.012507)
feature 159 (0.012490)
feature 107 (0.012246)
feature 181 (0.011916)
feature 171 (0.011856)
feature 172 (0.011655)
feature 62 (0.011401)
feature 285 (0.011400)
feature 105 (0.010222)
feature 135 (0.009857)
feature 21 (0.009729)
feature 167 (0.009591)
inner fold=1
accuracy=0.586956521739
feature 168 (0.030673)
feature 3 (0.024319)
feature 158 (0.023379)
feature 38 (0.021780)
feature 14 (0.020978)
feature 152 (0.018723)
feature 222 (0.018417)
feature 172 (0.016456)
feature 43 (0.015823)
feature 144 (0.015711)
feature 131 (0.015619)
feature 84 (0.015009)
feature 138 (0.014696)
feature 134 (0.014529)
feature 153 (0.014526)
feature 390 (0.014219)
feature 12 (0.014195)
feature 136 (0.013018)
feature 156 (0.012219)
feature 52 (0.012127)
feature 40 (0.011957)
feature 210 (0.011715)
feature 148 (0.011650)
feature 203 (0.011632)
feature 56 (0.011581)
feature 62 (0.011559)
feature 21 (0.011537)
feature 231 (0.011353)
feature 139 (0.011269)
feature 235 (0.011159)
inner fold=2
accuracy=0.688888888889
feature 171 (0.042405)
feature 12 (0.038123)
feature 142 (0.037500)
feature 78 (0.025809)
feature 81 (0.023891)
feature 134 (0.023245)
feature 152 (0.018618)
feature 294 (0.017319)
feature 21 (0.015993)
feature 202 (0.015614)
feature 24 (0.015511)
feature 203 (0.014853)
feature 283 (0.014320)
feature 180 (0.014228)
feature 42 (0.012965)
feature 160 (0.012740)
feature 41 (0.012672)
feature 140 (0.012176)
feature 107 (0.012142)
feature 151 (0.011968)
feature 157 (0.011198)
feature 103 (0.011106)
feature 55 (0.011095)
feature 163 (0.011035)
feature 43 (0.010661)
feature 122 (0.010560)
feature 172 (0.010281)
feature 46 (0.010142)
feature 215 (0.010010)
feature 223 (0.009794)
inner fold=3
accuracy=0.511111111111
feature 30 (0.028393)
feature 152 (0.027059)
feature 138 (0.022342)
feature 2 (0.021297)
feature 79 (0.020631)
feature 151 (0.019280)
feature 55 (0.018951)
feature 69 (0.018641)
feature 52 (0.018271)
feature 122 (0.017760)
feature 107 (0.017730)
feature 24 (0.016825)
feature 174 (0.016768)
feature 143 (0.015072)
feature 155 (0.014228)
feature 103 (0.014182)
feature 173 (0.013408)
feature 14 (0.013116)
feature 141 (0.012953)
feature 235 (0.012144)
feature 58 (0.012080)
feature 77 (0.012058)
feature 46 (0.011237)
feature 130 (0.011086)
feature 227 (0.011016)
feature 168 (0.010662)
feature 110 (0.010573)
feature 129 (0.010348)
feature 222 (0.010203)
feature 164 (0.010166)
inner fold=4
accuracy=0.6

lay_id=6
feature 46 (0.027994)
feature 84 (0.023917)
feature 126 (0.020528)
feature 152 (0.020481)
feature 55 (0.019878)
feature 171 (0.018319)
feature 58 (0.017489)
feature 227 (0.017075)
feature 8 (0.015852)
feature 5 (0.015783)
feature 0 (0.015656)
feature 207 (0.015197)
feature 173 (0.015156)
feature 185 (0.015082)
feature 203 (0.014455)
feature 181 (0.014168)
feature 172 (0.014085)
feature 165 (0.013687)
feature 4 (0.013399)
feature 125 (0.012965)
feature 52 (0.012627)
feature 105 (0.011948)
feature 129 (0.011760)
feature 164 (0.011283)
feature 294 (0.010819)
feature 168 (0.010243)
feature 47 (0.009847)
feature 36 (0.009601)
feature 18 (0.009563)
feature 90 (0.009478)
inner fold=0
accuracy=0.586956521739
feature 58 (0.027037)
feature 134 (0.025165)
feature 4 (0.023437)
feature 294 (0.020038)
feature 139 (0.018755)
feature 77 (0.018255)
feature 164 (0.018174)
feature 44 (0.016851)
feature 0 (0.015993)
feature 235 (0.015966)
feature 153 (0.015601)
feature 110 (0.015572)
feature 135 (0.014416)
feature 160 (0.014249)
feature 152 (0.013217)
feature 175 (0.013124)
feature 8 (0.012891)
feature 151 (0.012878)
feature 208 (0.012706)
feature 61 (0.012676)
feature 63 (0.012456)
feature 210 (0.012146)
feature 203 (0.011889)
feature 216 (0.011793)
feature 70 (0.011628)
feature 161 (0.011582)
feature 121 (0.010990)
feature 156 (0.010333)
feature 166 (0.010280)
feature 24 (0.010127)
inner fold=1
accuracy=0.478260869565
feature 174 (0.030039)
feature 385 (0.023926)
feature 210 (0.023524)
feature 137 (0.023206)
feature 58 (0.022650)
feature 227 (0.020762)
feature 46 (0.019767)
feature 4 (0.019253)
feature 38 (0.019249)
feature 123 (0.017446)
feature 104 (0.016750)
feature 175 (0.016306)
feature 128 (0.015797)
feature 125 (0.015104)
feature 138 (0.014955)
feature 80 (0.013597)
feature 8 (0.013355)
feature 344 (0.012750)
feature 106 (0.012695)
feature 203 (0.012655)
feature 102 (0.012645)
feature 235 (0.012384)
feature 3 (0.012203)
feature 129 (0.012073)
feature 55 (0.011791)
feature 54 (0.011718)
feature 18 (0.011603)
feature 464 (0.011294)
feature 103 (0.010964)
feature 84 (0.010766)
inner fold=2
accuracy=0.488888888889
feature 129 (0.023072)
feature 134 (0.022769)
feature 101 (0.018957)
feature 171 (0.018852)
feature 213 (0.018224)
feature 151 (0.018038)
feature 149 (0.016211)
feature 128 (0.016185)
feature 142 (0.015862)
feature 184 (0.015334)
feature 43 (0.014758)
feature 362 (0.014424)
feature 110 (0.014340)
feature 216 (0.013788)
feature 395 (0.012800)
feature 78 (0.012777)
feature 55 (0.012342)
feature 46 (0.012080)
feature 358 (0.012040)
feature 173 (0.011864)
feature 135 (0.011480)
feature 30 (0.011394)
feature 139 (0.011280)
feature 140 (0.011162)
feature 203 (0.011139)
feature 143 (0.010921)
feature 42 (0.010379)
feature 74 (0.010041)
feature 164 (0.009906)
feature 159 (0.009572)
inner fold=3
accuracy=0.6
feature 129 (0.032786)
feature 82 (0.027289)
feature 106 (0.026175)
feature 166 (0.022133)
feature 43 (0.021468)
feature 46 (0.020987)
feature 294 (0.019679)
feature 167 (0.019214)
feature 168 (0.019177)
feature 79 (0.018160)
feature 194 (0.017270)
feature 131 (0.015038)
feature 207 (0.014318)
feature 174 (0.014179)
feature 156 (0.013731)
feature 127 (0.013404)
feature 208 (0.013087)
feature 152 (0.012263)
feature 200 (0.011661)
feature 272 (0.011507)
feature 159 (0.010872)
feature 203 (0.010856)
feature 464 (0.010661)
feature 73 (0.010037)
feature 70 (0.009916)
feature 394 (0.009912)
feature 227 (0.009792)
feature 171 (0.009678)
feature 362 (0.009578)
feature 186 (0.009559)
inner fold=4
accuracy=0.622222222222
feature 294 (0.041791)
feature 163 (0.028033)
feature 227 (0.026897)
feature 135 (0.023537)
feature 148 (0.020893)
feature 201 (0.020016)
feature 122 (0.018019)
feature 78 (0.017929)
feature 123 (0.017705)
feature 12 (0.017254)
feature 173 (0.016571)
feature 165 (0.016417)
feature 56 (0.015748)
feature 60 (0.015318)
feature 40 (0.015134)
feature 70 (0.014861)
feature 143 (0.014431)
feature 231 (0.014096)
feature 30 (0.013986)
feature 215 (0.013367)
feature 168 (0.012611)
feature 14 (0.012498)
feature 381 (0.012424)
feature 142 (0.011870)
feature 127 (0.011533)
feature 50 (0.011266)
feature 71 (0.011194)
feature 126 (0.010650)
feature 153 (0.010367)
feature 131 (0.009899)
inner fold=0
accuracy=0.608695652174
feature 81 (0.033120)
feature 294 (0.032889)
feature 215 (0.027425)
feature 33 (0.025051)
feature 129 (0.024037)
feature 104 (0.019384)
feature 201 (0.019235)
feature 222 (0.018592)
feature 213 (0.018245)
feature 231 (0.017097)
feature 57 (0.015801)
feature 275 (0.014033)
feature 135 (0.013838)
feature 84 (0.013730)
feature 171 (0.013003)
feature 12 (0.012944)
feature 153 (0.012550)
feature 133 (0.012465)
feature 50 (0.012322)
feature 18 (0.012160)
feature 199 (0.012115)
feature 42 (0.011748)
feature 148 (0.011409)
feature 46 (0.011286)
feature 99 (0.011003)
feature 172 (0.010408)
feature 53 (0.010266)
feature 214 (0.010240)
feature 58 (0.009948)
feature 249 (0.009747)
inner fold=1
accuracy=0.652173913043
feature 173 (0.031325)
feature 46 (0.024434)
feature 143 (0.022969)
feature 131 (0.020824)
feature 79 (0.019265)
feature 215 (0.018439)
feature 184 (0.018026)
feature 138 (0.017527)
feature 130 (0.017374)
feature 101 (0.016319)
feature 0 (0.015751)
feature 109 (0.015038)
feature 136 (0.014989)
feature 2 (0.014911)
feature 166 (0.014909)
feature 156 (0.014626)
feature 231 (0.014466)
feature 169 (0.014286)
feature 181 (0.014158)
feature 8 (0.013893)
feature 58 (0.012781)
feature 222 (0.012734)
feature 139 (0.012577)
feature 54 (0.012482)
feature 159 (0.012241)
feature 52 (0.011925)
feature 168 (0.011362)
feature 209 (0.011191)
feature 81 (0.011133)
feature 203 (0.010973)
inner fold=2
accuracy=0.533333333333
feature 294 (0.031228)
feature 78 (0.024937)
feature 385 (0.023569)
feature 168 (0.021860)
feature 81 (0.020819)
feature 57 (0.018515)
feature 159 (0.018198)
feature 208 (0.017692)
feature 126 (0.016505)
feature 156 (0.015635)
feature 84 (0.014613)
feature 165 (0.014246)
feature 142 (0.013721)
feature 24 (0.013375)
feature 58 (0.013335)
feature 158 (0.012174)
feature 442 (0.012087)
feature 129 (0.012010)
feature 43 (0.011951)
feature 52 (0.011603)
feature 33 (0.010981)
feature 173 (0.010845)
feature 80 (0.010821)
feature 234 (0.010750)
feature 101 (0.010481)
feature 14 (0.009916)
feature 63 (0.009825)
feature 164 (0.009800)
feature 187 (0.009697)
feature 372 (0.009595)
inner fold=3
accuracy=0.622222222222
feature 123 (0.022338)
feature 137 (0.021617)
feature 81 (0.021349)
feature 294 (0.020552)
feature 125 (0.020529)
feature 0 (0.019514)
feature 142 (0.018964)
feature 30 (0.018637)
feature 129 (0.018560)
feature 57 (0.016940)
feature 136 (0.016896)
feature 110 (0.015711)
feature 201 (0.015173)
feature 127 (0.013871)
feature 152 (0.013680)
feature 385 (0.013664)
feature 172 (0.013644)
feature 231 (0.013022)
feature 199 (0.011797)
feature 128 (0.011796)
feature 159 (0.011731)
feature 182 (0.011708)
feature 78 (0.011436)
feature 168 (0.011337)
feature 285 (0.011189)
feature 156 (0.010900)
feature 181 (0.010597)
feature 77 (0.010145)
feature 148 (0.009741)
feature 47 (0.009495)
inner fold=4
accuracy=0.533333333333

lay_id=7
feature 152 (0.038026)
feature 227 (0.035079)
feature 142 (0.027371)
feature 294 (0.025421)
feature 62 (0.020776)
feature 172 (0.020485)
feature 138 (0.019323)
feature 174 (0.017686)
feature 171 (0.017529)
feature 131 (0.017517)
feature 101 (0.017210)
feature 107 (0.017159)
feature 194 (0.017112)
feature 141 (0.015355)
feature 175 (0.015134)
feature 110 (0.014792)
feature 41 (0.014655)
feature 120 (0.014572)
feature 81 (0.014153)
feature 137 (0.013413)
feature 45 (0.013373)
feature 158 (0.013006)
feature 182 (0.012958)
feature 46 (0.012762)
feature 383 (0.012725)
feature 109 (0.011876)
feature 151 (0.011445)
feature 60 (0.011430)
feature 161 (0.010654)
feature 148 (0.010086)
inner fold=0
accuracy=0.673913043478
feature 172 (0.030633)
feature 46 (0.027485)
feature 82 (0.023749)
feature 294 (0.023650)
feature 114 (0.021276)
feature 158 (0.019329)
feature 362 (0.018354)
feature 216 (0.017995)
feature 125 (0.017172)
feature 390 (0.016276)
feature 137 (0.016163)
feature 146 (0.015944)
feature 30 (0.015106)
feature 48 (0.015084)
feature 183 (0.015046)
feature 35 (0.014916)
feature 231 (0.014549)
feature 159 (0.014535)
feature 171 (0.013976)
feature 108 (0.013938)
feature 141 (0.013560)
feature 122 (0.013496)
feature 28 (0.013432)
feature 138 (0.012340)
feature 202 (0.012171)
feature 154 (0.012013)
feature 105 (0.011874)
feature 102 (0.011763)
feature 227 (0.011302)
feature 110 (0.010445)
inner fold=1
accuracy=0.673913043478
feature 127 (0.033911)
feature 46 (0.025491)
feature 107 (0.024036)
feature 172 (0.023337)
feature 203 (0.020749)
feature 38 (0.020448)
feature 411 (0.020340)
feature 173 (0.019788)
feature 129 (0.018527)
feature 200 (0.017657)
feature 155 (0.015112)
feature 109 (0.014779)
feature 222 (0.014758)
feature 3 (0.014728)
feature 141 (0.014212)
feature 227 (0.013755)
feature 143 (0.013700)
feature 52 (0.013350)
feature 110 (0.013327)
feature 101 (0.013000)
feature 146 (0.012989)
feature 285 (0.012191)
feature 56 (0.011988)
feature 153 (0.011843)
feature 95 (0.011586)
feature 30 (0.011080)
feature 213 (0.010743)
feature 123 (0.010734)
feature 77 (0.010463)
feature 130 (0.010366)
inner fold=2
accuracy=0.577777777778
feature 168 (0.041545)
feature 174 (0.024848)
feature 172 (0.022870)
feature 81 (0.019867)
feature 156 (0.018868)
feature 120 (0.018664)
feature 47 (0.017507)
feature 171 (0.017212)
feature 155 (0.016892)
feature 294 (0.016396)
feature 130 (0.016134)
feature 51 (0.015200)
feature 58 (0.014604)
feature 203 (0.014153)
feature 125 (0.013783)
feature 126 (0.013779)
feature 182 (0.012994)
feature 53 (0.012611)
feature 152 (0.012437)
feature 164 (0.012392)
feature 142 (0.011735)
feature 210 (0.011604)
feature 101 (0.011565)
feature 349 (0.011368)
feature 46 (0.011200)
feature 60 (0.011083)
feature 140 (0.010892)
feature 5 (0.010374)
feature 209 (0.010247)
feature 100 (0.010151)
inner fold=3
accuracy=0.622222222222
feature 294 (0.033309)
feature 79 (0.030603)
feature 129 (0.030512)
feature 106 (0.023158)
feature 175 (0.022256)
feature 176 (0.022181)
feature 168 (0.020171)
feature 231 (0.019791)
feature 51 (0.019180)
feature 55 (0.018650)
feature 172 (0.018009)
feature 46 (0.017479)
feature 208 (0.016529)
feature 141 (0.016513)
feature 84 (0.016199)
feature 156 (0.014927)
feature 47 (0.013305)
feature 454 (0.012930)
feature 109 (0.012611)
feature 199 (0.012538)
feature 78 (0.012342)
feature 110 (0.011911)
feature 52 (0.010542)
feature 58 (0.010419)
feature 215 (0.010294)
feature 227 (0.010098)
feature 81 (0.009834)
feature 53 (0.009832)
feature 181 (0.009726)
feature 139 (0.009643)
inner fold=4
accuracy=0.577777777778
feature 138 (0.032021)
feature 129 (0.026669)
feature 69 (0.025847)
feature 172 (0.024835)
feature 231 (0.022455)
feature 148 (0.020422)
feature 171 (0.018628)
feature 153 (0.018107)
feature 211 (0.017538)
feature 84 (0.016925)
feature 214 (0.016528)
feature 139 (0.015968)
feature 137 (0.015911)
feature 294 (0.015677)
feature 103 (0.015464)
feature 53 (0.015225)
feature 135 (0.014975)
feature 210 (0.014373)
feature 134 (0.014172)
feature 78 (0.014057)
feature 56 (0.013763)
feature 52 (0.013709)
feature 207 (0.013583)
feature 130 (0.013347)
feature 29 (0.013259)
feature 110 (0.013192)
feature 174 (0.012790)
feature 33 (0.012461)
feature 234 (0.012298)
feature 79 (0.011968)
inner fold=0
accuracy=0.630434782609
feature 213 (0.023334)
feature 53 (0.020260)
feature 70 (0.020083)
feature 209 (0.019827)
feature 136 (0.017466)
feature 107 (0.016144)
feature 104 (0.014840)
feature 41 (0.014799)
feature 200 (0.014713)
feature 208 (0.014380)
feature 155 (0.014248)
feature 135 (0.013897)
feature 28 (0.013594)
feature 55 (0.013552)
feature 174 (0.013541)
feature 137 (0.013308)
feature 182 (0.013054)
feature 127 (0.012493)
feature 4 (0.012463)
feature 152 (0.012409)
feature 56 (0.012371)
feature 129 (0.012347)
feature 145 (0.011936)
feature 110 (0.011704)
feature 126 (0.011673)
feature 138 (0.011187)
feature 216 (0.011041)
feature 140 (0.010904)
feature 82 (0.010747)
feature 387 (0.010725)
inner fold=1
accuracy=0.717391304348
feature 78 (0.031722)
feature 110 (0.029469)
feature 122 (0.027298)
feature 155 (0.023718)
feature 172 (0.021235)
feature 294 (0.017800)
feature 42 (0.017570)
feature 142 (0.017548)
feature 14 (0.015978)
feature 171 (0.015364)
feature 137 (0.014949)
feature 135 (0.014361)
feature 168 (0.014084)
feature 130 (0.014014)
feature 121 (0.013473)
feature 140 (0.013461)
feature 184 (0.012717)
feature 454 (0.012289)
feature 58 (0.012062)
feature 143 (0.011985)
feature 174 (0.011696)
feature 26 (0.011566)
feature 63 (0.011204)
feature 131 (0.011184)
feature 158 (0.010975)
feature 146 (0.010885)
feature 235 (0.010816)
feature 164 (0.010654)
feature 166 (0.010543)
feature 126 (0.010470)
inner fold=2
accuracy=0.555555555556
feature 78 (0.026735)
feature 130 (0.023695)
feature 172 (0.023219)
feature 77 (0.023000)
feature 166 (0.019071)
feature 135 (0.018730)
feature 175 (0.017766)
feature 43 (0.017503)
feature 12 (0.017262)
feature 294 (0.016932)
feature 44 (0.016665)
feature 156 (0.015860)
feature 5 (0.015751)
feature 155 (0.014391)
feature 58 (0.014302)
feature 110 (0.014292)
feature 272 (0.014226)
feature 223 (0.013898)
feature 164 (0.013596)
feature 213 (0.013041)
feature 103 (0.012482)
feature 53 (0.012159)
feature 134 (0.012140)
feature 385 (0.012099)
feature 139 (0.011876)
feature 38 (0.011517)
feature 126 (0.011146)
feature 127 (0.010684)
feature 210 (0.010222)
feature 14 (0.010221)
inner fold=3
accuracy=0.622222222222
feature 30 (0.034996)
feature 172 (0.030095)
feature 4 (0.026961)
feature 170 (0.023928)
feature 362 (0.022931)
feature 115 (0.022361)
feature 142 (0.022351)
feature 157 (0.022136)
feature 78 (0.016865)
feature 46 (0.015944)
feature 173 (0.015302)
feature 222 (0.014747)
feature 207 (0.014148)
feature 209 (0.014057)
feature 385 (0.013940)
feature 227 (0.013776)
feature 148 (0.013392)
feature 200 (0.013009)
feature 101 (0.012742)
feature 14 (0.012094)
feature 171 (0.011902)
feature 174 (0.011607)
feature 79 (0.011529)
feature 77 (0.010944)
feature 69 (0.010554)
feature 224 (0.009965)
feature 85 (0.009861)
feature 138 (0.009810)
feature 175 (0.009792)
feature 122 (0.009725)
inner fold=4
accuracy=0.555555555556

lay_id=8
feature 213 (0.024883)
feature 235 (0.022664)
feature 155 (0.022645)
feature 52 (0.021992)
feature 5 (0.021812)
feature 38 (0.020226)
feature 134 (0.017248)
feature 81 (0.016969)
feature 395 (0.016689)
feature 55 (0.014938)
feature 137 (0.014759)
feature 101 (0.014402)
feature 174 (0.014375)
feature 4 (0.013968)
feature 78 (0.013766)
feature 184 (0.013542)
feature 152 (0.013247)
feature 115 (0.012858)
feature 46 (0.012567)
feature 294 (0.012528)
feature 84 (0.012296)
feature 301 (0.011867)
feature 159 (0.011720)
feature 211 (0.011572)
feature 272 (0.011251)
feature 142 (0.010909)
feature 107 (0.010682)
feature 61 (0.010503)
feature 50 (0.010302)
feature 227 (0.010213)
inner fold=0
accuracy=0.5
feature 138 (0.045135)
feature 57 (0.027636)
feature 174 (0.024206)
feature 77 (0.020191)
feature 134 (0.019512)
feature 62 (0.019452)
feature 209 (0.018199)
feature 60 (0.017554)
feature 207 (0.016977)
feature 171 (0.015594)
feature 385 (0.015442)
feature 81 (0.015226)
feature 24 (0.014730)
feature 28 (0.013498)
feature 12 (0.013328)
feature 160 (0.012919)
feature 203 (0.012673)
feature 136 (0.012404)
feature 185 (0.011959)
feature 464 (0.011794)
feature 125 (0.011688)
feature 208 (0.011627)
feature 21 (0.011346)
feature 58 (0.011335)
feature 4 (0.011312)
feature 135 (0.011157)
feature 75 (0.011088)
feature 84 (0.011024)
feature 42 (0.011001)
feature 222 (0.010857)
inner fold=1
accuracy=0.608695652174
feature 84 (0.035133)
feature 168 (0.025891)
feature 157 (0.021708)
feature 57 (0.019920)
feature 159 (0.019641)
feature 171 (0.018131)
feature 12 (0.017452)
feature 125 (0.017347)
feature 231 (0.015060)
feature 30 (0.014901)
feature 235 (0.014190)
feature 56 (0.013369)
feature 62 (0.012486)
feature 395 (0.012430)
feature 294 (0.012138)
feature 137 (0.011878)
feature 2 (0.011400)
feature 58 (0.011236)
feature 215 (0.010857)
feature 18 (0.010764)
feature 193 (0.010696)
feature 79 (0.010646)
feature 149 (0.010517)
feature 78 (0.010489)
feature 52 (0.010407)
feature 166 (0.010214)
feature 115 (0.010158)
feature 36 (0.010093)
feature 126 (0.010067)
feature 45 (0.010031)
inner fold=2
accuracy=0.622222222222
feature 46 (0.042564)
feature 168 (0.030004)
feature 172 (0.028865)
feature 3 (0.026386)
feature 60 (0.023782)
feature 152 (0.022962)
feature 142 (0.018890)
feature 174 (0.018376)
feature 128 (0.016506)
feature 209 (0.016184)
feature 159 (0.015881)
feature 203 (0.015215)
feature 55 (0.014756)
feature 173 (0.014299)
feature 0 (0.014030)
feature 18 (0.012744)
feature 390 (0.012702)
feature 40 (0.012085)
feature 107 (0.011642)
feature 216 (0.011556)
feature 294 (0.011516)
feature 408 (0.011212)
feature 53 (0.011036)
feature 123 (0.010917)
feature 169 (0.010898)
feature 125 (0.010672)
feature 163 (0.010625)
feature 120 (0.010444)
feature 136 (0.010031)
feature 13 (0.009925)
inner fold=3
accuracy=0.422222222222
feature 209 (0.023767)
feature 168 (0.023565)
feature 199 (0.020652)
feature 173 (0.019703)
feature 55 (0.019671)
feature 213 (0.019079)
feature 128 (0.018774)
feature 142 (0.017763)
feature 203 (0.016644)
feature 3 (0.016215)
feature 336 (0.015348)
feature 101 (0.014665)
feature 51 (0.014634)
feature 82 (0.014534)
feature 53 (0.014456)
feature 344 (0.014398)
feature 181 (0.013798)
feature 151 (0.013779)
feature 123 (0.013463)
feature 156 (0.013436)
feature 385 (0.013318)
feature 106 (0.013265)
feature 33 (0.013233)
feature 30 (0.013052)
feature 155 (0.012671)
feature 129 (0.012648)
feature 42 (0.012488)
feature 171 (0.012134)
feature 227 (0.011973)
feature 24 (0.011640)
inner fold=4
accuracy=0.622222222222
feature 81 (0.028095)
feature 142 (0.028021)
feature 143 (0.023353)
feature 57 (0.020392)
feature 173 (0.020177)
feature 211 (0.018739)
feature 77 (0.017460)
feature 358 (0.017055)
feature 222 (0.016986)
feature 215 (0.016371)
feature 231 (0.015485)
feature 14 (0.015327)
feature 120 (0.014809)
feature 128 (0.014654)
feature 140 (0.014280)
feature 84 (0.013851)
feature 148 (0.013784)
feature 159 (0.013621)
feature 52 (0.013438)
feature 152 (0.013005)
feature 12 (0.012470)
feature 38 (0.012399)
feature 1 (0.012116)
feature 127 (0.012042)
feature 141 (0.011757)
feature 46 (0.011722)
feature 194 (0.010630)
feature 193 (0.010356)
feature 123 (0.010333)
feature 53 (0.010296)
inner fold=0
accuracy=0.608695652174
feature 171 (0.034497)
feature 30 (0.024550)
feature 172 (0.023325)
feature 56 (0.018971)
feature 168 (0.018390)
feature 137 (0.017269)
feature 28 (0.016838)
feature 110 (0.016739)
feature 42 (0.016406)
feature 39 (0.015875)
feature 82 (0.015018)
feature 138 (0.014566)
feature 135 (0.014466)
feature 107 (0.014438)
feature 227 (0.013636)
feature 155 (0.013471)
feature 106 (0.013101)
feature 156 (0.012733)
feature 203 (0.012642)
feature 62 (0.012548)
feature 412 (0.012427)
feature 166 (0.012144)
feature 349 (0.012101)
feature 210 (0.011901)
feature 165 (0.011878)
feature 211 (0.011528)
feature 164 (0.011443)
feature 5 (0.011163)
feature 81 (0.010793)
feature 123 (0.010537)
inner fold=1
accuracy=0.608695652174
feature 139 (0.029268)
feature 172 (0.026387)
feature 114 (0.025621)
feature 137 (0.023856)
feature 44 (0.023083)
feature 71 (0.021149)
feature 42 (0.020322)
feature 166 (0.018783)
feature 155 (0.018547)
feature 30 (0.018358)
feature 208 (0.017816)
feature 131 (0.016908)
feature 38 (0.016774)
feature 53 (0.016296)
feature 194 (0.016114)
feature 175 (0.016097)
feature 135 (0.015515)
feature 171 (0.014564)
feature 73 (0.013705)
feature 70 (0.013493)
feature 95 (0.011927)
feature 127 (0.011786)
feature 81 (0.011596)
feature 0 (0.011282)
feature 389 (0.010964)
feature 213 (0.010914)
feature 85 (0.010784)
feature 227 (0.010697)
feature 54 (0.010581)
feature 174 (0.010522)
inner fold=2
accuracy=0.6
feature 168 (0.041703)
feature 78 (0.031559)
feature 152 (0.028629)
feature 158 (0.027795)
feature 46 (0.026303)
feature 227 (0.025166)
feature 174 (0.024152)
feature 130 (0.019780)
feature 43 (0.018479)
feature 175 (0.016875)
feature 105 (0.015076)
feature 209 (0.014725)
feature 155 (0.014497)
feature 151 (0.013680)
feature 148 (0.013137)
feature 102 (0.012470)
feature 143 (0.012317)
feature 164 (0.012232)
feature 294 (0.011899)
feature 134 (0.011856)
feature 115 (0.011763)
feature 139 (0.011696)
feature 123 (0.011671)
feature 27 (0.011649)
feature 157 (0.011611)
feature 344 (0.011358)
feature 77 (0.010724)
feature 194 (0.010675)
feature 63 (0.010472)
feature 200 (0.010383)
inner fold=3
accuracy=0.622222222222
feature 53 (0.023016)
feature 137 (0.022326)
feature 123 (0.020855)
feature 168 (0.018786)
feature 128 (0.018362)
feature 171 (0.017812)
feature 160 (0.017659)
feature 54 (0.017612)
feature 152 (0.017586)
feature 107 (0.017556)
feature 81 (0.017264)
feature 18 (0.016861)
feature 372 (0.016701)
feature 163 (0.015549)
feature 165 (0.014584)
feature 71 (0.014582)
feature 199 (0.014365)
feature 148 (0.014364)
feature 127 (0.014050)
feature 34 (0.013834)
feature 58 (0.013544)
feature 46 (0.013398)
feature 202 (0.013182)
feature 79 (0.011653)
feature 38 (0.011319)
feature 110 (0.010930)
feature 62 (0.010853)
feature 40 (0.010846)
feature 210 (0.010809)
feature 164 (0.010802)
inner fold=4
accuracy=0.666666666667

outer fold 5
lay_id=0
feature 377 (0.024854)
feature 162 (0.022845)
feature 198 (0.021060)
feature 199 (0.020646)
feature 231 (0.020316)
feature 138 (0.019979)
feature 167 (0.018907)
feature 160 (0.018834)
feature 211 (0.018414)
feature 290 (0.017995)
feature 144 (0.017134)
feature 54 (0.016957)
feature 358 (0.016905)
feature 48 (0.016412)
feature 29 (0.016403)
feature 168 (0.016099)
feature 223 (0.015313)
feature 124 (0.014719)
feature 79 (0.014462)
feature 26 (0.013149)
feature 379 (0.012683)
feature 33 (0.012173)
feature 155 (0.012061)
feature 386 (0.011755)
feature 58 (0.011427)
feature 149 (0.011411)
feature 163 (0.011368)
feature 186 (0.011330)
feature 219 (0.011179)
feature 119 (0.011151)
inner fold=0
accuracy=0.565217391304
feature 132 (0.030256)
feature 167 (0.026969)
feature 212 (0.025960)
feature 116 (0.025906)
feature 155 (0.022418)
feature 39 (0.019570)
feature 227 (0.019428)
feature 133 (0.019208)
feature 125 (0.018557)
feature 124 (0.018283)
feature 42 (0.018240)
feature 195 (0.016202)
feature 122 (0.015983)
feature 140 (0.015710)
feature 164 (0.015600)
feature 30 (0.013813)
feature 51 (0.013672)
feature 53 (0.013398)
feature 159 (0.012778)
feature 179 (0.012591)
feature 49 (0.012276)
feature 211 (0.011865)
feature 48 (0.011472)
feature 75 (0.011471)
feature 46 (0.011414)
feature 129 (0.011211)
feature 220 (0.011180)
feature 268 (0.010908)
feature 52 (0.010810)
feature 209 (0.010686)
inner fold=1
accuracy=0.5
feature 147 (0.033021)
feature 42 (0.030078)
feature 196 (0.029466)
feature 39 (0.024803)
feature 77 (0.022772)
feature 445 (0.021590)
feature 290 (0.021177)
feature 51 (0.019243)
feature 139 (0.018471)
feature 100 (0.018240)
feature 340 (0.017524)
feature 171 (0.016612)
feature 134 (0.016014)
feature 48 (0.014911)
feature 199 (0.014400)
feature 116 (0.012767)
feature 127 (0.011599)
feature 52 (0.011597)
feature 156 (0.011510)
feature 155 (0.011219)
feature 165 (0.011142)
feature 169 (0.011092)
feature 168 (0.011076)
feature 210 (0.010864)
feature 438 (0.010817)
feature 36 (0.010638)
feature 122 (0.010558)
feature 381 (0.010235)
feature 377 (0.010136)
feature 197 (0.009803)
inner fold=2
accuracy=0.673913043478
feature 168 (0.031231)
feature 199 (0.029471)
feature 25 (0.020568)
feature 119 (0.018938)
feature 133 (0.017707)
feature 127 (0.017707)
feature 340 (0.016620)
feature 20 (0.016584)
feature 151 (0.016290)
feature 125 (0.015461)
feature 204 (0.015175)
feature 122 (0.014551)
feature 74 (0.014488)
feature 103 (0.014209)
feature 77 (0.013670)
feature 175 (0.012900)
feature 205 (0.012611)
feature 160 (0.012555)
feature 178 (0.012477)
feature 184 (0.012449)
feature 138 (0.012108)
feature 52 (0.012035)
feature 154 (0.011980)
feature 290 (0.011939)
feature 358 (0.011760)
feature 207 (0.011660)
feature 137 (0.011258)
feature 180 (0.011203)
feature 78 (0.010953)
feature 198 (0.010845)
inner fold=3
accuracy=0.555555555556
feature 24 (0.029519)
feature 26 (0.027096)
feature 203 (0.026205)
feature 122 (0.024129)
feature 130 (0.022964)
feature 125 (0.021602)
feature 52 (0.019805)
feature 40 (0.018736)
feature 144 (0.018513)
feature 138 (0.018433)
feature 336 (0.018142)
feature 204 (0.017721)
feature 139 (0.017430)
feature 51 (0.016841)
feature 132 (0.016134)
feature 134 (0.015666)
feature 119 (0.015582)
feature 162 (0.015173)
feature 290 (0.014911)
feature 155 (0.014854)
feature 30 (0.014719)
feature 154 (0.014585)
feature 153 (0.014377)
feature 42 (0.014224)
feature 121 (0.013196)
feature 223 (0.013002)
feature 207 (0.012833)
feature 227 (0.012258)
feature 345 (0.011705)
feature 127 (0.011150)
inner fold=4
accuracy=0.511111111111
feature 39 (0.039043)
feature 168 (0.035401)
feature 227 (0.027190)
feature 34 (0.026340)
feature 164 (0.021753)
feature 54 (0.020294)
feature 29 (0.019145)
feature 131 (0.018340)
feature 169 (0.017928)
feature 223 (0.017779)
feature 56 (0.015804)
feature 118 (0.015718)
feature 30 (0.014980)
feature 381 (0.014651)
feature 199 (0.014615)
feature 25 (0.014134)
feature 75 (0.014037)
feature 1 (0.013208)
feature 209 (0.013207)
feature 97 (0.012753)
feature 123 (0.012561)
feature 148 (0.012391)
feature 205 (0.012308)
feature 130 (0.011869)
feature 124 (0.011617)
feature 154 (0.011289)
feature 51 (0.011099)
feature 49 (0.011076)
feature 178 (0.010583)
feature 111 (0.010402)
inner fold=0
accuracy=0.586956521739
feature 125 (0.037297)
feature 168 (0.027725)
feature 14 (0.023832)
feature 199 (0.022189)
feature 74 (0.018657)
feature 160 (0.017115)
feature 223 (0.017111)
feature 42 (0.015579)
feature 80 (0.015043)
feature 139 (0.014619)
feature 227 (0.014519)
feature 141 (0.014012)
feature 77 (0.012820)
feature 218 (0.012578)
feature 124 (0.011697)
feature 117 (0.011106)
feature 161 (0.011027)
feature 75 (0.010992)
feature 147 (0.010796)
feature 177 (0.010652)
feature 340 (0.010612)
feature 138 (0.010497)
feature 25 (0.010340)
feature 206 (0.010126)
feature 17 (0.009897)
feature 143 (0.009802)
feature 0 (0.009707)
feature 49 (0.009698)
feature 360 (0.009517)
feature 183 (0.009332)
inner fold=1
accuracy=0.630434782609
feature 167 (0.045097)
feature 268 (0.030363)
feature 218 (0.023716)
feature 198 (0.023259)
feature 39 (0.022164)
feature 199 (0.021626)
feature 290 (0.021220)
feature 4 (0.021160)
feature 8 (0.021055)
feature 24 (0.020735)
feature 162 (0.018850)
feature 26 (0.017353)
feature 30 (0.016409)
feature 122 (0.015211)
feature 0 (0.014505)
feature 29 (0.014418)
feature 139 (0.013843)
feature 78 (0.013640)
feature 51 (0.012867)
feature 38 (0.012319)
feature 178 (0.012179)
feature 127 (0.012157)
feature 345 (0.011755)
feature 42 (0.011374)
feature 95 (0.011273)
feature 152 (0.010879)
feature 134 (0.010485)
feature 377 (0.009963)
feature 170 (0.009894)
feature 54 (0.009548)
inner fold=2
accuracy=0.630434782609
feature 199 (0.027883)
feature 54 (0.025613)
feature 169 (0.025399)
feature 77 (0.023544)
feature 212 (0.020985)
feature 184 (0.018845)
feature 34 (0.018750)
feature 111 (0.018405)
feature 162 (0.018307)
feature 29 (0.016278)
feature 38 (0.015929)
feature 125 (0.015785)
feature 103 (0.015327)
feature 116 (0.014743)
feature 195 (0.014379)
feature 218 (0.014323)
feature 171 (0.013927)
feature 1 (0.013170)
feature 290 (0.013069)
feature 168 (0.013066)
feature 51 (0.012876)
feature 438 (0.012782)
feature 134 (0.012626)
feature 75 (0.012173)
feature 281 (0.011998)
feature 297 (0.011861)
feature 138 (0.011503)
feature 450 (0.011273)
feature 215 (0.011241)
feature 123 (0.010687)
inner fold=3
accuracy=0.6
feature 290 (0.034234)
feature 54 (0.020104)
feature 168 (0.019893)
feature 78 (0.019152)
feature 162 (0.018195)
feature 227 (0.017328)
feature 124 (0.017128)
feature 163 (0.016408)
feature 223 (0.015852)
feature 152 (0.015847)
feature 77 (0.014337)
feature 450 (0.014152)
feature 121 (0.013901)
feature 154 (0.013600)
feature 42 (0.013598)
feature 49 (0.013406)
feature 164 (0.012721)
feature 123 (0.012509)
feature 198 (0.012206)
feature 404 (0.012100)
feature 100 (0.012094)
feature 170 (0.011656)
feature 10 (0.011628)
feature 165 (0.011295)
feature 160 (0.011134)
feature 1 (0.011127)
feature 218 (0.010870)
feature 110 (0.010865)
feature 26 (0.010826)
feature 0 (0.010819)
inner fold=4
accuracy=0.533333333333

lay_id=1
feature 58 (0.032314)
feature 294 (0.029313)
feature 166 (0.028715)
feature 203 (0.025911)
feature 127 (0.025552)
feature 155 (0.022273)
feature 184 (0.020921)
feature 172 (0.019858)
feature 168 (0.016483)
feature 173 (0.016139)
feature 207 (0.016037)
feature 137 (0.015861)
feature 69 (0.015655)
feature 77 (0.014647)
feature 159 (0.013673)
feature 143 (0.013095)
feature 174 (0.013079)
feature 223 (0.012483)
feature 110 (0.012454)
feature 167 (0.012381)
feature 102 (0.012249)
feature 152 (0.012224)
feature 129 (0.012158)
feature 50 (0.011844)
feature 151 (0.011274)
feature 175 (0.011040)
feature 27 (0.010945)
feature 138 (0.010728)
feature 121 (0.010265)
feature 42 (0.010234)
inner fold=0
accuracy=0.630434782609
feature 202 (0.029216)
feature 294 (0.027579)
feature 58 (0.026072)
feature 231 (0.023912)
feature 101 (0.020478)
feature 33 (0.018827)
feature 134 (0.018237)
feature 135 (0.018085)
feature 164 (0.016466)
feature 12 (0.015840)
feature 52 (0.015114)
feature 123 (0.015091)
feature 60 (0.014891)
feature 115 (0.014740)
feature 287 (0.014721)
feature 73 (0.014450)
feature 38 (0.013508)
feature 129 (0.012914)
feature 213 (0.012509)
feature 216 (0.012175)
feature 143 (0.011897)
feature 208 (0.011823)
feature 168 (0.011574)
feature 46 (0.011400)
feature 344 (0.011328)
feature 80 (0.010735)
feature 126 (0.010692)
feature 45 (0.010668)
feature 153 (0.010556)
feature 383 (0.010546)
inner fold=1
accuracy=0.695652173913
feature 151 (0.027544)
feature 101 (0.025165)
feature 294 (0.023168)
feature 202 (0.019933)
feature 158 (0.019889)
feature 13 (0.019111)
feature 123 (0.019070)
feature 1 (0.018835)
feature 166 (0.018088)
feature 82 (0.017905)
feature 172 (0.017888)
feature 203 (0.015240)
feature 29 (0.014916)
feature 97 (0.014906)
feature 55 (0.014490)
feature 79 (0.012622)
feature 152 (0.011297)
feature 219 (0.011104)
feature 42 (0.010684)
feature 104 (0.010277)
feature 130 (0.010257)
feature 54 (0.010110)
feature 56 (0.010079)
feature 62 (0.009989)
feature 134 (0.009898)
feature 12 (0.009447)
feature 127 (0.009315)
feature 126 (0.009161)
feature 125 (0.009111)
feature 122 (0.008818)
inner fold=2
accuracy=0.630434782609
feature 203 (0.035183)
feature 156 (0.025499)
feature 134 (0.024089)
feature 383 (0.023316)
feature 208 (0.021755)
feature 138 (0.020871)
feature 172 (0.019619)
feature 159 (0.018977)
feature 294 (0.018272)
feature 123 (0.016234)
feature 2 (0.016001)
feature 174 (0.015824)
feature 33 (0.015682)
feature 110 (0.014932)
feature 81 (0.014448)
feature 50 (0.013891)
feature 149 (0.012772)
feature 84 (0.012660)
feature 1 (0.012444)
feature 385 (0.012215)
feature 46 (0.011970)
feature 168 (0.011964)
feature 207 (0.011790)
feature 79 (0.011690)
feature 231 (0.011431)
feature 99 (0.010866)
feature 58 (0.010857)
feature 184 (0.010716)
feature 82 (0.010310)
feature 52 (0.010133)
inner fold=3
accuracy=0.822222222222
feature 14 (0.026009)
feature 172 (0.024865)
feature 84 (0.024581)
feature 294 (0.024509)
feature 144 (0.023597)
feature 79 (0.022051)
feature 235 (0.020204)
feature 18 (0.017666)
feature 152 (0.016693)
feature 175 (0.016157)
feature 203 (0.015780)
feature 45 (0.015608)
feature 171 (0.015370)
feature 46 (0.014407)
feature 63 (0.014130)
feature 136 (0.012920)
feature 0 (0.012537)
feature 164 (0.012461)
feature 125 (0.012252)
feature 156 (0.012066)
feature 24 (0.011381)
feature 78 (0.011358)
feature 36 (0.011267)
feature 44 (0.011076)
feature 145 (0.010883)
feature 57 (0.010555)
feature 30 (0.010294)
feature 107 (0.010228)
feature 151 (0.009616)
feature 42 (0.009585)
inner fold=4
accuracy=0.533333333333
feature 137 (0.032094)
feature 173 (0.026481)
feature 142 (0.022739)
feature 1 (0.021867)
feature 156 (0.021639)
feature 442 (0.019682)
feature 102 (0.017647)
feature 30 (0.017586)
feature 12 (0.017449)
feature 165 (0.016975)
feature 100 (0.015907)
feature 168 (0.015900)
feature 138 (0.015472)
feature 161 (0.014912)
feature 152 (0.014607)
feature 42 (0.014467)
feature 128 (0.013287)
feature 53 (0.012894)
feature 285 (0.011166)
feature 202 (0.011118)
feature 123 (0.011057)
feature 171 (0.011035)
feature 151 (0.010765)
feature 13 (0.010484)
feature 157 (0.010459)
feature 122 (0.010263)
feature 139 (0.010220)
feature 201 (0.010107)
feature 78 (0.009857)
feature 209 (0.009851)
inner fold=0
accuracy=0.652173913043
feature 231 (0.034187)
feature 129 (0.029234)
feature 172 (0.028089)
feature 14 (0.023305)
feature 294 (0.019033)
feature 50 (0.016726)
feature 161 (0.015936)
feature 83 (0.014989)
feature 211 (0.014570)
feature 84 (0.014096)
feature 215 (0.014034)
feature 199 (0.013992)
feature 209 (0.013698)
feature 56 (0.013644)
feature 188 (0.013544)
feature 157 (0.012802)
feature 55 (0.012477)
feature 174 (0.011436)
feature 53 (0.011421)
feature 1 (0.010519)
feature 235 (0.010435)
feature 44 (0.010428)
feature 5 (0.010383)
feature 155 (0.010352)
feature 110 (0.010317)
feature 28 (0.010293)
feature 104 (0.010274)
feature 122 (0.010050)
feature 127 (0.010040)
feature 34 (0.009998)
inner fold=1
accuracy=0.673913043478
feature 235 (0.030904)
feature 213 (0.023265)
feature 344 (0.021596)
feature 44 (0.021443)
feature 38 (0.020651)
feature 215 (0.020090)
feature 172 (0.018917)
feature 167 (0.018492)
feature 129 (0.018360)
feature 294 (0.017445)
feature 138 (0.017432)
feature 18 (0.016485)
feature 152 (0.015398)
feature 52 (0.014779)
feature 115 (0.014385)
feature 164 (0.014210)
feature 77 (0.013762)
feature 103 (0.013421)
feature 216 (0.013292)
feature 135 (0.013250)
feature 51 (0.013058)
feature 101 (0.012916)
feature 159 (0.012190)
feature 17 (0.011693)
feature 142 (0.011305)
feature 106 (0.011241)
feature 126 (0.010606)
feature 171 (0.010536)
feature 21 (0.010496)
feature 15 (0.010208)
inner fold=2
accuracy=0.565217391304
feature 166 (0.032401)
feature 272 (0.018248)
feature 135 (0.017655)
feature 344 (0.017480)
feature 134 (0.017323)
feature 84 (0.016664)
feature 381 (0.016369)
feature 114 (0.015553)
feature 56 (0.015414)
feature 53 (0.015021)
feature 46 (0.014850)
feature 78 (0.014649)
feature 174 (0.014458)
feature 57 (0.014221)
feature 283 (0.013828)
feature 362 (0.012939)
feature 139 (0.012523)
feature 164 (0.012192)
feature 110 (0.012185)
feature 120 (0.012103)
feature 29 (0.011886)
feature 464 (0.011773)
feature 200 (0.011737)
feature 18 (0.011638)
feature 294 (0.011581)
feature 136 (0.011553)
feature 55 (0.011447)
feature 165 (0.011397)
feature 122 (0.011026)
feature 203 (0.011011)
inner fold=3
accuracy=0.577777777778
feature 231 (0.038875)
feature 70 (0.024191)
feature 102 (0.021135)
feature 223 (0.020663)
feature 135 (0.020216)
feature 1 (0.017187)
feature 81 (0.016694)
feature 60 (0.016623)
feature 42 (0.016390)
feature 62 (0.016240)
feature 193 (0.015940)
feature 164 (0.015802)
feature 383 (0.015350)
feature 69 (0.015116)
feature 44 (0.015027)
feature 80 (0.014964)
feature 115 (0.014702)
feature 165 (0.014322)
feature 78 (0.013626)
feature 139 (0.013608)
feature 122 (0.013414)
feature 2 (0.012833)
feature 294 (0.012732)
feature 123 (0.012232)
feature 215 (0.011804)
feature 182 (0.011529)
feature 172 (0.011200)
feature 30 (0.010932)
feature 168 (0.010631)
feature 29 (0.010463)
inner fold=4
accuracy=0.6

lay_id=2
feature 166 (0.031608)
feature 168 (0.030895)
feature 77 (0.023690)
feature 123 (0.023549)
feature 272 (0.023142)
feature 1 (0.021754)
feature 157 (0.019034)
feature 235 (0.017069)
feature 203 (0.016607)
feature 209 (0.016527)
feature 344 (0.016022)
feature 30 (0.015174)
feature 38 (0.014980)
feature 156 (0.014748)
feature 134 (0.014660)
feature 114 (0.014265)
feature 161 (0.014262)
feature 55 (0.013962)
feature 207 (0.013860)
feature 153 (0.013766)
feature 142 (0.013478)
feature 216 (0.012710)
feature 155 (0.012262)
feature 81 (0.012171)
feature 138 (0.012130)
feature 109 (0.011548)
feature 208 (0.011233)
feature 53 (0.011207)
feature 3 (0.010772)
feature 144 (0.010758)
inner fold=0
accuracy=0.586956521739
feature 164 (0.026998)
feature 81 (0.024479)
feature 60 (0.022768)
feature 171 (0.020066)
feature 385 (0.019635)
feature 82 (0.018212)
feature 173 (0.017493)
feature 38 (0.016667)
feature 136 (0.016156)
feature 161 (0.015940)
feature 272 (0.015382)
feature 216 (0.015233)
feature 174 (0.014469)
feature 110 (0.014454)
feature 135 (0.013890)
feature 53 (0.013873)
feature 102 (0.013789)
feature 125 (0.013747)
feature 55 (0.013711)
feature 139 (0.013683)
feature 215 (0.013587)
feature 172 (0.013552)
feature 151 (0.013545)
feature 214 (0.013394)
feature 175 (0.012050)
feature 123 (0.011827)
feature 224 (0.011613)
feature 200 (0.010856)
feature 57 (0.010536)
feature 99 (0.010426)
inner fold=1
accuracy=0.695652173913
feature 30 (0.037425)
feature 136 (0.033014)
feature 0 (0.020779)
feature 203 (0.019696)
feature 155 (0.017278)
feature 60 (0.016644)
feature 134 (0.016084)
feature 171 (0.015608)
feature 34 (0.015042)
feature 151 (0.014046)
feature 125 (0.013934)
feature 166 (0.013873)
feature 164 (0.013285)
feature 287 (0.012929)
feature 219 (0.012821)
feature 120 (0.011875)
feature 159 (0.011816)
feature 395 (0.011392)
feature 153 (0.011182)
feature 100 (0.011144)
feature 121 (0.011103)
feature 110 (0.010765)
feature 5 (0.010731)
feature 123 (0.010577)
feature 138 (0.010546)
feature 161 (0.010493)
feature 56 (0.010363)
feature 78 (0.010321)
feature 115 (0.010299)
feature 172 (0.010112)
inner fold=2
accuracy=0.673913043478
feature 412 (0.021487)
feature 77 (0.021346)
feature 123 (0.020322)
feature 106 (0.019547)
feature 172 (0.019482)
feature 442 (0.018620)
feature 235 (0.016930)
feature 129 (0.016924)
feature 209 (0.016697)
feature 53 (0.016609)
feature 130 (0.015556)
feature 175 (0.014279)
feature 125 (0.014047)
feature 107 (0.013658)
feature 165 (0.013041)
feature 60 (0.012853)
feature 35 (0.012103)
feature 1 (0.012095)
feature 193 (0.012079)
feature 4 (0.012026)
feature 29 (0.011736)
feature 203 (0.011518)
feature 183 (0.011410)
feature 78 (0.011292)
feature 166 (0.011070)
feature 207 (0.011043)
feature 136 (0.010917)
feature 201 (0.010631)
feature 169 (0.010529)
feature 151 (0.010524)
inner fold=3
accuracy=0.533333333333
feature 231 (0.040107)
feature 294 (0.027336)
feature 30 (0.025947)
feature 148 (0.021975)
feature 235 (0.021852)
feature 77 (0.020677)
feature 209 (0.019948)
feature 158 (0.018532)
feature 160 (0.018375)
feature 215 (0.017678)
feature 156 (0.015840)
feature 3 (0.015443)
feature 58 (0.014787)
feature 136 (0.014731)
feature 79 (0.014349)
feature 51 (0.014175)
feature 140 (0.013612)
feature 141 (0.013428)
feature 167 (0.013134)
feature 171 (0.013129)
feature 174 (0.012846)
feature 183 (0.012717)
feature 213 (0.012569)
feature 152 (0.012457)
feature 106 (0.012096)
feature 222 (0.012057)
feature 129 (0.011993)
feature 103 (0.011205)
feature 168 (0.009890)
feature 149 (0.009649)
inner fold=4
accuracy=0.555555555556
feature 294 (0.039522)
feature 156 (0.036958)
feature 97 (0.026204)
feature 207 (0.023512)
feature 58 (0.023114)
feature 14 (0.020465)
feature 34 (0.020235)
feature 201 (0.019023)
feature 214 (0.018458)
feature 46 (0.017119)
feature 172 (0.016556)
feature 171 (0.016213)
feature 55 (0.014897)
feature 85 (0.014788)
feature 44 (0.014667)
feature 1 (0.014432)
feature 166 (0.013856)
feature 151 (0.013824)
feature 110 (0.013714)
feature 0 (0.013665)
feature 235 (0.013656)
feature 128 (0.012487)
feature 33 (0.011890)
feature 29 (0.011815)
feature 131 (0.011740)
feature 38 (0.011528)
feature 148 (0.011415)
feature 54 (0.011196)
feature 141 (0.010573)
feature 227 (0.010217)
inner fold=0
accuracy=0.652173913043
feature 294 (0.044626)
feature 44 (0.032246)
feature 172 (0.025443)
feature 53 (0.022238)
feature 208 (0.022125)
feature 214 (0.021984)
feature 138 (0.019910)
feature 136 (0.018084)
feature 168 (0.017022)
feature 142 (0.016704)
feature 3 (0.016361)
feature 141 (0.015983)
feature 213 (0.014640)
feature 56 (0.014420)
feature 429 (0.013352)
feature 129 (0.012550)
feature 105 (0.012140)
feature 203 (0.011983)
feature 147 (0.011958)
feature 103 (0.011160)
feature 52 (0.011118)
feature 173 (0.010388)
feature 33 (0.010344)
feature 13 (0.010233)
feature 155 (0.010230)
feature 40 (0.010036)
feature 164 (0.009974)
feature 81 (0.009972)
feature 137 (0.009827)
feature 79 (0.009809)
inner fold=1
accuracy=0.695652173913
feature 123 (0.027735)
feature 216 (0.025903)
feature 38 (0.025602)
feature 134 (0.023574)
feature 81 (0.020644)
feature 43 (0.018488)
feature 161 (0.018419)
feature 143 (0.017619)
feature 158 (0.016844)
feature 171 (0.016841)
feature 12 (0.015916)
feature 173 (0.015653)
feature 182 (0.015234)
feature 55 (0.015123)
feature 110 (0.014482)
feature 172 (0.014391)
feature 70 (0.013815)
feature 151 (0.013602)
feature 203 (0.013596)
feature 24 (0.013512)
feature 53 (0.013452)
feature 159 (0.013055)
feature 362 (0.012741)
feature 180 (0.011657)
feature 449 (0.011554)
feature 170 (0.011335)
feature 35 (0.011322)
feature 136 (0.011244)
feature 29 (0.011205)
feature 50 (0.011092)
inner fold=2
accuracy=0.804347826087
feature 122 (0.031301)
feature 175 (0.030078)
feature 123 (0.027906)
feature 109 (0.021907)
feature 164 (0.021443)
feature 139 (0.021392)
feature 294 (0.020856)
feature 34 (0.019621)
feature 21 (0.018307)
feature 129 (0.017958)
feature 4 (0.017836)
feature 390 (0.017654)
feature 202 (0.016976)
feature 173 (0.016367)
feature 181 (0.016050)
feature 77 (0.015151)
feature 81 (0.015043)
feature 131 (0.013786)
feature 137 (0.013542)
feature 136 (0.013110)
feature 43 (0.012268)
feature 151 (0.012218)
feature 110 (0.011855)
feature 148 (0.011633)
feature 153 (0.010726)
feature 24 (0.010622)
feature 12 (0.010461)
feature 287 (0.010286)
feature 143 (0.009983)
feature 71 (0.009749)
inner fold=3
accuracy=0.6
feature 44 (0.026684)
feature 81 (0.023387)
feature 106 (0.021996)
feature 53 (0.018519)
feature 108 (0.018426)
feature 30 (0.018345)
feature 166 (0.017876)
feature 129 (0.017273)
feature 0 (0.016857)
feature 152 (0.016689)
feature 127 (0.016424)
feature 188 (0.016030)
feature 42 (0.015528)
feature 136 (0.015502)
feature 208 (0.014948)
feature 202 (0.013945)
feature 169 (0.013783)
feature 82 (0.013776)
feature 4 (0.013329)
feature 138 (0.013094)
feature 153 (0.013076)
feature 56 (0.012900)
feature 156 (0.012825)
feature 222 (0.012371)
feature 454 (0.012062)
feature 155 (0.011882)
feature 164 (0.011787)
feature 172 (0.011629)
feature 173 (0.011360)
feature 43 (0.011222)
inner fold=4
accuracy=0.644444444444

lay_id=3
feature 2 (0.025700)
feature 207 (0.023997)
feature 164 (0.019834)
feature 21 (0.019298)
feature 155 (0.018958)
feature 24 (0.018881)
feature 172 (0.018464)
feature 3 (0.017651)
feature 33 (0.015963)
feature 30 (0.015309)
feature 71 (0.015205)
feature 272 (0.014656)
feature 152 (0.014543)
feature 77 (0.014521)
feature 187 (0.014286)
feature 109 (0.014242)
feature 81 (0.013602)
feature 165 (0.013476)
feature 166 (0.012947)
feature 46 (0.012748)
feature 84 (0.012668)
feature 301 (0.012296)
feature 80 (0.012295)
feature 135 (0.012282)
feature 58 (0.012195)
feature 344 (0.011772)
feature 0 (0.011699)
feature 184 (0.011692)
feature 55 (0.011434)
feature 235 (0.011211)
inner fold=0
accuracy=0.652173913043
feature 14 (0.021373)
feature 158 (0.018642)
feature 372 (0.016924)
feature 69 (0.016407)
feature 169 (0.015354)
feature 43 (0.015260)
feature 55 (0.014605)
feature 83 (0.014186)
feature 79 (0.014160)
feature 202 (0.013977)
feature 171 (0.013836)
feature 114 (0.013277)
feature 173 (0.013079)
feature 165 (0.012976)
feature 211 (0.012640)
feature 97 (0.012292)
feature 294 (0.012144)
feature 128 (0.012106)
feature 188 (0.011942)
feature 129 (0.011907)
feature 176 (0.011782)
feature 46 (0.011653)
feature 127 (0.011430)
feature 153 (0.011365)
feature 62 (0.011242)
feature 139 (0.010859)
feature 216 (0.010825)
feature 130 (0.010801)
feature 82 (0.010768)
feature 73 (0.010764)
inner fold=1
accuracy=0.565217391304
feature 2 (0.039643)
feature 123 (0.037810)
feature 215 (0.026592)
feature 151 (0.021078)
feature 129 (0.019393)
feature 44 (0.019375)
feature 294 (0.018959)
feature 17 (0.018663)
feature 171 (0.018581)
feature 138 (0.017468)
feature 172 (0.016684)
feature 213 (0.016432)
feature 183 (0.014712)
feature 158 (0.013923)
feature 156 (0.013654)
feature 84 (0.013512)
feature 165 (0.013469)
feature 231 (0.013406)
feature 136 (0.013108)
feature 235 (0.012894)
feature 227 (0.012629)
feature 166 (0.012456)
feature 83 (0.011297)
feature 201 (0.011283)
feature 155 (0.011229)
feature 174 (0.011218)
feature 45 (0.011176)
feature 128 (0.011017)
feature 168 (0.010514)
feature 175 (0.010152)
inner fold=2
accuracy=0.565217391304
feature 171 (0.028608)
feature 123 (0.020790)
feature 58 (0.019597)
feature 344 (0.019457)
feature 227 (0.019352)
feature 115 (0.018798)
feature 159 (0.018148)
feature 4 (0.015169)
feature 174 (0.015064)
feature 222 (0.014669)
feature 55 (0.014659)
feature 156 (0.014103)
feature 134 (0.013916)
feature 188 (0.013177)
feature 137 (0.012891)
feature 110 (0.012875)
feature 43 (0.012695)
feature 161 (0.012649)
feature 18 (0.012612)
feature 231 (0.012344)
feature 5 (0.012316)
feature 199 (0.012135)
feature 33 (0.012121)
feature 194 (0.011985)
feature 78 (0.011739)
feature 2 (0.011694)
feature 69 (0.011223)
feature 38 (0.010769)
feature 294 (0.010510)
feature 84 (0.010429)
inner fold=3
accuracy=0.688888888889
feature 134 (0.024195)
feature 235 (0.021675)
feature 166 (0.020773)
feature 167 (0.019098)
feature 215 (0.018450)
feature 173 (0.018205)
feature 60 (0.017817)
feature 81 (0.017411)
feature 442 (0.016977)
feature 272 (0.016862)
feature 139 (0.016769)
feature 199 (0.015279)
feature 294 (0.014898)
feature 55 (0.013819)
feature 362 (0.013663)
feature 175 (0.013294)
feature 130 (0.012463)
feature 138 (0.011423)
feature 201 (0.011276)
feature 227 (0.011182)
feature 122 (0.011164)
feature 145 (0.011098)
feature 106 (0.011084)
feature 454 (0.010847)
feature 216 (0.010845)
feature 395 (0.010813)
feature 412 (0.010269)
feature 170 (0.010100)
feature 128 (0.009988)
feature 4 (0.009862)
inner fold=4
accuracy=0.622222222222
feature 171 (0.043128)
feature 227 (0.030911)
feature 130 (0.028441)
feature 231 (0.028136)
feature 46 (0.027850)
feature 134 (0.021884)
feature 180 (0.018257)
feature 142 (0.017444)
feature 344 (0.017262)
feature 115 (0.016396)
feature 105 (0.015971)
feature 120 (0.014959)
feature 207 (0.014555)
feature 24 (0.014388)
feature 167 (0.013716)
feature 168 (0.013611)
feature 109 (0.012641)
feature 166 (0.012534)
feature 148 (0.011882)
feature 43 (0.011685)
feature 157 (0.011587)
feature 44 (0.011575)
feature 138 (0.011311)
feature 159 (0.011270)
feature 275 (0.011188)
feature 156 (0.011038)
feature 412 (0.010857)
feature 18 (0.010680)
feature 81 (0.010667)
feature 381 (0.010551)
inner fold=0
accuracy=0.565217391304
feature 344 (0.032682)
feature 34 (0.028166)
feature 107 (0.022806)
feature 55 (0.022694)
feature 164 (0.020123)
feature 14 (0.019977)
feature 3 (0.019499)
feature 56 (0.018983)
feature 44 (0.017863)
feature 148 (0.016588)
feature 184 (0.016028)
feature 158 (0.015978)
feature 70 (0.015744)
feature 227 (0.015352)
feature 123 (0.015112)
feature 84 (0.014902)
feature 40 (0.013490)
feature 120 (0.013349)
feature 139 (0.012528)
feature 153 (0.012481)
feature 110 (0.011466)
feature 157 (0.011399)
feature 194 (0.011057)
feature 51 (0.011038)
feature 38 (0.011028)
feature 129 (0.010531)
feature 80 (0.010466)
feature 50 (0.010357)
feature 167 (0.010287)
feature 188 (0.010061)
inner fold=1
accuracy=0.608695652174
feature 166 (0.033607)
feature 35 (0.030304)
feature 172 (0.027187)
feature 2 (0.024999)
feature 161 (0.024765)
feature 3 (0.022572)
feature 81 (0.022067)
feature 142 (0.021443)
feature 168 (0.019707)
feature 167 (0.019439)
feature 171 (0.018941)
feature 152 (0.018400)
feature 46 (0.016837)
feature 164 (0.015899)
feature 55 (0.014888)
feature 18 (0.014744)
feature 155 (0.014717)
feature 157 (0.014108)
feature 231 (0.013858)
feature 80 (0.013847)
feature 344 (0.013686)
feature 34 (0.012999)
feature 175 (0.012843)
feature 159 (0.012308)
feature 227 (0.012283)
feature 24 (0.012281)
feature 44 (0.011830)
feature 148 (0.011368)
feature 294 (0.011307)
feature 33 (0.010565)
inner fold=2
accuracy=0.652173913043
feature 168 (0.026787)
feature 129 (0.026580)
feature 43 (0.025817)
feature 78 (0.020346)
feature 231 (0.019948)
feature 152 (0.019530)
feature 134 (0.019449)
feature 109 (0.019383)
feature 110 (0.019205)
feature 42 (0.018909)
feature 136 (0.018766)
feature 156 (0.018384)
feature 30 (0.017473)
feature 344 (0.016989)
feature 158 (0.016959)
feature 173 (0.015800)
feature 36 (0.014109)
feature 38 (0.013830)
feature 199 (0.012929)
feature 171 (0.012801)
feature 115 (0.012796)
feature 51 (0.012423)
feature 5 (0.012355)
feature 107 (0.012350)
feature 149 (0.012322)
feature 44 (0.012062)
feature 106 (0.011967)
feature 142 (0.011362)
feature 34 (0.011269)
feature 420 (0.011021)
inner fold=3
accuracy=0.666666666667
feature 231 (0.031926)
feature 172 (0.030931)
feature 139 (0.023281)
feature 152 (0.016770)
feature 136 (0.016147)
feature 84 (0.015980)
feature 158 (0.015855)
feature 159 (0.015291)
feature 81 (0.015038)
feature 201 (0.014898)
feature 110 (0.014219)
feature 164 (0.013694)
feature 126 (0.013494)
feature 24 (0.013342)
feature 176 (0.013338)
feature 60 (0.012879)
feature 235 (0.012845)
feature 222 (0.012815)
feature 4 (0.012786)
feature 393 (0.012084)
feature 44 (0.012079)
feature 12 (0.011064)
feature 123 (0.011032)
feature 38 (0.010984)
feature 169 (0.010968)
feature 184 (0.010939)
feature 216 (0.010685)
feature 129 (0.010595)
feature 115 (0.010313)
feature 46 (0.010282)
inner fold=4
accuracy=0.555555555556

lay_id=4
feature 60 (0.023879)
feature 164 (0.023421)
feature 344 (0.022064)
feature 79 (0.021848)
feature 207 (0.020668)
feature 83 (0.019602)
feature 152 (0.019594)
feature 214 (0.018961)
feature 138 (0.018077)
feature 85 (0.017885)
feature 213 (0.017749)
feature 294 (0.017241)
feature 174 (0.016409)
feature 385 (0.016344)
feature 199 (0.015982)
feature 114 (0.014979)
feature 148 (0.014792)
feature 103 (0.014656)
feature 128 (0.014531)
feature 130 (0.013454)
feature 176 (0.013049)
feature 53 (0.012708)
feature 81 (0.012348)
feature 127 (0.012289)
feature 143 (0.011154)
feature 168 (0.011078)
feature 54 (0.011020)
feature 147 (0.010478)
feature 390 (0.010362)
feature 46 (0.010251)
inner fold=0
accuracy=0.608695652174
feature 156 (0.030072)
feature 56 (0.021354)
feature 174 (0.021345)
feature 46 (0.018543)
feature 77 (0.018412)
feature 165 (0.017310)
feature 157 (0.017297)
feature 231 (0.017051)
feature 152 (0.016751)
feature 81 (0.016022)
feature 136 (0.015963)
feature 168 (0.014225)
feature 52 (0.014181)
feature 43 (0.013440)
feature 201 (0.013381)
feature 208 (0.013149)
feature 58 (0.012991)
feature 2 (0.012800)
feature 60 (0.012718)
feature 148 (0.012668)
feature 63 (0.012582)
feature 14 (0.011323)
feature 151 (0.011088)
feature 18 (0.011084)
feature 169 (0.010793)
feature 83 (0.010691)
feature 213 (0.010344)
feature 180 (0.010289)
feature 123 (0.010010)
feature 37 (0.009925)
inner fold=1
accuracy=0.586956521739
feature 129 (0.028346)
feature 81 (0.027428)
feature 164 (0.021364)
feature 156 (0.019177)
feature 168 (0.018741)
feature 174 (0.018164)
feature 172 (0.017973)
feature 235 (0.017404)
feature 231 (0.016660)
feature 193 (0.015917)
feature 58 (0.015075)
feature 80 (0.013966)
feature 412 (0.013349)
feature 294 (0.013252)
feature 84 (0.013131)
feature 4 (0.012592)
feature 24 (0.012489)
feature 30 (0.012458)
feature 122 (0.012199)
feature 53 (0.012004)
feature 39 (0.011938)
feature 57 (0.011677)
feature 152 (0.011589)
feature 123 (0.011449)
feature 136 (0.011251)
feature 82 (0.010804)
feature 33 (0.010554)
feature 69 (0.010523)
feature 203 (0.010168)
feature 211 (0.010115)
inner fold=2
accuracy=0.652173913043
feature 46 (0.025137)
feature 58 (0.024882)
feature 156 (0.022024)
feature 107 (0.021992)
feature 4 (0.020836)
feature 171 (0.020217)
feature 454 (0.019761)
feature 131 (0.019576)
feature 81 (0.019117)
feature 152 (0.019052)
feature 383 (0.017701)
feature 148 (0.015357)
feature 215 (0.015095)
feature 272 (0.014825)
feature 44 (0.014684)
feature 123 (0.014615)
feature 201 (0.014485)
feature 56 (0.014081)
feature 442 (0.013679)
feature 43 (0.013661)
feature 172 (0.013614)
feature 5 (0.012679)
feature 164 (0.012209)
feature 238 (0.011510)
feature 21 (0.011492)
feature 53 (0.011134)
feature 77 (0.010837)
feature 182 (0.010694)
feature 301 (0.010347)
feature 203 (0.010274)
inner fold=3
accuracy=0.666666666667
feature 81 (0.041220)
feature 203 (0.019403)
feature 110 (0.019374)
feature 137 (0.019147)
feature 174 (0.018582)
feature 157 (0.018200)
feature 175 (0.016605)
feature 158 (0.016590)
feature 223 (0.015580)
feature 215 (0.015553)
feature 48 (0.014464)
feature 275 (0.014103)
feature 60 (0.013770)
feature 168 (0.013550)
feature 69 (0.013382)
feature 213 (0.013335)
feature 385 (0.013281)
feature 183 (0.013043)
feature 207 (0.012952)
feature 38 (0.012889)
feature 42 (0.012741)
feature 166 (0.011823)
feature 372 (0.011647)
feature 300 (0.010970)
feature 72 (0.010730)
feature 70 (0.010288)
feature 136 (0.010152)
feature 5 (0.009872)
feature 171 (0.009815)
feature 24 (0.009664)
inner fold=4
accuracy=0.622222222222
feature 203 (0.022188)
feature 123 (0.019184)
feature 107 (0.018799)
feature 222 (0.018467)
feature 194 (0.018352)
feature 4 (0.018087)
feature 18 (0.018020)
feature 385 (0.017855)
feature 156 (0.017460)
feature 81 (0.015555)
feature 42 (0.015314)
feature 62 (0.014928)
feature 46 (0.014829)
feature 120 (0.014499)
feature 30 (0.014375)
feature 70 (0.014253)
feature 155 (0.013977)
feature 172 (0.013816)
feature 160 (0.013199)
feature 157 (0.013063)
feature 211 (0.012396)
feature 126 (0.012281)
feature 227 (0.011968)
feature 159 (0.011625)
feature 216 (0.011586)
feature 171 (0.011518)
feature 1 (0.011391)
feature 173 (0.011241)
feature 134 (0.010874)
feature 132 (0.010768)
inner fold=0
accuracy=0.5
feature 138 (0.040630)
feature 120 (0.029650)
feature 57 (0.028692)
feature 81 (0.027505)
feature 148 (0.023310)
feature 172 (0.023253)
feature 97 (0.021070)
feature 188 (0.018840)
feature 166 (0.017765)
feature 168 (0.016598)
feature 156 (0.016224)
feature 161 (0.015716)
feature 55 (0.015698)
feature 294 (0.014786)
feature 174 (0.014539)
feature 4 (0.013648)
feature 152 (0.013607)
feature 103 (0.013049)
feature 44 (0.012789)
feature 344 (0.012217)
feature 3 (0.011551)
feature 2 (0.011320)
feature 201 (0.011089)
feature 159 (0.010790)
feature 202 (0.010404)
feature 285 (0.010265)
feature 46 (0.009640)
feature 164 (0.009626)
feature 144 (0.009307)
feature 114 (0.009196)
inner fold=1
accuracy=0.630434782609
feature 168 (0.035714)
feature 151 (0.026926)
feature 231 (0.025204)
feature 235 (0.021855)
feature 123 (0.021664)
feature 157 (0.020493)
feature 294 (0.020321)
feature 171 (0.020296)
feature 129 (0.020239)
feature 141 (0.019799)
feature 81 (0.018413)
feature 155 (0.017956)
feature 70 (0.017816)
feature 30 (0.016846)
feature 174 (0.016619)
feature 207 (0.016101)
feature 69 (0.015610)
feature 14 (0.014338)
feature 114 (0.014052)
feature 131 (0.013809)
feature 71 (0.013259)
feature 115 (0.012954)
feature 394 (0.012691)
feature 166 (0.012406)
feature 57 (0.012141)
feature 40 (0.011898)
feature 134 (0.011611)
feature 159 (0.010693)
feature 145 (0.010525)
feature 203 (0.010320)
inner fold=2
accuracy=0.608695652174
feature 235 (0.030806)
feature 156 (0.030640)
feature 168 (0.024953)
feature 81 (0.023196)
feature 78 (0.023166)
feature 84 (0.022787)
feature 42 (0.018216)
feature 52 (0.017303)
feature 200 (0.017286)
feature 134 (0.016862)
feature 46 (0.016834)
feature 114 (0.016320)
feature 125 (0.015652)
feature 442 (0.015241)
feature 211 (0.014994)
feature 164 (0.014912)
feature 77 (0.014016)
feature 148 (0.013661)
feature 129 (0.012475)
feature 136 (0.011764)
feature 123 (0.011726)
feature 137 (0.011446)
feature 184 (0.011212)
feature 53 (0.011134)
feature 158 (0.010257)
feature 163 (0.010142)
feature 215 (0.009992)
feature 2 (0.009713)
feature 135 (0.009239)
feature 209 (0.009025)
inner fold=3
accuracy=0.688888888889
feature 219 (0.036167)
feature 227 (0.026125)
feature 171 (0.023608)
feature 344 (0.021575)
feature 231 (0.021065)
feature 55 (0.019870)
feature 174 (0.018223)
feature 141 (0.018186)
feature 168 (0.017877)
feature 235 (0.017712)
feature 152 (0.016781)
feature 79 (0.016627)
feature 53 (0.016067)
feature 101 (0.015480)
feature 164 (0.015306)
feature 161 (0.014948)
feature 138 (0.014687)
feature 134 (0.013254)
feature 115 (0.012634)
feature 130 (0.012583)
feature 61 (0.012051)
feature 285 (0.011886)
feature 223 (0.011522)
feature 43 (0.011289)
feature 57 (0.011190)
feature 62 (0.010834)
feature 15 (0.010655)
feature 166 (0.010645)
feature 97 (0.010361)
feature 27 (0.009994)
inner fold=4
accuracy=0.711111111111

outer fold 6
lay_id=0
feature 180 (0.036294)
feature 211 (0.023239)
feature 54 (0.022928)
feature 121 (0.022102)
feature 199 (0.021498)
feature 290 (0.020696)
feature 39 (0.019935)
feature 119 (0.019675)
feature 218 (0.019210)
feature 167 (0.019185)
feature 40 (0.018692)
feature 164 (0.018265)
feature 77 (0.017822)
feature 42 (0.017339)
feature 138 (0.016573)
feature 149 (0.014477)
feature 163 (0.014255)
feature 116 (0.013513)
feature 99 (0.013335)
feature 53 (0.013309)
feature 223 (0.013110)
feature 17 (0.012626)
feature 168 (0.012561)
feature 43 (0.012078)
feature 179 (0.012006)
feature 377 (0.011953)
feature 144 (0.011506)
feature 124 (0.011076)
feature 196 (0.011028)
feature 157 (0.010395)
inner fold=0
accuracy=0.673913043478
feature 167 (0.033102)
feature 116 (0.033100)
feature 125 (0.022579)
feature 212 (0.021238)
feature 161 (0.019115)
feature 133 (0.018541)
feature 204 (0.018038)
feature 0 (0.017742)
feature 36 (0.016946)
feature 78 (0.016904)
feature 155 (0.016334)
feature 58 (0.015942)
feature 123 (0.015834)
feature 144 (0.014850)
feature 102 (0.013600)
feature 53 (0.012838)
feature 220 (0.012515)
feature 51 (0.012333)
feature 199 (0.012265)
feature 147 (0.012110)
feature 177 (0.012032)
feature 130 (0.012012)
feature 210 (0.011894)
feature 211 (0.011667)
feature 151 (0.010787)
feature 77 (0.010739)
feature 75 (0.010468)
feature 122 (0.010399)
feature 169 (0.010168)
feature 50 (0.009952)
inner fold=1
accuracy=0.54347826087
feature 51 (0.027481)
feature 116 (0.021103)
feature 445 (0.019787)
feature 74 (0.019686)
feature 135 (0.019382)
feature 199 (0.019214)
feature 54 (0.018837)
feature 20 (0.018061)
feature 39 (0.017994)
feature 167 (0.017644)
feature 209 (0.016935)
feature 106 (0.016775)
feature 121 (0.015942)
feature 195 (0.015621)
feature 290 (0.014652)
feature 127 (0.014081)
feature 156 (0.014056)
feature 122 (0.013670)
feature 48 (0.013597)
feature 75 (0.013127)
feature 35 (0.012839)
feature 111 (0.012203)
feature 42 (0.012169)
feature 17 (0.011782)
feature 41 (0.011657)
feature 170 (0.011528)
feature 80 (0.011398)
feature 171 (0.011207)
feature 165 (0.010511)
feature 118 (0.010316)
inner fold=2
accuracy=0.608695652174
feature 77 (0.031884)
feature 180 (0.028541)
feature 122 (0.023372)
feature 42 (0.021346)
feature 164 (0.019438)
feature 124 (0.019275)
feature 34 (0.016313)
feature 169 (0.015831)
feature 209 (0.015620)
feature 136 (0.015155)
feature 102 (0.014757)
feature 184 (0.014601)
feature 73 (0.014122)
feature 438 (0.013689)
feature 52 (0.013464)
feature 123 (0.011897)
feature 178 (0.011653)
feature 69 (0.011459)
feature 79 (0.011456)
feature 227 (0.011242)
feature 119 (0.011232)
feature 26 (0.011033)
feature 74 (0.010995)
feature 154 (0.010745)
feature 290 (0.010726)
feature 183 (0.010666)
feature 54 (0.010399)
feature 91 (0.010315)
feature 121 (0.010217)
feature 106 (0.010209)
inner fold=3
accuracy=0.577777777778
feature 30 (0.021900)
feature 209 (0.021882)
feature 134 (0.021582)
feature 168 (0.021247)
feature 290 (0.019337)
feature 164 (0.019125)
feature 10 (0.017708)
feature 99 (0.016466)
feature 54 (0.016401)
feature 127 (0.016068)
feature 124 (0.015968)
feature 126 (0.015432)
feature 132 (0.015187)
feature 199 (0.015037)
feature 119 (0.014776)
feature 13 (0.013423)
feature 58 (0.012610)
feature 179 (0.012582)
feature 151 (0.012146)
feature 56 (0.012063)
feature 52 (0.011959)
feature 65 (0.011792)
feature 78 (0.011758)
feature 51 (0.010960)
feature 106 (0.010667)
feature 171 (0.010505)
feature 204 (0.010469)
feature 35 (0.010271)
feature 44 (0.010180)
feature 153 (0.009785)
inner fold=4
accuracy=0.622222222222
feature 168 (0.025675)
feature 223 (0.024280)
feature 119 (0.022123)
feature 209 (0.022106)
feature 133 (0.020316)
feature 130 (0.020116)
feature 39 (0.019315)
feature 169 (0.019234)
feature 164 (0.018939)
feature 156 (0.018486)
feature 124 (0.017570)
feature 207 (0.015306)
feature 199 (0.014531)
feature 40 (0.013888)
feature 122 (0.013829)
feature 121 (0.013528)
feature 138 (0.012948)
feature 163 (0.012447)
feature 47 (0.012426)
feature 78 (0.012258)
feature 53 (0.012212)
feature 66 (0.011648)
feature 154 (0.011275)
feature 153 (0.011244)
feature 126 (0.011239)
feature 155 (0.010890)
feature 171 (0.010874)
feature 135 (0.010468)
feature 51 (0.010248)
feature 204 (0.010239)
inner fold=0
accuracy=0.652173913043
feature 164 (0.050712)
feature 170 (0.041733)
feature 167 (0.029010)
feature 135 (0.028345)
feature 10 (0.021088)
feature 152 (0.019550)
feature 161 (0.018823)
feature 199 (0.018595)
feature 169 (0.018193)
feature 125 (0.017700)
feature 180 (0.016892)
feature 20 (0.016326)
feature 42 (0.016236)
feature 134 (0.015907)
feature 77 (0.015663)
feature 155 (0.015551)
feature 227 (0.015546)
feature 196 (0.015421)
feature 105 (0.015161)
feature 160 (0.015133)
feature 230 (0.013784)
feature 59 (0.012977)
feature 49 (0.012729)
feature 52 (0.012346)
feature 14 (0.011706)
feature 450 (0.010420)
feature 100 (0.010362)
feature 75 (0.010162)
feature 268 (0.010128)
feature 102 (0.009961)
inner fold=1
accuracy=0.608695652174
feature 167 (0.022563)
feature 152 (0.021094)
feature 124 (0.019910)
feature 127 (0.018346)
feature 193 (0.017943)
feature 51 (0.017077)
feature 290 (0.016779)
feature 196 (0.015858)
feature 211 (0.015024)
feature 184 (0.014984)
feature 47 (0.014504)
feature 77 (0.014010)
feature 78 (0.013723)
feature 42 (0.012988)
feature 162 (0.012961)
feature 207 (0.012911)
feature 79 (0.012821)
feature 10 (0.012279)
feature 118 (0.012115)
feature 340 (0.011729)
feature 297 (0.011670)
feature 148 (0.011333)
feature 166 (0.011180)
feature 227 (0.010952)
feature 190 (0.010936)
feature 38 (0.010567)
feature 4 (0.010311)
feature 179 (0.010001)
feature 170 (0.009955)
feature 95 (0.009905)
inner fold=2
accuracy=0.565217391304
feature 164 (0.036127)
feature 167 (0.029376)
feature 198 (0.022967)
feature 130 (0.021661)
feature 199 (0.021547)
feature 122 (0.020336)
feature 59 (0.019576)
feature 131 (0.019459)
feature 38 (0.019368)
feature 138 (0.018966)
feature 169 (0.018649)
feature 196 (0.015952)
feature 171 (0.015746)
feature 52 (0.015741)
feature 209 (0.015664)
feature 184 (0.014973)
feature 168 (0.014781)
feature 161 (0.014548)
feature 26 (0.014505)
feature 116 (0.014168)
feature 86 (0.013288)
feature 165 (0.013271)
feature 42 (0.013132)
feature 93 (0.012824)
feature 78 (0.012822)
feature 124 (0.012600)
feature 49 (0.012480)
feature 125 (0.011843)
feature 219 (0.011761)
feature 8 (0.011462)
inner fold=3
accuracy=0.6
feature 164 (0.045512)
feature 290 (0.037501)
feature 152 (0.029629)
feature 110 (0.026473)
feature 132 (0.026011)
feature 199 (0.024798)
feature 77 (0.024512)
feature 223 (0.023248)
feature 29 (0.021505)
feature 204 (0.017714)
feature 74 (0.017601)
feature 30 (0.016017)
feature 50 (0.015477)
feature 198 (0.014224)
feature 124 (0.013804)
feature 125 (0.012105)
feature 227 (0.011914)
feature 46 (0.011848)
feature 44 (0.011407)
feature 105 (0.011290)
feature 40 (0.011178)
feature 75 (0.011171)
feature 54 (0.011121)
feature 209 (0.010922)
feature 144 (0.010791)
feature 151 (0.010715)
feature 31 (0.010578)
feature 13 (0.010557)
feature 10 (0.010400)
feature 126 (0.010384)
inner fold=4
accuracy=0.488888888889

lay_id=1
feature 168 (0.027708)
feature 231 (0.026668)
feature 106 (0.025286)
feature 44 (0.020445)
feature 201 (0.018808)
feature 109 (0.018506)
feature 58 (0.018231)
feature 1 (0.018178)
feature 0 (0.017581)
feature 34 (0.016135)
feature 143 (0.015189)
feature 139 (0.015167)
feature 294 (0.014725)
feature 145 (0.014715)
feature 30 (0.014184)
feature 62 (0.014116)
feature 18 (0.013838)
feature 138 (0.013783)
feature 155 (0.013250)
feature 60 (0.013190)
feature 135 (0.012887)
feature 209 (0.012275)
feature 171 (0.012094)
feature 184 (0.012016)
feature 51 (0.011529)
feature 125 (0.011518)
feature 181 (0.011230)
feature 287 (0.011135)
feature 211 (0.011120)
feature 172 (0.011024)
inner fold=0
accuracy=0.673913043478
feature 58 (0.029277)
feature 167 (0.026596)
feature 294 (0.024923)
feature 202 (0.024849)
feature 168 (0.023720)
feature 77 (0.020916)
feature 214 (0.018929)
feature 129 (0.018746)
feature 184 (0.018577)
feature 227 (0.018276)
feature 62 (0.017258)
feature 172 (0.016947)
feature 38 (0.016170)
feature 12 (0.016017)
feature 97 (0.015318)
feature 176 (0.014657)
feature 213 (0.013750)
feature 208 (0.013459)
feature 136 (0.013345)
feature 134 (0.013042)
feature 159 (0.012944)
feature 71 (0.012725)
feature 193 (0.012281)
feature 174 (0.011903)
feature 83 (0.011528)
feature 18 (0.011220)
feature 14 (0.011144)
feature 173 (0.010706)
feature 53 (0.010527)
feature 99 (0.010500)
inner fold=1
accuracy=0.5
feature 202 (0.032895)
feature 294 (0.032676)
feature 73 (0.026716)
feature 171 (0.024406)
feature 82 (0.022113)
feature 18 (0.021866)
feature 134 (0.020565)
feature 381 (0.019841)
feature 45 (0.018814)
feature 143 (0.016640)
feature 157 (0.016618)
feature 14 (0.016485)
feature 231 (0.016228)
feature 61 (0.015386)
feature 172 (0.015242)
feature 164 (0.015025)
feature 41 (0.014724)
feature 188 (0.014557)
feature 155 (0.014533)
feature 12 (0.013269)
feature 165 (0.012805)
feature 142 (0.012782)
feature 168 (0.012577)
feature 213 (0.012169)
feature 56 (0.011424)
feature 442 (0.011312)
feature 135 (0.011271)
feature 4 (0.010687)
feature 35 (0.010684)
feature 21 (0.010563)
inner fold=2
accuracy=0.630434782609
feature 294 (0.046419)
feature 81 (0.029001)
feature 158 (0.026516)
feature 50 (0.025004)
feature 165 (0.024119)
feature 174 (0.020891)
feature 129 (0.019618)
feature 168 (0.018812)
feature 110 (0.018508)
feature 211 (0.017010)
feature 202 (0.015939)
feature 100 (0.015521)
feature 199 (0.014567)
feature 159 (0.014529)
feature 44 (0.014412)
feature 53 (0.013997)
feature 145 (0.013672)
feature 383 (0.013305)
feature 107 (0.013224)
feature 126 (0.013162)
feature 214 (0.012922)
feature 55 (0.012588)
feature 8 (0.012500)
feature 30 (0.012381)
feature 71 (0.011870)
feature 200 (0.011803)
feature 101 (0.011008)
feature 12 (0.010696)
feature 148 (0.010502)
feature 3 (0.009948)
inner fold=3
accuracy=0.622222222222
feature 294 (0.040663)
feature 30 (0.033685)
feature 14 (0.028371)
feature 168 (0.028212)
feature 199 (0.026605)
feature 171 (0.022689)
feature 235 (0.021224)
feature 144 (0.018443)
feature 175 (0.018065)
feature 52 (0.016595)
feature 222 (0.015660)
feature 174 (0.014326)
feature 156 (0.013829)
feature 216 (0.013309)
feature 152 (0.013145)
feature 84 (0.012818)
feature 102 (0.012386)
feature 155 (0.011963)
feature 4 (0.011301)
feature 83 (0.011202)
feature 78 (0.011149)
feature 80 (0.010442)
feature 181 (0.010216)
feature 173 (0.010105)
feature 18 (0.009747)
feature 114 (0.009703)
feature 50 (0.009702)
feature 207 (0.009686)
feature 122 (0.009554)
feature 161 (0.009375)
inner fold=4
accuracy=0.577777777778
feature 294 (0.023315)
feature 102 (0.021927)
feature 231 (0.018431)
feature 165 (0.017982)
feature 209 (0.017500)
feature 156 (0.017169)
feature 152 (0.015942)
feature 53 (0.015500)
feature 78 (0.014957)
feature 100 (0.014257)
feature 110 (0.014253)
feature 171 (0.014116)
feature 173 (0.013872)
feature 227 (0.013692)
feature 125 (0.013443)
feature 85 (0.013385)
feature 44 (0.013339)
feature 52 (0.012862)
feature 158 (0.012669)
feature 385 (0.012552)
feature 155 (0.012398)
feature 17 (0.012276)
feature 40 (0.012251)
feature 390 (0.012032)
feature 58 (0.011635)
feature 105 (0.011436)
feature 161 (0.011320)
feature 176 (0.011301)
feature 442 (0.011259)
feature 1 (0.010891)
inner fold=0
accuracy=0.54347826087
feature 231 (0.036204)
feature 171 (0.020483)
feature 172 (0.020049)
feature 138 (0.018797)
feature 78 (0.018450)
feature 214 (0.018439)
feature 18 (0.018171)
feature 235 (0.016692)
feature 201 (0.016267)
feature 52 (0.015419)
feature 55 (0.015341)
feature 39 (0.014811)
feature 340 (0.014288)
feature 174 (0.014282)
feature 148 (0.014110)
feature 209 (0.013873)
feature 62 (0.013702)
feature 125 (0.013231)
feature 139 (0.013230)
feature 84 (0.012885)
feature 135 (0.012833)
feature 101 (0.012738)
feature 133 (0.012242)
feature 109 (0.012027)
feature 115 (0.011542)
feature 104 (0.011390)
feature 46 (0.011376)
feature 385 (0.011253)
feature 151 (0.010550)
feature 166 (0.010539)
inner fold=1
accuracy=0.630434782609
feature 81 (0.033235)
feature 227 (0.027462)
feature 128 (0.022394)
feature 171 (0.021699)
feature 294 (0.019452)
feature 231 (0.019382)
feature 30 (0.019279)
feature 184 (0.018061)
feature 14 (0.017947)
feature 174 (0.017489)
feature 235 (0.017145)
feature 203 (0.015354)
feature 159 (0.015311)
feature 110 (0.014995)
feature 164 (0.014937)
feature 137 (0.014426)
feature 63 (0.013800)
feature 77 (0.013398)
feature 78 (0.012608)
feature 127 (0.012482)
feature 130 (0.012348)
feature 135 (0.012191)
feature 58 (0.011863)
feature 27 (0.011755)
feature 140 (0.011659)
feature 43 (0.011594)
feature 151 (0.011382)
feature 155 (0.011362)
feature 125 (0.010801)
feature 103 (0.010607)
inner fold=2
accuracy=0.652173913043
feature 12 (0.025270)
feature 81 (0.023858)
feature 171 (0.022651)
feature 203 (0.021563)
feature 122 (0.020239)
feature 156 (0.019673)
feature 200 (0.018852)
feature 454 (0.017554)
feature 151 (0.015837)
feature 58 (0.015147)
feature 155 (0.015123)
feature 77 (0.015079)
feature 44 (0.015037)
feature 24 (0.014611)
feature 101 (0.014445)
feature 18 (0.014169)
feature 51 (0.013836)
feature 135 (0.013415)
feature 134 (0.013403)
feature 46 (0.012664)
feature 158 (0.012659)
feature 84 (0.012341)
feature 42 (0.012253)
feature 194 (0.012120)
feature 126 (0.011493)
feature 199 (0.011382)
feature 56 (0.011234)
feature 57 (0.011171)
feature 188 (0.010242)
feature 60 (0.010224)
inner fold=3
accuracy=0.6
feature 231 (0.047203)
feature 58 (0.026325)
feature 227 (0.025239)
feature 109 (0.023773)
feature 21 (0.023089)
feature 122 (0.020558)
feature 235 (0.020201)
feature 165 (0.018237)
feature 134 (0.017235)
feature 153 (0.015872)
feature 127 (0.015858)
feature 199 (0.015397)
feature 43 (0.015167)
feature 152 (0.015031)
feature 383 (0.013955)
feature 110 (0.013727)
feature 33 (0.013687)
feature 156 (0.012928)
feature 60 (0.012849)
feature 98 (0.012222)
feature 188 (0.012160)
feature 168 (0.012061)
feature 45 (0.012034)
feature 201 (0.011503)
feature 44 (0.011029)
feature 174 (0.010972)
feature 82 (0.010906)
feature 377 (0.010271)
feature 381 (0.010159)
feature 301 (0.010046)
inner fold=4
accuracy=0.488888888889

lay_id=2
feature 203 (0.026211)
feature 43 (0.026072)
feature 128 (0.025548)
feature 123 (0.024333)
feature 81 (0.023530)
feature 231 (0.023130)
feature 235 (0.019587)
feature 138 (0.019288)
feature 159 (0.018955)
feature 114 (0.018724)
feature 109 (0.018476)
feature 164 (0.016577)
feature 199 (0.015501)
feature 156 (0.014161)
feature 172 (0.013894)
feature 80 (0.013319)
feature 35 (0.013299)
feature 30 (0.012369)
feature 110 (0.011971)
feature 166 (0.011968)
feature 141 (0.011717)
feature 27 (0.010680)
feature 165 (0.010671)
feature 78 (0.010546)
feature 102 (0.010446)
feature 53 (0.009970)
feature 104 (0.009960)
feature 68 (0.009810)
feature 131 (0.009747)
feature 414 (0.009584)
inner fold=0
accuracy=0.608695652174
feature 214 (0.022501)
feature 81 (0.020737)
feature 227 (0.019998)
feature 171 (0.019764)
feature 24 (0.019465)
feature 159 (0.019217)
feature 139 (0.018361)
feature 136 (0.017220)
feature 203 (0.016407)
feature 55 (0.015954)
feature 122 (0.014876)
feature 147 (0.014693)
feature 272 (0.013722)
feature 53 (0.013606)
feature 125 (0.013552)
feature 107 (0.013449)
feature 56 (0.013252)
feature 381 (0.013046)
feature 62 (0.012989)
feature 157 (0.012962)
feature 419 (0.012711)
feature 224 (0.012656)
feature 44 (0.011596)
feature 128 (0.011574)
feature 138 (0.011449)
feature 46 (0.011431)
feature 103 (0.011426)
feature 175 (0.011294)
feature 216 (0.011162)
feature 155 (0.011146)
inner fold=1
accuracy=0.586956521739
feature 153 (0.027712)
feature 173 (0.026984)
feature 227 (0.023120)
feature 136 (0.022173)
feature 131 (0.018718)
feature 79 (0.017357)
feature 30 (0.016650)
feature 134 (0.016427)
feature 171 (0.015802)
feature 128 (0.015768)
feature 102 (0.015618)
feature 43 (0.014504)
feature 464 (0.014051)
feature 211 (0.013884)
feature 56 (0.013604)
feature 168 (0.013379)
feature 38 (0.013370)
feature 231 (0.013256)
feature 142 (0.012548)
feature 44 (0.012528)
feature 53 (0.012136)
feature 77 (0.011783)
feature 137 (0.011753)
feature 52 (0.011730)
feature 138 (0.011717)
feature 123 (0.011477)
feature 208 (0.011468)
feature 82 (0.011416)
feature 180 (0.011052)
feature 172 (0.010958)
inner fold=2
accuracy=0.608695652174
feature 138 (0.032764)
feature 168 (0.026199)
feature 171 (0.025435)
feature 184 (0.022114)
feature 235 (0.021896)
feature 209 (0.021375)
feature 109 (0.021331)
feature 99 (0.020527)
feature 381 (0.017551)
feature 58 (0.017256)
feature 174 (0.016860)
feature 412 (0.016120)
feature 81 (0.016074)
feature 199 (0.015322)
feature 84 (0.015004)
feature 50 (0.014341)
feature 79 (0.014192)
feature 35 (0.013887)
feature 136 (0.013234)
feature 275 (0.013095)
feature 40 (0.013032)
feature 122 (0.012616)
feature 227 (0.012179)
feature 134 (0.011536)
feature 56 (0.010926)
feature 175 (0.010539)
feature 429 (0.009899)
feature 57 (0.009675)
feature 14 (0.009460)
feature 3 (0.009375)
inner fold=3
accuracy=0.466666666667
feature 235 (0.027798)
feature 62 (0.025766)
feature 159 (0.024100)
feature 171 (0.023790)
feature 174 (0.022080)
feature 160 (0.022029)
feature 131 (0.020986)
feature 156 (0.019212)
feature 148 (0.018978)
feature 165 (0.018760)
feature 272 (0.018669)
feature 231 (0.018606)
feature 34 (0.018404)
feature 73 (0.016326)
feature 158 (0.015954)
feature 84 (0.015895)
feature 110 (0.015109)
feature 77 (0.015105)
feature 44 (0.014678)
feature 183 (0.014106)
feature 215 (0.013420)
feature 30 (0.013127)
feature 175 (0.012346)
feature 152 (0.011596)
feature 155 (0.011359)
feature 209 (0.011074)
feature 202 (0.010654)
feature 161 (0.010258)
feature 294 (0.010248)
feature 120 (0.009703)
inner fold=4
accuracy=0.555555555556
feature 213 (0.029146)
feature 294 (0.026437)
feature 101 (0.021433)
feature 46 (0.021093)
feature 201 (0.019877)
feature 211 (0.018330)
feature 38 (0.017685)
feature 14 (0.017657)
feature 143 (0.016329)
feature 171 (0.015681)
feature 200 (0.015275)
feature 174 (0.015233)
feature 224 (0.014773)
feature 164 (0.014450)
feature 73 (0.013734)
feature 0 (0.012800)
feature 34 (0.012588)
feature 175 (0.012557)
feature 104 (0.012477)
feature 156 (0.012368)
feature 41 (0.012010)
feature 134 (0.011861)
feature 199 (0.011663)
feature 70 (0.011642)
feature 53 (0.011529)
feature 126 (0.010678)
feature 81 (0.010533)
feature 77 (0.010151)
feature 208 (0.010072)
feature 130 (0.009843)
inner fold=0
accuracy=0.478260869565
feature 294 (0.043228)
feature 171 (0.030744)
feature 222 (0.028311)
feature 81 (0.023599)
feature 170 (0.021299)
feature 43 (0.020701)
feature 136 (0.019121)
feature 208 (0.018444)
feature 174 (0.018420)
feature 203 (0.018074)
feature 142 (0.017725)
feature 63 (0.016726)
feature 34 (0.015396)
feature 175 (0.014808)
feature 42 (0.014760)
feature 24 (0.014724)
feature 211 (0.013851)
feature 167 (0.013726)
feature 106 (0.013485)
feature 138 (0.013320)
feature 115 (0.012277)
feature 18 (0.012165)
feature 147 (0.011192)
feature 135 (0.011083)
feature 153 (0.010912)
feature 56 (0.010719)
feature 44 (0.010527)
feature 155 (0.010374)
feature 40 (0.010216)
feature 184 (0.010052)
inner fold=1
accuracy=0.652173913043
feature 43 (0.033168)
feature 81 (0.029163)
feature 172 (0.027759)
feature 30 (0.021459)
feature 152 (0.017271)
feature 129 (0.016854)
feature 159 (0.016851)
feature 77 (0.016278)
feature 168 (0.015570)
feature 55 (0.015327)
feature 156 (0.015109)
feature 166 (0.014489)
feature 171 (0.013523)
feature 272 (0.013469)
feature 44 (0.013280)
feature 24 (0.012757)
feature 161 (0.012082)
feature 12 (0.011885)
feature 209 (0.011781)
feature 201 (0.011738)
feature 362 (0.011169)
feature 120 (0.010858)
feature 155 (0.010537)
feature 210 (0.010535)
feature 294 (0.010435)
feature 135 (0.010365)
feature 122 (0.010099)
feature 136 (0.010092)
feature 14 (0.010029)
feature 235 (0.009929)
inner fold=2
accuracy=0.652173913043
feature 294 (0.051919)
feature 122 (0.032859)
feature 120 (0.023733)
feature 139 (0.023376)
feature 21 (0.022980)
feature 390 (0.019391)
feature 148 (0.018478)
feature 175 (0.018093)
feature 138 (0.017905)
feature 53 (0.016626)
feature 127 (0.016145)
feature 143 (0.015995)
feature 173 (0.015287)
feature 81 (0.015044)
feature 34 (0.014816)
feature 51 (0.014718)
feature 3 (0.013286)
feature 216 (0.013146)
feature 136 (0.013069)
feature 203 (0.012726)
feature 161 (0.012665)
feature 207 (0.012191)
feature 211 (0.011737)
feature 196 (0.010452)
feature 381 (0.010098)
feature 171 (0.009406)
feature 155 (0.009316)
feature 33 (0.009244)
feature 57 (0.009052)
feature 38 (0.009038)
inner fold=3
accuracy=0.577777777778
feature 171 (0.036876)
feature 385 (0.024433)
feature 110 (0.024098)
feature 137 (0.019746)
feature 129 (0.019574)
feature 294 (0.019318)
feature 157 (0.019067)
feature 231 (0.018719)
feature 142 (0.018370)
feature 1 (0.017085)
feature 184 (0.016592)
feature 81 (0.016128)
feature 135 (0.015982)
feature 109 (0.014372)
feature 168 (0.014004)
feature 2 (0.013543)
feature 12 (0.012845)
feature 143 (0.012836)
feature 155 (0.012777)
feature 272 (0.012613)
feature 128 (0.012265)
feature 149 (0.012001)
feature 203 (0.011967)
feature 41 (0.011752)
feature 152 (0.011587)
feature 181 (0.011584)
feature 159 (0.011511)
feature 138 (0.011424)
feature 120 (0.011282)
feature 209 (0.011222)
inner fold=4
accuracy=0.644444444444

lay_id=3
feature 231 (0.035052)
feature 24 (0.024339)
feature 120 (0.021230)
feature 168 (0.019570)
feature 159 (0.019006)
feature 182 (0.017293)
feature 129 (0.016631)
feature 163 (0.014988)
feature 81 (0.014910)
feature 36 (0.014786)
feature 45 (0.014079)
feature 235 (0.013700)
feature 169 (0.013580)
feature 56 (0.012778)
feature 184 (0.012080)
feature 340 (0.012017)
feature 62 (0.011949)
feature 164 (0.011903)
feature 4 (0.011632)
feature 160 (0.011557)
feature 57 (0.011343)
feature 186 (0.011320)
feature 156 (0.011254)
feature 174 (0.010833)
feature 344 (0.010444)
feature 152 (0.010187)
feature 14 (0.010179)
feature 21 (0.010107)
feature 192 (0.009793)
feature 128 (0.009760)
inner fold=0
accuracy=0.630434782609
feature 58 (0.026137)
feature 43 (0.024616)
feature 172 (0.022771)
feature 81 (0.022523)
feature 30 (0.022345)
feature 203 (0.020969)
feature 125 (0.020835)
feature 156 (0.018644)
feature 235 (0.018427)
feature 136 (0.017573)
feature 231 (0.017452)
feature 159 (0.016583)
feature 138 (0.016256)
feature 14 (0.015817)
feature 33 (0.015566)
feature 110 (0.015566)
feature 137 (0.014410)
feature 77 (0.013790)
feature 129 (0.013618)
feature 127 (0.013120)
feature 97 (0.013019)
feature 169 (0.012760)
feature 214 (0.012525)
feature 106 (0.012233)
feature 78 (0.012047)
feature 13 (0.011968)
feature 202 (0.011917)
feature 101 (0.011849)
feature 50 (0.011806)
feature 157 (0.011637)
inner fold=1
accuracy=0.565217391304
feature 294 (0.032693)
feature 166 (0.023209)
feature 33 (0.022792)
feature 159 (0.022274)
feature 158 (0.019888)
feature 167 (0.018577)
feature 344 (0.018486)
feature 175 (0.018459)
feature 390 (0.016786)
feature 138 (0.016290)
feature 81 (0.016170)
feature 21 (0.015656)
feature 213 (0.014881)
feature 171 (0.014255)
feature 80 (0.014149)
feature 215 (0.013943)
feature 203 (0.013377)
feature 157 (0.013035)
feature 131 (0.012812)
feature 173 (0.012657)
feature 231 (0.012479)
feature 164 (0.012045)
feature 168 (0.011818)
feature 156 (0.011813)
feature 122 (0.011681)
feature 201 (0.011624)
feature 151 (0.011467)
feature 38 (0.011254)
feature 275 (0.011215)
feature 55 (0.010730)
inner fold=2
accuracy=0.521739130435
feature 156 (0.033736)
feature 171 (0.031967)
feature 58 (0.028399)
feature 123 (0.022808)
feature 168 (0.022222)
feature 170 (0.021436)
feature 172 (0.020722)
feature 81 (0.019311)
feature 153 (0.018079)
feature 148 (0.016390)
feature 339 (0.015943)
feature 110 (0.015792)
feature 161 (0.014940)
feature 138 (0.014440)
feature 362 (0.014100)
feature 227 (0.013502)
feature 4 (0.013198)
feature 103 (0.012972)
feature 2 (0.012766)
feature 213 (0.012714)
feature 175 (0.012207)
feature 159 (0.012003)
feature 209 (0.011459)
feature 201 (0.010990)
feature 102 (0.010717)
feature 5 (0.010620)
feature 127 (0.010403)
feature 173 (0.010052)
feature 133 (0.010026)
feature 128 (0.008994)
inner fold=3
accuracy=0.577777777778
feature 81 (0.032315)
feature 33 (0.027179)
feature 122 (0.025413)
feature 143 (0.023313)
feature 135 (0.020898)
feature 159 (0.019363)
feature 78 (0.018162)
feature 158 (0.017662)
feature 340 (0.016454)
feature 166 (0.015012)
feature 123 (0.014499)
feature 199 (0.014482)
feature 104 (0.014360)
feature 171 (0.014318)
feature 344 (0.013872)
feature 168 (0.013865)
feature 12 (0.013481)
feature 362 (0.013290)
feature 165 (0.012963)
feature 128 (0.012447)
feature 139 (0.011973)
feature 224 (0.011973)
feature 167 (0.011660)
feature 137 (0.011652)
feature 301 (0.011515)
feature 202 (0.011283)
feature 45 (0.011141)
feature 129 (0.010764)
feature 40 (0.010763)
feature 80 (0.010583)
inner fold=4
accuracy=0.666666666667
feature 227 (0.048032)
feature 166 (0.025217)
feature 129 (0.023782)
feature 120 (0.023151)
feature 172 (0.022602)
feature 44 (0.022379)
feature 138 (0.021105)
feature 207 (0.018811)
feature 168 (0.018510)
feature 294 (0.018170)
feature 142 (0.018123)
feature 145 (0.017549)
feature 126 (0.016887)
feature 159 (0.016409)
feature 152 (0.016388)
feature 171 (0.016317)
feature 165 (0.015723)
feature 24 (0.014908)
feature 176 (0.013044)
feature 210 (0.012821)
feature 57 (0.011963)
feature 122 (0.011947)
feature 102 (0.011796)
feature 127 (0.011259)
feature 70 (0.011103)
feature 250 (0.011037)
feature 202 (0.010680)
feature 153 (0.010538)
feature 167 (0.010244)
feature 151 (0.010197)
inner fold=0
accuracy=0.673913043478
feature 34 (0.026282)
feature 56 (0.020855)
feature 84 (0.019901)
feature 12 (0.019055)
feature 160 (0.017802)
feature 137 (0.017687)
feature 344 (0.017571)
feature 136 (0.017073)
feature 172 (0.016545)
feature 222 (0.015861)
feature 106 (0.015145)
feature 120 (0.014510)
feature 82 (0.014323)
feature 45 (0.014155)
feature 227 (0.013098)
feature 81 (0.012799)
feature 122 (0.012551)
feature 70 (0.012237)
feature 131 (0.011780)
feature 58 (0.011416)
feature 189 (0.011241)
feature 143 (0.011024)
feature 148 (0.010897)
feature 151 (0.010790)
feature 105 (0.010293)
feature 199 (0.010195)
feature 130 (0.010140)
feature 211 (0.010048)
feature 166 (0.009769)
feature 214 (0.009679)
inner fold=1
accuracy=0.717391304348
feature 159 (0.024110)
feature 231 (0.022597)
feature 227 (0.021201)
feature 203 (0.020652)
feature 294 (0.019963)
feature 81 (0.019889)
feature 14 (0.018455)
feature 1 (0.018082)
feature 168 (0.017214)
feature 173 (0.016844)
feature 185 (0.016835)
feature 58 (0.016513)
feature 12 (0.016250)
feature 100 (0.015784)
feature 188 (0.015244)
feature 149 (0.015093)
feature 57 (0.014781)
feature 174 (0.014271)
feature 145 (0.014241)
feature 167 (0.013018)
feature 125 (0.012796)
feature 78 (0.012073)
feature 213 (0.012023)
feature 152 (0.011610)
feature 214 (0.011579)
feature 160 (0.011217)
feature 139 (0.011193)
feature 128 (0.011135)
feature 172 (0.011055)
feature 102 (0.010968)
inner fold=2
accuracy=0.586956521739
feature 231 (0.041342)
feature 136 (0.032139)
feature 294 (0.026874)
feature 227 (0.019825)
feature 148 (0.019057)
feature 55 (0.018680)
feature 34 (0.017976)
feature 109 (0.017175)
feature 57 (0.017155)
feature 171 (0.016577)
feature 214 (0.016134)
feature 152 (0.015872)
feature 125 (0.015830)
feature 110 (0.015379)
feature 381 (0.014991)
feature 123 (0.014533)
feature 184 (0.014507)
feature 158 (0.014315)
feature 142 (0.013972)
feature 38 (0.013061)
feature 454 (0.013030)
feature 383 (0.012139)
feature 161 (0.011932)
feature 216 (0.011265)
feature 169 (0.010601)
feature 168 (0.010355)
feature 141 (0.010298)
feature 344 (0.010016)
feature 222 (0.009927)
feature 159 (0.009917)
inner fold=3
accuracy=0.577777777778
feature 168 (0.033868)
feature 55 (0.027778)
feature 81 (0.025391)
feature 109 (0.023773)
feature 142 (0.021530)
feature 14 (0.021086)
feature 126 (0.019664)
feature 231 (0.019134)
feature 84 (0.017575)
feature 208 (0.017002)
feature 155 (0.016868)
feature 12 (0.016399)
feature 164 (0.016382)
feature 385 (0.016093)
feature 120 (0.016044)
feature 3 (0.015599)
feature 110 (0.015135)
feature 171 (0.014993)
feature 211 (0.014787)
feature 158 (0.013974)
feature 78 (0.012842)
feature 131 (0.012811)
feature 53 (0.012654)
feature 44 (0.012164)
feature 15 (0.011620)
feature 213 (0.011427)
feature 123 (0.010222)
feature 294 (0.009715)
feature 134 (0.009189)
feature 197 (0.008870)
inner fold=4
accuracy=0.622222222222

lay_id=4
feature 136 (0.032970)
feature 168 (0.024572)
feature 2 (0.024528)
feature 155 (0.021145)
feature 122 (0.019678)
feature 128 (0.017028)
feature 79 (0.017018)
feature 207 (0.016142)
feature 142 (0.015135)
feature 294 (0.014756)
feature 344 (0.014742)
feature 50 (0.014546)
feature 127 (0.013659)
feature 52 (0.013119)
feature 377 (0.012951)
feature 143 (0.012715)
feature 397 (0.011545)
feature 152 (0.011535)
feature 60 (0.011457)
feature 138 (0.011319)
feature 58 (0.011264)
feature 85 (0.011245)
feature 56 (0.011174)
feature 157 (0.010762)
feature 372 (0.010696)
feature 45 (0.010618)
feature 48 (0.010400)
feature 44 (0.010385)
feature 213 (0.010296)
feature 139 (0.010262)
inner fold=0
accuracy=0.586956521739
feature 123 (0.022923)
feature 12 (0.021084)
feature 56 (0.020013)
feature 78 (0.018714)
feature 51 (0.018595)
feature 294 (0.017441)
feature 17 (0.017376)
feature 165 (0.017237)
feature 45 (0.016033)
feature 183 (0.015905)
feature 52 (0.015659)
feature 82 (0.014928)
feature 227 (0.014500)
feature 141 (0.014281)
feature 146 (0.014022)
feature 38 (0.013503)
feature 120 (0.013471)
feature 110 (0.013082)
feature 134 (0.012516)
feature 81 (0.012501)
feature 70 (0.012426)
feature 203 (0.012169)
feature 122 (0.011431)
feature 166 (0.011244)
feature 157 (0.011201)
feature 171 (0.010970)
feature 208 (0.010872)
feature 102 (0.010445)
feature 3 (0.010284)
feature 222 (0.010132)
inner fold=1
accuracy=0.608695652174
feature 211 (0.025692)
feature 122 (0.025461)
feature 152 (0.022388)
feature 142 (0.022039)
feature 171 (0.020830)
feature 79 (0.018071)
feature 57 (0.017800)
feature 77 (0.016476)
feature 109 (0.016340)
feature 62 (0.016047)
feature 235 (0.015516)
feature 200 (0.014683)
feature 158 (0.014297)
feature 203 (0.014033)
feature 17 (0.014005)
feature 159 (0.013808)
feature 14 (0.013787)
feature 147 (0.012926)
feature 412 (0.012365)
feature 168 (0.012190)
feature 130 (0.012071)
feature 138 (0.011770)
feature 172 (0.011416)
feature 40 (0.011390)
feature 201 (0.011339)
feature 114 (0.011289)
feature 231 (0.011205)
feature 52 (0.010760)
feature 81 (0.010477)
feature 210 (0.010435)
inner fold=2
accuracy=0.565217391304
feature 129 (0.027795)
feature 169 (0.023428)
feature 168 (0.022969)
feature 148 (0.018210)
feature 46 (0.017882)
feature 79 (0.017865)
feature 122 (0.016473)
feature 164 (0.016167)
feature 142 (0.016003)
feature 201 (0.015798)
feature 155 (0.015567)
feature 51 (0.014923)
feature 183 (0.014579)
feature 44 (0.014545)
feature 52 (0.014521)
feature 234 (0.013833)
feature 81 (0.013198)
feature 47 (0.012922)
feature 62 (0.012822)
feature 128 (0.012519)
feature 160 (0.012475)
feature 60 (0.012343)
feature 14 (0.012099)
feature 211 (0.011932)
feature 17 (0.011641)
feature 156 (0.011620)
feature 109 (0.011543)
feature 8 (0.011344)
feature 58 (0.011186)
feature 34 (0.011170)
inner fold=3
accuracy=0.688888888889
feature 81 (0.028544)
feature 203 (0.024021)
feature 213 (0.022216)
feature 235 (0.019740)
feature 85 (0.017687)
feature 102 (0.017289)
feature 138 (0.016125)
feature 134 (0.015990)
feature 60 (0.015348)
feature 210 (0.015090)
feature 165 (0.014365)
feature 52 (0.013919)
feature 48 (0.013843)
feature 149 (0.013284)
feature 12 (0.012466)
feature 80 (0.012343)
feature 222 (0.012082)
feature 174 (0.011465)
feature 183 (0.011236)
feature 36 (0.011037)
feature 184 (0.010974)
feature 131 (0.010750)
feature 21 (0.010670)
feature 129 (0.010646)
feature 151 (0.010604)
feature 164 (0.010563)
feature 135 (0.010440)
feature 201 (0.010393)
feature 209 (0.010105)
feature 171 (0.009958)
inner fold=4
accuracy=0.488888888889
feature 43 (0.033645)
feature 12 (0.027202)
feature 164 (0.021501)
feature 235 (0.019618)
feature 153 (0.019052)
feature 231 (0.018772)
feature 101 (0.018552)
feature 143 (0.018535)
feature 137 (0.016655)
feature 81 (0.016558)
feature 129 (0.016121)
feature 110 (0.015332)
feature 208 (0.014654)
feature 128 (0.014109)
feature 202 (0.013996)
feature 136 (0.013899)
feature 138 (0.012887)
feature 148 (0.012352)
feature 42 (0.012276)
feature 159 (0.012140)
feature 161 (0.011860)
feature 46 (0.011670)
feature 211 (0.011352)
feature 63 (0.011227)
feature 171 (0.011222)
feature 126 (0.010652)
feature 62 (0.010372)
feature 71 (0.010284)
feature 127 (0.010049)
feature 73 (0.010008)
inner fold=0
accuracy=0.652173913043
feature 138 (0.035097)
feature 120 (0.024839)
feature 213 (0.021318)
feature 34 (0.020253)
feature 156 (0.019403)
feature 148 (0.018325)
feature 202 (0.017975)
feature 52 (0.016129)
feature 182 (0.015547)
feature 40 (0.015019)
feature 203 (0.014918)
feature 103 (0.014752)
feature 215 (0.014619)
feature 168 (0.014481)
feature 383 (0.014344)
feature 164 (0.014142)
feature 55 (0.013703)
feature 183 (0.013613)
feature 57 (0.013560)
feature 139 (0.013008)
feature 152 (0.012630)
feature 107 (0.012556)
feature 46 (0.012548)
feature 79 (0.012115)
feature 214 (0.011455)
feature 151 (0.011394)
feature 161 (0.011128)
feature 78 (0.011019)
feature 155 (0.010923)
feature 73 (0.010855)
inner fold=1
accuracy=0.608695652174
feature 231 (0.035038)
feature 81 (0.032948)
feature 110 (0.030958)
feature 168 (0.023869)
feature 156 (0.020885)
feature 104 (0.019394)
feature 172 (0.018318)
feature 171 (0.016360)
feature 53 (0.015913)
feature 55 (0.015311)
feature 143 (0.014899)
feature 227 (0.014692)
feature 123 (0.014675)
feature 344 (0.014292)
feature 139 (0.013956)
feature 133 (0.013686)
feature 235 (0.012873)
feature 44 (0.012646)
feature 141 (0.012488)
feature 234 (0.012121)
feature 223 (0.012007)
feature 125 (0.011998)
feature 158 (0.011572)
feature 294 (0.011474)
feature 101 (0.011474)
feature 137 (0.011100)
feature 109 (0.011090)
feature 107 (0.010843)
feature 464 (0.010511)
feature 159 (0.010323)
inner fold=2
accuracy=0.608695652174
feature 153 (0.029451)
feature 138 (0.026373)
feature 81 (0.025451)
feature 151 (0.022100)
feature 3 (0.022036)
feature 58 (0.019399)
feature 109 (0.018921)
feature 156 (0.018263)
feature 40 (0.016608)
feature 79 (0.016227)
feature 56 (0.015648)
feature 200 (0.015339)
feature 103 (0.014483)
feature 235 (0.014429)
feature 55 (0.013896)
feature 60 (0.013728)
feature 184 (0.013665)
feature 213 (0.013626)
feature 137 (0.013550)
feature 34 (0.013155)
feature 57 (0.012806)
feature 78 (0.011814)
feature 222 (0.011684)
feature 46 (0.011499)
feature 166 (0.011204)
feature 167 (0.010607)
feature 33 (0.010381)
feature 38 (0.010336)
feature 101 (0.010219)
feature 77 (0.009817)
inner fold=3
accuracy=0.555555555556
feature 38 (0.026016)
feature 385 (0.023116)
feature 164 (0.020025)
feature 139 (0.019186)
feature 344 (0.019031)
feature 43 (0.018937)
feature 227 (0.018774)
feature 153 (0.018600)
feature 81 (0.017378)
feature 129 (0.017252)
feature 235 (0.015428)
feature 30 (0.015384)
feature 464 (0.015228)
feature 82 (0.014534)
feature 210 (0.013536)
feature 135 (0.013129)
feature 84 (0.012826)
feature 48 (0.012814)
feature 169 (0.012314)
feature 115 (0.011137)
feature 14 (0.010947)
feature 13 (0.010942)
feature 79 (0.010584)
feature 125 (0.010580)
feature 197 (0.010499)
feature 159 (0.010488)
feature 174 (0.010462)
feature 77 (0.009539)
feature 194 (0.009308)
feature 22 (0.009064)
inner fold=4
accuracy=0.577777777778

lay_id=5
feature 182 (0.036697)
feature 81 (0.035478)
feature 158 (0.021622)
feature 131 (0.020473)
feature 128 (0.020023)
feature 169 (0.017251)
feature 168 (0.016770)
feature 120 (0.016724)
feature 183 (0.016490)
feature 159 (0.015990)
feature 12 (0.015790)
feature 0 (0.014311)
feature 40 (0.014250)
feature 38 (0.014137)
feature 142 (0.013188)
feature 202 (0.012926)
feature 43 (0.012926)
feature 52 (0.012652)
feature 235 (0.012499)
feature 34 (0.012410)
feature 129 (0.012100)
feature 109 (0.011986)
feature 107 (0.011855)
feature 152 (0.011700)
feature 285 (0.011277)
feature 101 (0.010946)
feature 14 (0.010633)
feature 362 (0.010560)
feature 161 (0.010541)
feature 203 (0.010485)
inner fold=0
accuracy=0.717391304348
feature 235 (0.038034)
feature 172 (0.025752)
feature 227 (0.025033)
feature 110 (0.024373)
feature 84 (0.023787)
feature 201 (0.020234)
feature 174 (0.018943)
feature 81 (0.018837)
feature 30 (0.016620)
feature 127 (0.015548)
feature 211 (0.015534)
feature 115 (0.014880)
feature 136 (0.014469)
feature 168 (0.014320)
feature 123 (0.014226)
feature 60 (0.014183)
feature 120 (0.013938)
feature 231 (0.013862)
feature 381 (0.013836)
feature 80 (0.013337)
feature 137 (0.013293)
feature 130 (0.013221)
feature 56 (0.013106)
feature 82 (0.013041)
feature 33 (0.012984)
feature 85 (0.012814)
feature 207 (0.012248)
feature 35 (0.011907)
feature 164 (0.011264)
feature 58 (0.011004)
inner fold=1
accuracy=0.652173913043
feature 110 (0.034998)
feature 103 (0.034445)
feature 231 (0.033748)
feature 148 (0.028375)
feature 184 (0.023711)
feature 168 (0.022042)
feature 128 (0.019416)
feature 129 (0.018171)
feature 53 (0.017105)
feature 77 (0.016852)
feature 179 (0.016375)
feature 222 (0.015723)
feature 171 (0.015555)
feature 156 (0.015080)
feature 172 (0.014866)
feature 106 (0.014841)
feature 165 (0.014593)
feature 175 (0.013988)
feature 58 (0.013574)
feature 140 (0.013389)
feature 105 (0.013006)
feature 95 (0.012980)
feature 349 (0.012612)
feature 115 (0.012459)
feature 344 (0.012312)
feature 21 (0.011588)
feature 126 (0.011319)
feature 408 (0.011192)
feature 107 (0.010552)
feature 24 (0.010466)
inner fold=2
accuracy=0.630434782609
feature 110 (0.042398)
feature 129 (0.027149)
feature 171 (0.026992)
feature 227 (0.026672)
feature 148 (0.022688)
feature 159 (0.021273)
feature 167 (0.019758)
feature 201 (0.018957)
feature 168 (0.017531)
feature 63 (0.017440)
feature 50 (0.016147)
feature 46 (0.015438)
feature 52 (0.014659)
feature 58 (0.014280)
feature 142 (0.014061)
feature 131 (0.013970)
feature 344 (0.013193)
feature 77 (0.013134)
feature 107 (0.012807)
feature 74 (0.012690)
feature 176 (0.012668)
feature 103 (0.012398)
feature 51 (0.012127)
feature 172 (0.011874)
feature 135 (0.011514)
feature 18 (0.010898)
feature 115 (0.010783)
feature 174 (0.010710)
feature 80 (0.010589)
feature 161 (0.010573)
inner fold=3
accuracy=0.644444444444
feature 171 (0.033601)
feature 168 (0.028073)
feature 80 (0.027008)
feature 84 (0.026266)
feature 272 (0.018273)
feature 173 (0.018030)
feature 126 (0.015843)
feature 120 (0.014774)
feature 159 (0.014674)
feature 172 (0.014547)
feature 231 (0.014070)
feature 227 (0.013977)
feature 139 (0.013920)
feature 203 (0.013405)
feature 151 (0.013021)
feature 122 (0.012313)
feature 14 (0.012078)
feature 12 (0.011793)
feature 285 (0.011750)
feature 127 (0.011705)
feature 166 (0.011360)
feature 68 (0.011344)
feature 163 (0.011173)
feature 156 (0.011148)
feature 79 (0.010935)
feature 200 (0.010656)
feature 169 (0.010427)
feature 182 (0.010224)
feature 17 (0.009921)
feature 85 (0.009641)
inner fold=4
accuracy=0.644444444444
feature 123 (0.035300)
feature 171 (0.031428)
feature 156 (0.023861)
feature 231 (0.020691)
feature 294 (0.020645)
feature 159 (0.019342)
feature 136 (0.019247)
feature 173 (0.018698)
feature 172 (0.018210)
feature 142 (0.017846)
feature 4 (0.017073)
feature 135 (0.015931)
feature 18 (0.015182)
feature 227 (0.014355)
feature 53 (0.013577)
feature 211 (0.013532)
feature 214 (0.013487)
feature 109 (0.012961)
feature 101 (0.012682)
feature 193 (0.012287)
feature 222 (0.012136)
feature 201 (0.012093)
feature 102 (0.012080)
feature 208 (0.011466)
feature 35 (0.011144)
feature 3 (0.011078)
feature 38 (0.010920)
feature 134 (0.010843)
feature 56 (0.010765)
feature 70 (0.010565)
inner fold=0
accuracy=0.586956521739
feature 171 (0.047260)
feature 80 (0.039746)
feature 136 (0.029610)
feature 167 (0.023523)
feature 215 (0.022561)
feature 151 (0.019372)
feature 105 (0.018917)
feature 53 (0.018912)
feature 12 (0.018856)
feature 77 (0.016371)
feature 38 (0.016317)
feature 202 (0.015436)
feature 79 (0.015078)
feature 128 (0.014957)
feature 294 (0.014164)
feature 141 (0.013811)
feature 214 (0.013009)
feature 60 (0.012866)
feature 200 (0.012817)
feature 169 (0.012475)
feature 51 (0.011780)
feature 203 (0.011552)
feature 82 (0.010942)
feature 210 (0.010655)
feature 159 (0.010475)
feature 81 (0.010395)
feature 235 (0.010218)
feature 52 (0.010112)
feature 208 (0.009125)
feature 285 (0.009073)
inner fold=1
accuracy=0.673913043478
feature 171 (0.043994)
feature 55 (0.029084)
feature 40 (0.025509)
feature 294 (0.025324)
feature 135 (0.023687)
feature 227 (0.022627)
feature 175 (0.020394)
feature 202 (0.019028)
feature 203 (0.018111)
feature 155 (0.016898)
feature 21 (0.016124)
feature 169 (0.015024)
feature 157 (0.014984)
feature 110 (0.014930)
feature 34 (0.014643)
feature 115 (0.013533)
feature 168 (0.012846)
feature 235 (0.012664)
feature 156 (0.012266)
feature 158 (0.012180)
feature 53 (0.011762)
feature 301 (0.011263)
feature 97 (0.010844)
feature 136 (0.010390)
feature 165 (0.010093)
feature 200 (0.010030)
feature 18 (0.009869)
feature 142 (0.009411)
feature 139 (0.008896)
feature 48 (0.008609)
inner fold=2
accuracy=0.565217391304
feature 142 (0.031951)
feature 79 (0.026072)
feature 157 (0.023031)
feature 52 (0.022430)
feature 171 (0.022190)
feature 168 (0.020930)
feature 164 (0.020711)
feature 137 (0.019809)
feature 110 (0.018526)
feature 174 (0.018334)
feature 4 (0.016581)
feature 81 (0.016143)
feature 78 (0.015961)
feature 216 (0.015894)
feature 285 (0.015104)
feature 55 (0.014770)
feature 175 (0.014323)
feature 122 (0.014077)
feature 203 (0.013784)
feature 57 (0.013232)
feature 170 (0.012798)
feature 56 (0.012244)
feature 73 (0.012133)
feature 160 (0.011920)
feature 114 (0.011824)
feature 107 (0.011117)
feature 84 (0.010527)
feature 129 (0.010234)
feature 126 (0.009782)
feature 148 (0.009630)
inner fold=3
accuracy=0.644444444444
feature 203 (0.034997)
feature 235 (0.032241)
feature 102 (0.028449)
feature 123 (0.024347)
feature 78 (0.022311)
feature 166 (0.021956)
feature 138 (0.020309)
feature 125 (0.019878)
feature 137 (0.018958)
feature 172 (0.016939)
feature 122 (0.015024)
feature 158 (0.014607)
feature 208 (0.013346)
feature 227 (0.013007)
feature 101 (0.012777)
feature 14 (0.012746)
feature 182 (0.012333)
feature 1 (0.011574)
feature 171 (0.011550)
feature 5 (0.011397)
feature 215 (0.011041)
feature 110 (0.010932)
feature 104 (0.010443)
feature 184 (0.010231)
feature 8 (0.010008)
feature 175 (0.009996)
feature 128 (0.009939)
feature 0 (0.009532)
feature 74 (0.009325)
feature 24 (0.009149)
inner fold=4
accuracy=0.488888888889

lay_id=6
feature 227 (0.034407)
feature 46 (0.027630)
feature 202 (0.025661)
feature 34 (0.025027)
feature 203 (0.022398)
feature 122 (0.020181)
feature 54 (0.019705)
feature 38 (0.019690)
feature 84 (0.019387)
feature 82 (0.018841)
feature 79 (0.018638)
feature 24 (0.018032)
feature 73 (0.017310)
feature 168 (0.017201)
feature 56 (0.015956)
feature 134 (0.014634)
feature 173 (0.014571)
feature 216 (0.014570)
feature 126 (0.012939)
feature 30 (0.012929)
feature 172 (0.012810)
feature 57 (0.012763)
feature 167 (0.012473)
feature 62 (0.012393)
feature 174 (0.011450)
feature 9 (0.011317)
feature 171 (0.010951)
feature 164 (0.010920)
feature 44 (0.010882)
feature 165 (0.010746)
inner fold=0
accuracy=0.565217391304
feature 158 (0.022382)
feature 157 (0.018742)
feature 14 (0.017887)
feature 174 (0.017747)
feature 227 (0.016555)
feature 222 (0.016412)
feature 203 (0.015716)
feature 152 (0.014894)
feature 151 (0.014512)
feature 30 (0.014134)
feature 58 (0.014028)
feature 156 (0.013626)
feature 43 (0.013414)
feature 147 (0.013129)
feature 125 (0.012733)
feature 79 (0.012648)
feature 42 (0.012505)
feature 140 (0.012393)
feature 115 (0.012317)
feature 44 (0.012243)
feature 171 (0.011764)
feature 294 (0.011705)
feature 5 (0.011654)
feature 209 (0.011644)
feature 107 (0.011431)
feature 142 (0.011104)
feature 2 (0.011002)
feature 60 (0.010800)
feature 77 (0.010564)
feature 131 (0.010177)
inner fold=1
accuracy=0.608695652174
feature 12 (0.027886)
feature 142 (0.024475)
feature 129 (0.023998)
feature 34 (0.023790)
feature 163 (0.023136)
feature 135 (0.021866)
feature 165 (0.019393)
feature 227 (0.019003)
feature 44 (0.018925)
feature 128 (0.017851)
feature 46 (0.016414)
feature 101 (0.016108)
feature 174 (0.015578)
feature 131 (0.015422)
feature 199 (0.015091)
feature 58 (0.014881)
feature 153 (0.014444)
feature 213 (0.014105)
feature 1 (0.013640)
feature 138 (0.013582)
feature 208 (0.013357)
feature 105 (0.012944)
feature 77 (0.012622)
feature 56 (0.012257)
feature 454 (0.012138)
feature 294 (0.012023)
feature 443 (0.011681)
feature 166 (0.011526)
feature 211 (0.010924)
feature 127 (0.010395)
inner fold=2
accuracy=0.54347826087
feature 171 (0.043837)
feature 4 (0.027340)
feature 174 (0.024529)
feature 168 (0.024210)
feature 34 (0.022352)
feature 200 (0.018464)
feature 14 (0.016634)
feature 61 (0.015993)
feature 158 (0.015890)
feature 77 (0.015642)
feature 222 (0.015576)
feature 344 (0.015538)
feature 156 (0.014900)
feature 46 (0.014572)
feature 5 (0.014488)
feature 82 (0.014249)
feature 101 (0.013783)
feature 42 (0.013540)
feature 58 (0.013319)
feature 83 (0.013241)
feature 60 (0.013111)
feature 134 (0.012986)
feature 3 (0.012964)
feature 52 (0.012486)
feature 1 (0.012210)
feature 122 (0.011398)
feature 137 (0.010975)
feature 36 (0.010792)
feature 12 (0.010585)
feature 181 (0.010120)
inner fold=3
accuracy=0.688888888889
feature 138 (0.050425)
feature 203 (0.030993)
feature 131 (0.027917)
feature 235 (0.023882)
feature 56 (0.021872)
feature 153 (0.020147)
feature 24 (0.017288)
feature 129 (0.017224)
feature 172 (0.016880)
feature 79 (0.016174)
feature 0 (0.015545)
feature 231 (0.015067)
feature 171 (0.014541)
feature 227 (0.014334)
feature 120 (0.014188)
feature 2 (0.013785)
feature 294 (0.013646)
feature 4 (0.013173)
feature 155 (0.012955)
feature 44 (0.012780)
feature 43 (0.012598)
feature 102 (0.012037)
feature 214 (0.011338)
feature 105 (0.011130)
feature 80 (0.011051)
feature 84 (0.010956)
feature 390 (0.010751)
feature 39 (0.010342)
feature 183 (0.010029)
feature 60 (0.009772)
inner fold=4
accuracy=0.666666666667
feature 294 (0.054628)
feature 215 (0.023515)
feature 122 (0.022028)
feature 203 (0.021612)
feature 44 (0.021419)
feature 80 (0.019153)
feature 199 (0.018040)
feature 57 (0.017283)
feature 135 (0.016738)
feature 127 (0.016516)
feature 181 (0.016375)
feature 0 (0.015807)
feature 138 (0.014474)
feature 166 (0.014388)
feature 142 (0.014142)
feature 158 (0.013854)
feature 202 (0.013074)
feature 385 (0.012308)
feature 272 (0.012071)
feature 82 (0.011038)
feature 133 (0.010985)
feature 81 (0.010961)
feature 38 (0.010921)
feature 235 (0.010832)
feature 145 (0.010712)
feature 172 (0.010530)
feature 126 (0.010192)
feature 198 (0.009752)
feature 130 (0.009670)
feature 134 (0.009375)
inner fold=0
accuracy=0.586956521739
feature 294 (0.040486)
feature 134 (0.036416)
feature 55 (0.030412)
feature 168 (0.025830)
feature 151 (0.025298)
feature 0 (0.023269)
feature 81 (0.022920)
feature 5 (0.021802)
feature 171 (0.019773)
feature 77 (0.018172)
feature 104 (0.017407)
feature 44 (0.016508)
feature 51 (0.016270)
feature 180 (0.015767)
feature 199 (0.015248)
feature 153 (0.015196)
feature 79 (0.015017)
feature 235 (0.014598)
feature 381 (0.014389)
feature 53 (0.014164)
feature 130 (0.014098)
feature 215 (0.013330)
feature 70 (0.013168)
feature 214 (0.013091)
feature 52 (0.011898)
feature 58 (0.011530)
feature 156 (0.011229)
feature 129 (0.010811)
feature 209 (0.010663)
feature 166 (0.009891)
inner fold=1
accuracy=0.586956521739
feature 138 (0.035205)
feature 294 (0.033961)
feature 110 (0.028697)
feature 135 (0.027433)
feature 203 (0.023772)
feature 131 (0.022409)
feature 44 (0.021087)
feature 161 (0.020569)
feature 201 (0.020313)
feature 159 (0.019909)
feature 101 (0.019439)
feature 0 (0.018030)
feature 51 (0.017650)
feature 103 (0.017366)
feature 58 (0.016193)
feature 134 (0.015126)
feature 173 (0.014982)
feature 167 (0.014448)
feature 168 (0.013731)
feature 122 (0.012968)
feature 142 (0.012111)
feature 78 (0.010885)
feature 464 (0.010860)
feature 148 (0.010834)
feature 213 (0.010779)
feature 140 (0.010602)
feature 182 (0.010112)
feature 39 (0.009914)
feature 126 (0.009827)
feature 55 (0.009548)
inner fold=2
accuracy=0.717391304348
feature 294 (0.039470)
feature 81 (0.033964)
feature 203 (0.026936)
feature 129 (0.020592)
feature 58 (0.019958)
feature 158 (0.018314)
feature 385 (0.017779)
feature 234 (0.017271)
feature 120 (0.015122)
feature 143 (0.014995)
feature 104 (0.014563)
feature 36 (0.014432)
feature 126 (0.014343)
feature 136 (0.014223)
feature 166 (0.014053)
feature 213 (0.013847)
feature 33 (0.013626)
feature 172 (0.013212)
feature 156 (0.012967)
feature 52 (0.012810)
feature 18 (0.012755)
feature 381 (0.012546)
feature 122 (0.012305)
feature 169 (0.012222)
feature 215 (0.011648)
feature 56 (0.011414)
feature 141 (0.011361)
feature 209 (0.010606)
feature 182 (0.010377)
feature 34 (0.010287)
inner fold=3
accuracy=0.644444444444
feature 168 (0.033988)
feature 43 (0.028898)
feature 201 (0.022193)
feature 165 (0.021976)
feature 40 (0.021120)
feature 207 (0.018341)
feature 142 (0.018008)
feature 294 (0.016417)
feature 55 (0.016359)
feature 138 (0.016298)
feature 272 (0.015460)
feature 62 (0.014334)
feature 202 (0.014242)
feature 58 (0.013998)
feature 83 (0.013819)
feature 34 (0.013615)
feature 143 (0.013536)
feature 235 (0.013313)
feature 141 (0.012542)
feature 208 (0.012515)
feature 46 (0.011975)
feature 223 (0.011863)
feature 0 (0.011863)
feature 134 (0.011813)
feature 222 (0.011591)
feature 344 (0.011186)
feature 114 (0.011077)
feature 33 (0.010760)
feature 122 (0.010332)
feature 77 (0.010316)
inner fold=4
accuracy=0.577777777778

outer fold 7
lay_id=0
feature 164 (0.033612)
feature 211 (0.021787)
feature 42 (0.021770)
feature 290 (0.021095)
feature 207 (0.020921)
feature 386 (0.017653)
feature 223 (0.017372)
feature 167 (0.017365)
feature 162 (0.017177)
feature 76 (0.016706)
feature 48 (0.016691)
feature 38 (0.016443)
feature 77 (0.016142)
feature 161 (0.016091)
feature 171 (0.015995)
feature 134 (0.015155)
feature 205 (0.014499)
feature 75 (0.014454)
feature 121 (0.013991)
feature 116 (0.013800)
feature 40 (0.013059)
feature 131 (0.012646)
feature 56 (0.012228)
feature 99 (0.012224)
feature 149 (0.011914)
feature 135 (0.011813)
feature 8 (0.011654)
feature 132 (0.011645)
feature 20 (0.011396)
feature 368 (0.011227)
inner fold=0
accuracy=0.739130434783
feature 125 (0.057145)
feature 167 (0.033808)
feature 116 (0.027774)
feature 122 (0.027269)
feature 14 (0.024722)
feature 212 (0.024546)
feature 231 (0.020473)
feature 171 (0.019721)
feature 209 (0.019372)
feature 340 (0.019126)
feature 26 (0.014570)
feature 169 (0.014461)
feature 97 (0.014362)
feature 137 (0.013539)
feature 40 (0.013447)
feature 149 (0.013386)
feature 138 (0.012922)
feature 163 (0.011430)
feature 36 (0.010952)
feature 64 (0.010891)
feature 124 (0.010822)
feature 220 (0.010772)
feature 75 (0.010644)
feature 80 (0.010474)
feature 199 (0.010442)
feature 30 (0.010253)
feature 73 (0.010186)
feature 195 (0.010155)
feature 0 (0.010032)
feature 227 (0.010005)
inner fold=1
accuracy=0.521739130435
feature 445 (0.023847)
feature 167 (0.022524)
feature 218 (0.021688)
feature 168 (0.021581)
feature 179 (0.019905)
feature 199 (0.019601)
feature 40 (0.019257)
feature 116 (0.018950)
feature 157 (0.018215)
feature 34 (0.016077)
feature 144 (0.015902)
feature 39 (0.015643)
feature 290 (0.015239)
feature 231 (0.015110)
feature 73 (0.014264)
feature 141 (0.013736)
feature 51 (0.013652)
feature 381 (0.012959)
feature 172 (0.012916)
feature 129 (0.012651)
feature 171 (0.012631)
feature 97 (0.012036)
feature 42 (0.011823)
feature 105 (0.011512)
feature 148 (0.011447)
feature 74 (0.011436)
feature 340 (0.011415)
feature 227 (0.011283)
feature 80 (0.011272)
feature 138 (0.011138)
inner fold=2
accuracy=0.652173913043
feature 40 (0.029733)
feature 122 (0.028447)
feature 49 (0.026630)
feature 0 (0.026050)
feature 48 (0.024511)
feature 204 (0.022975)
feature 168 (0.021123)
feature 77 (0.020277)
feature 170 (0.020080)
feature 52 (0.017438)
feature 25 (0.016785)
feature 39 (0.016366)
feature 206 (0.015920)
feature 438 (0.015881)
feature 207 (0.015755)
feature 390 (0.015338)
feature 203 (0.015187)
feature 58 (0.015126)
feature 167 (0.014807)
feature 381 (0.013799)
feature 42 (0.013484)
feature 23 (0.013239)
feature 1 (0.011944)
feature 74 (0.011496)
feature 50 (0.011308)
feature 93 (0.011152)
feature 281 (0.010888)
feature 103 (0.010415)
feature 15 (0.010233)
feature 377 (0.009960)
inner fold=3
accuracy=0.555555555556
feature 164 (0.031802)
feature 290 (0.028251)
feature 56 (0.023400)
feature 76 (0.020136)
feature 212 (0.019472)
feature 171 (0.017849)
feature 199 (0.017635)
feature 168 (0.016993)
feature 180 (0.016245)
feature 105 (0.016180)
feature 124 (0.016174)
feature 160 (0.014787)
feature 121 (0.014656)
feature 177 (0.014160)
feature 268 (0.013703)
feature 54 (0.013354)
feature 102 (0.012934)
feature 43 (0.012843)
feature 78 (0.012494)
feature 209 (0.012074)
feature 34 (0.011734)
feature 153 (0.011623)
feature 125 (0.011612)
feature 144 (0.011429)
feature 58 (0.011342)
feature 119 (0.011018)
feature 205 (0.011004)
feature 134 (0.010879)
feature 167 (0.010270)
feature 197 (0.010041)
inner fold=4
accuracy=0.711111111111
feature 168 (0.044217)
feature 290 (0.037763)
feature 119 (0.025334)
feature 171 (0.024002)
feature 223 (0.023122)
feature 54 (0.021174)
feature 227 (0.017311)
feature 199 (0.017066)
feature 169 (0.016514)
feature 268 (0.015888)
feature 39 (0.015505)
feature 209 (0.015055)
feature 198 (0.014689)
feature 93 (0.014226)
feature 340 (0.013688)
feature 122 (0.013399)
feature 116 (0.013254)
feature 144 (0.013187)
feature 211 (0.013175)
feature 75 (0.012630)
feature 97 (0.012060)
feature 106 (0.011832)
feature 142 (0.011715)
feature 219 (0.011568)
feature 1 (0.011532)
feature 132 (0.011454)
feature 358 (0.011405)
feature 137 (0.011320)
feature 162 (0.011274)
feature 51 (0.010912)
inner fold=0
accuracy=0.673913043478
feature 125 (0.031490)
feature 74 (0.026577)
feature 167 (0.020110)
feature 134 (0.018711)
feature 169 (0.018120)
feature 268 (0.017618)
feature 147 (0.015968)
feature 54 (0.015851)
feature 198 (0.015475)
feature 49 (0.015055)
feature 106 (0.014950)
feature 130 (0.014700)
feature 102 (0.014507)
feature 42 (0.014359)
feature 51 (0.014325)
feature 77 (0.014193)
feature 59 (0.013773)
feature 227 (0.013593)
feature 205 (0.013235)
feature 195 (0.013069)
feature 218 (0.013039)
feature 58 (0.012450)
feature 119 (0.011684)
feature 145 (0.011185)
feature 148 (0.010812)
feature 29 (0.010701)
feature 183 (0.010540)
feature 154 (0.010386)
feature 168 (0.010284)
feature 100 (0.010222)
inner fold=1
accuracy=0.630434782609
feature 10 (0.031467)
feature 207 (0.026823)
feature 42 (0.025608)
feature 167 (0.022715)
feature 1 (0.022352)
feature 168 (0.021192)
feature 38 (0.020468)
feature 77 (0.020372)
feature 124 (0.019642)
feature 135 (0.017365)
feature 151 (0.016992)
feature 131 (0.016869)
feature 49 (0.016748)
feature 127 (0.016458)
feature 161 (0.015879)
feature 148 (0.015461)
feature 218 (0.015270)
feature 126 (0.014983)
feature 152 (0.014459)
feature 51 (0.014420)
feature 123 (0.012924)
feature 153 (0.011541)
feature 145 (0.011370)
feature 163 (0.010962)
feature 330 (0.010916)
feature 39 (0.010823)
feature 302 (0.010465)
feature 106 (0.010378)
feature 199 (0.010327)
feature 209 (0.010261)
inner fold=2
accuracy=0.521739130435
feature 164 (0.039463)
feature 223 (0.028849)
feature 134 (0.027409)
feature 171 (0.024495)
feature 167 (0.023693)
feature 160 (0.023135)
feature 290 (0.020628)
feature 116 (0.019896)
feature 184 (0.018020)
feature 125 (0.017561)
feature 151 (0.016303)
feature 124 (0.016237)
feature 73 (0.014470)
feature 209 (0.014449)
feature 34 (0.014266)
feature 30 (0.013739)
feature 161 (0.013425)
feature 26 (0.013337)
feature 65 (0.013241)
feature 49 (0.012530)
feature 98 (0.012419)
feature 133 (0.012025)
feature 24 (0.011174)
feature 17 (0.010881)
feature 29 (0.010589)
feature 4 (0.010577)
feature 180 (0.010511)
feature 297 (0.010314)
feature 52 (0.010234)
feature 36 (0.009445)
inner fold=3
accuracy=0.688888888889
feature 290 (0.045105)
feature 164 (0.029970)
feature 199 (0.029325)
feature 381 (0.027687)
feature 54 (0.019879)
feature 195 (0.017810)
feature 134 (0.017425)
feature 10 (0.017348)
feature 78 (0.017323)
feature 168 (0.016887)
feature 231 (0.016177)
feature 135 (0.015606)
feature 169 (0.015348)
feature 155 (0.015051)
feature 151 (0.014374)
feature 130 (0.014262)
feature 209 (0.014222)
feature 30 (0.014199)
feature 52 (0.014038)
feature 132 (0.013099)
feature 340 (0.012961)
feature 205 (0.012784)
feature 281 (0.012280)
feature 34 (0.011766)
feature 160 (0.011528)
feature 125 (0.011201)
feature 284 (0.010247)
feature 124 (0.009844)
feature 268 (0.009145)
feature 26 (0.009024)
inner fold=4
accuracy=0.555555555556

lay_id=1
feature 34 (0.036691)
feature 109 (0.028494)
feature 2 (0.022155)
feature 63 (0.021733)
feature 184 (0.021358)
feature 33 (0.020628)
feature 175 (0.020248)
feature 155 (0.019998)
feature 171 (0.016825)
feature 159 (0.015617)
feature 4 (0.015600)
feature 129 (0.015382)
feature 105 (0.014996)
feature 362 (0.014893)
feature 173 (0.014700)
feature 134 (0.014468)
feature 294 (0.014210)
feature 135 (0.014160)
feature 203 (0.014021)
feature 385 (0.013903)
feature 122 (0.013733)
feature 82 (0.012800)
feature 123 (0.012553)
feature 201 (0.012415)
feature 142 (0.012321)
feature 1 (0.012298)
feature 102 (0.011908)
feature 231 (0.011476)
feature 210 (0.011475)
feature 211 (0.011352)
inner fold=0
accuracy=0.608695652174
feature 171 (0.024198)
feature 168 (0.024087)
feature 77 (0.022304)
feature 294 (0.022088)
feature 53 (0.021515)
feature 138 (0.021155)
feature 148 (0.020792)
feature 172 (0.020056)
feature 202 (0.017790)
feature 222 (0.017775)
feature 33 (0.016480)
feature 14 (0.015295)
feature 58 (0.015158)
feature 164 (0.015040)
feature 80 (0.014750)
feature 84 (0.014522)
feature 209 (0.013359)
feature 134 (0.013134)
feature 129 (0.012752)
feature 151 (0.012688)
feature 52 (0.012410)
feature 139 (0.012246)
feature 101 (0.012055)
feature 1 (0.011933)
feature 216 (0.011926)
feature 158 (0.011282)
feature 152 (0.011195)
feature 44 (0.010947)
feature 71 (0.010874)
feature 381 (0.010739)
inner fold=1
accuracy=0.717391304348
feature 84 (0.031624)
feature 172 (0.025020)
feature 46 (0.020639)
feature 83 (0.019856)
feature 82 (0.018346)
feature 44 (0.018303)
feature 142 (0.017437)
feature 55 (0.017233)
feature 53 (0.016855)
feature 12 (0.016829)
feature 148 (0.016069)
feature 131 (0.015966)
feature 153 (0.015150)
feature 155 (0.014042)
feature 129 (0.014009)
feature 38 (0.013167)
feature 203 (0.013016)
feature 128 (0.012862)
feature 122 (0.012740)
feature 165 (0.012633)
feature 176 (0.012375)
feature 14 (0.012302)
feature 168 (0.011416)
feature 143 (0.011174)
feature 43 (0.010992)
feature 235 (0.010941)
feature 109 (0.010716)
feature 344 (0.010503)
feature 202 (0.010452)
feature 36 (0.010360)
inner fold=2
accuracy=0.586956521739
feature 294 (0.034973)
feature 168 (0.031798)
feature 174 (0.031767)
feature 182 (0.023602)
feature 1 (0.023584)
feature 123 (0.022419)
feature 145 (0.019231)
feature 62 (0.017447)
feature 159 (0.017365)
feature 156 (0.017102)
feature 81 (0.017013)
feature 110 (0.016704)
feature 57 (0.016635)
feature 136 (0.016608)
feature 227 (0.015525)
feature 129 (0.015478)
feature 134 (0.015000)
feature 209 (0.014028)
feature 24 (0.013250)
feature 4 (0.012969)
feature 362 (0.012887)
feature 214 (0.012378)
feature 161 (0.012334)
feature 203 (0.011937)
feature 97 (0.011866)
feature 138 (0.011832)
feature 115 (0.011577)
feature 127 (0.009847)
feature 125 (0.009362)
feature 12 (0.009249)
inner fold=3
accuracy=0.622222222222
feature 294 (0.069982)
feature 14 (0.031215)
feature 123 (0.024179)
feature 153 (0.022137)
feature 34 (0.022058)
feature 109 (0.021871)
feature 164 (0.019893)
feature 134 (0.018918)
feature 81 (0.018643)
feature 131 (0.016739)
feature 169 (0.015748)
feature 55 (0.015206)
feature 158 (0.015030)
feature 148 (0.014540)
feature 172 (0.014091)
feature 130 (0.012616)
feature 121 (0.012217)
feature 188 (0.011686)
feature 199 (0.011400)
feature 53 (0.011242)
feature 216 (0.011240)
feature 213 (0.010941)
feature 68 (0.010782)
feature 106 (0.010646)
feature 78 (0.010510)
feature 80 (0.010208)
feature 175 (0.010060)
feature 137 (0.009690)
feature 44 (0.009542)
feature 0 (0.009286)
inner fold=4
accuracy=0.555555555556
feature 209 (0.031668)
feature 172 (0.025602)
feature 156 (0.021955)
feature 442 (0.021098)
feature 165 (0.017934)
feature 34 (0.017696)
feature 145 (0.016547)
feature 362 (0.016353)
feature 12 (0.015929)
feature 102 (0.015755)
feature 151 (0.014632)
feature 157 (0.014027)
feature 4 (0.014027)
feature 164 (0.013964)
feature 168 (0.013875)
feature 203 (0.013642)
feature 43 (0.013226)
feature 120 (0.012814)
feature 152 (0.012727)
feature 5 (0.012662)
feature 101 (0.012182)
feature 45 (0.012142)
feature 193 (0.012077)
feature 137 (0.011486)
feature 128 (0.011367)
feature 78 (0.011240)
feature 46 (0.011208)
feature 216 (0.010462)
feature 60 (0.010449)
feature 138 (0.010395)
inner fold=0
accuracy=0.695652173913
feature 165 (0.033639)
feature 18 (0.030159)
feature 155 (0.020416)
feature 159 (0.020373)
feature 136 (0.019431)
feature 227 (0.019168)
feature 46 (0.019118)
feature 104 (0.018268)
feature 14 (0.017700)
feature 139 (0.017177)
feature 80 (0.017016)
feature 235 (0.016920)
feature 101 (0.015456)
feature 385 (0.015287)
feature 153 (0.015156)
feature 33 (0.014278)
feature 231 (0.013726)
feature 77 (0.013602)
feature 102 (0.013502)
feature 171 (0.012631)
feature 222 (0.012539)
feature 201 (0.012442)
feature 51 (0.012340)
feature 364 (0.011971)
feature 54 (0.011449)
feature 180 (0.011343)
feature 4 (0.011335)
feature 50 (0.010820)
feature 156 (0.010808)
feature 174 (0.010590)
inner fold=1
accuracy=0.565217391304
feature 235 (0.027459)
feature 78 (0.024109)
feature 30 (0.023943)
feature 139 (0.020611)
feature 136 (0.019885)
feature 201 (0.019770)
feature 164 (0.019271)
feature 385 (0.018979)
feature 54 (0.017722)
feature 294 (0.016209)
feature 122 (0.015495)
feature 21 (0.014863)
feature 166 (0.014523)
feature 34 (0.013923)
feature 77 (0.013688)
feature 209 (0.013357)
feature 26 (0.013215)
feature 152 (0.013155)
feature 131 (0.012839)
feature 158 (0.012445)
feature 155 (0.012268)
feature 203 (0.012186)
feature 171 (0.011957)
feature 0 (0.011384)
feature 5 (0.010947)
feature 102 (0.010856)
feature 207 (0.010751)
feature 125 (0.010645)
feature 33 (0.010242)
feature 127 (0.010235)
inner fold=2
accuracy=0.608695652174
feature 231 (0.027820)
feature 156 (0.024200)
feature 454 (0.022291)
feature 136 (0.020829)
feature 18 (0.020553)
feature 155 (0.018211)
feature 135 (0.017199)
feature 53 (0.017194)
feature 46 (0.017188)
feature 80 (0.017027)
feature 172 (0.016866)
feature 52 (0.016186)
feature 84 (0.015223)
feature 55 (0.014898)
feature 165 (0.014772)
feature 208 (0.014480)
feature 34 (0.014410)
feature 209 (0.014352)
feature 152 (0.013981)
feature 169 (0.013565)
feature 141 (0.013145)
feature 203 (0.012415)
feature 54 (0.011911)
feature 129 (0.011789)
feature 120 (0.011762)
feature 60 (0.011341)
feature 210 (0.011125)
feature 106 (0.010359)
feature 161 (0.010074)
feature 207 (0.009631)
inner fold=3
accuracy=0.688888888889
feature 43 (0.028349)
feature 172 (0.027480)
feature 156 (0.019994)
feature 166 (0.019656)
feature 168 (0.019383)
feature 231 (0.019011)
feature 202 (0.018335)
feature 214 (0.018221)
feature 60 (0.016972)
feature 52 (0.016374)
feature 200 (0.015162)
feature 134 (0.014472)
feature 161 (0.014268)
feature 24 (0.013725)
feature 0 (0.013674)
feature 81 (0.013670)
feature 227 (0.013167)
feature 216 (0.012921)
feature 175 (0.012865)
feature 294 (0.012690)
feature 115 (0.012572)
feature 215 (0.012519)
feature 203 (0.011840)
feature 33 (0.011701)
feature 80 (0.011667)
feature 148 (0.011492)
feature 68 (0.011391)
feature 188 (0.011298)
feature 171 (0.011256)
feature 78 (0.011210)
inner fold=4
accuracy=0.555555555556

lay_id=2
feature 175 (0.031737)
feature 134 (0.027854)
feature 123 (0.027342)
feature 110 (0.020532)
feature 33 (0.020320)
feature 182 (0.016713)
feature 153 (0.015849)
feature 231 (0.015590)
feature 145 (0.014995)
feature 125 (0.014612)
feature 294 (0.014546)
feature 135 (0.014481)
feature 173 (0.014321)
feature 40 (0.014293)
feature 213 (0.014281)
feature 5 (0.013515)
feature 161 (0.013486)
feature 272 (0.012536)
feature 114 (0.012512)
feature 130 (0.012123)
feature 83 (0.011730)
feature 8 (0.011081)
feature 54 (0.010995)
feature 164 (0.010952)
feature 385 (0.010937)
feature 17 (0.010837)
feature 122 (0.010542)
feature 166 (0.010436)
feature 57 (0.010269)
feature 168 (0.009754)
inner fold=0
accuracy=0.586956521739
feature 139 (0.029604)
feature 128 (0.025936)
feature 155 (0.025856)
feature 153 (0.023997)
feature 141 (0.020693)
feature 164 (0.020015)
feature 344 (0.019221)
feature 58 (0.017538)
feature 203 (0.016834)
feature 84 (0.016584)
feature 18 (0.015863)
feature 385 (0.015407)
feature 340 (0.015000)
feature 130 (0.014824)
feature 129 (0.014786)
feature 55 (0.014112)
feature 78 (0.014068)
feature 171 (0.014020)
feature 183 (0.014004)
feature 107 (0.012771)
feature 200 (0.012526)
feature 81 (0.012515)
feature 63 (0.012273)
feature 362 (0.012228)
feature 21 (0.012016)
feature 123 (0.011912)
feature 62 (0.011253)
feature 42 (0.011073)
feature 234 (0.010913)
feature 54 (0.010648)
inner fold=1
accuracy=0.630434782609
feature 134 (0.029444)
feature 168 (0.026588)
feature 222 (0.025516)
feature 77 (0.023755)
feature 171 (0.023704)
feature 153 (0.021892)
feature 51 (0.020631)
feature 173 (0.019743)
feature 157 (0.018805)
feature 109 (0.016933)
feature 30 (0.016695)
feature 166 (0.016498)
feature 160 (0.016282)
feature 216 (0.015309)
feature 81 (0.014331)
feature 211 (0.013706)
feature 148 (0.013292)
feature 82 (0.013055)
feature 175 (0.012709)
feature 102 (0.012708)
feature 33 (0.011681)
feature 3 (0.011440)
feature 215 (0.011201)
feature 62 (0.011113)
feature 139 (0.010868)
feature 131 (0.010785)
feature 54 (0.010766)
feature 14 (0.010659)
feature 136 (0.010267)
feature 213 (0.010176)
inner fold=2
accuracy=0.565217391304
feature 168 (0.031697)
feature 46 (0.028718)
feature 84 (0.021553)
feature 43 (0.020880)
feature 171 (0.020834)
feature 33 (0.019372)
feature 123 (0.019008)
feature 134 (0.016939)
feature 129 (0.016516)
feature 79 (0.016257)
feature 169 (0.015976)
feature 138 (0.015748)
feature 175 (0.015727)
feature 203 (0.015400)
feature 110 (0.015315)
feature 101 (0.014674)
feature 145 (0.013800)
feature 68 (0.013481)
feature 148 (0.012393)
feature 40 (0.012279)
feature 56 (0.012162)
feature 349 (0.012054)
feature 29 (0.011748)
feature 80 (0.011221)
feature 81 (0.011200)
feature 3 (0.009912)
feature 55 (0.009728)
feature 223 (0.009652)
feature 126 (0.009412)
feature 174 (0.008943)
inner fold=3
accuracy=0.644444444444
feature 171 (0.031659)
feature 222 (0.028857)
feature 2 (0.026927)
feature 152 (0.023953)
feature 199 (0.023470)
feature 235 (0.022320)
feature 184 (0.020972)
feature 294 (0.020118)
feature 231 (0.019005)
feature 62 (0.018216)
feature 84 (0.017467)
feature 158 (0.016918)
feature 83 (0.016528)
feature 44 (0.016514)
feature 408 (0.016461)
feature 80 (0.016381)
feature 164 (0.015794)
feature 30 (0.014548)
feature 157 (0.014135)
feature 174 (0.013313)
feature 175 (0.013172)
feature 38 (0.012597)
feature 210 (0.012422)
feature 182 (0.011761)
feature 156 (0.011541)
feature 46 (0.011226)
feature 106 (0.010845)
feature 125 (0.010604)
feature 183 (0.010491)
feature 135 (0.010090)
inner fold=4
accuracy=0.6
feature 294 (0.042786)
feature 148 (0.030886)
feature 159 (0.023865)
feature 104 (0.021226)
feature 14 (0.020671)
feature 101 (0.020243)
feature 209 (0.020204)
feature 344 (0.019759)
feature 201 (0.019206)
feature 34 (0.019025)
feature 166 (0.017134)
feature 110 (0.015197)
feature 102 (0.014887)
feature 46 (0.014835)
feature 114 (0.014349)
feature 174 (0.014123)
feature 216 (0.013363)
feature 129 (0.013152)
feature 142 (0.013125)
feature 169 (0.013107)
feature 97 (0.013069)
feature 140 (0.012447)
feature 227 (0.012413)
feature 173 (0.012354)
feature 56 (0.011691)
feature 165 (0.011644)
feature 136 (0.011618)
feature 222 (0.011506)
feature 139 (0.010221)
feature 134 (0.009752)
inner fold=0
accuracy=0.521739130435
feature 136 (0.044034)
feature 294 (0.038364)
feature 171 (0.028279)
feature 101 (0.024941)
feature 344 (0.018884)
feature 214 (0.018629)
feature 175 (0.017683)
feature 138 (0.017458)
feature 123 (0.017412)
feature 109 (0.016421)
feature 158 (0.015119)
feature 215 (0.014777)
feature 148 (0.014430)
feature 210 (0.012505)
feature 81 (0.012170)
feature 128 (0.012049)
feature 143 (0.011348)
feature 159 (0.011259)
feature 172 (0.011106)
feature 24 (0.010999)
feature 182 (0.010847)
feature 44 (0.010660)
feature 153 (0.010498)
feature 165 (0.010458)
feature 16 (0.010436)
feature 188 (0.010095)
feature 45 (0.010019)
feature 222 (0.009836)
feature 52 (0.009824)
feature 82 (0.009533)
inner fold=1
accuracy=0.717391304348
feature 43 (0.035002)
feature 171 (0.030783)
feature 123 (0.028521)
feature 46 (0.026366)
feature 78 (0.024239)
feature 129 (0.017524)
feature 167 (0.016905)
feature 77 (0.016426)
feature 40 (0.014326)
feature 156 (0.013932)
feature 134 (0.013683)
feature 168 (0.013664)
feature 227 (0.013526)
feature 203 (0.013092)
feature 109 (0.012535)
feature 81 (0.012430)
feature 148 (0.012229)
feature 128 (0.012199)
feature 14 (0.011627)
feature 272 (0.011125)
feature 63 (0.011100)
feature 193 (0.011075)
feature 51 (0.010914)
feature 231 (0.010896)
feature 202 (0.010280)
feature 69 (0.010125)
feature 121 (0.009954)
feature 72 (0.009781)
feature 138 (0.009565)
feature 33 (0.009345)
inner fold=2
accuracy=0.673913043478
feature 294 (0.055549)
feature 81 (0.027928)
feature 168 (0.027026)
feature 160 (0.026883)
feature 166 (0.021092)
feature 123 (0.018689)
feature 213 (0.017923)
feature 344 (0.017079)
feature 155 (0.015303)
feature 175 (0.015255)
feature 272 (0.015240)
feature 222 (0.014879)
feature 148 (0.014651)
feature 153 (0.014305)
feature 14 (0.014206)
feature 381 (0.013830)
feature 139 (0.013372)
feature 130 (0.013094)
feature 216 (0.012962)
feature 136 (0.012888)
feature 47 (0.012369)
feature 209 (0.012039)
feature 231 (0.012038)
feature 180 (0.011736)
feature 215 (0.011260)
feature 46 (0.011193)
feature 134 (0.011159)
feature 5 (0.011118)
feature 149 (0.011097)
feature 385 (0.010572)
inner fold=3
accuracy=0.511111111111
feature 129 (0.029809)
feature 153 (0.029131)
feature 171 (0.022380)
feature 272 (0.018878)
feature 182 (0.018759)
feature 151 (0.016348)
feature 2 (0.016128)
feature 79 (0.016059)
feature 148 (0.014665)
feature 30 (0.014154)
feature 209 (0.014076)
feature 121 (0.013993)
feature 110 (0.013915)
feature 138 (0.013614)
feature 53 (0.013611)
feature 158 (0.013465)
feature 44 (0.013255)
feature 12 (0.013146)
feature 202 (0.012901)
feature 51 (0.012877)
feature 172 (0.012722)
feature 40 (0.012447)
feature 165 (0.012289)
feature 397 (0.012231)
feature 184 (0.011896)
feature 123 (0.011866)
feature 159 (0.011821)
feature 143 (0.011552)
feature 381 (0.011391)
feature 142 (0.011388)
inner fold=4
accuracy=0.688888888889

lay_id=3
feature 171 (0.032934)
feature 4 (0.030768)
feature 148 (0.021534)
feature 207 (0.017782)
feature 129 (0.017224)
feature 157 (0.016337)
feature 101 (0.016225)
feature 63 (0.015961)
feature 18 (0.015671)
feature 55 (0.015461)
feature 160 (0.015179)
feature 165 (0.015002)
feature 46 (0.014727)
feature 166 (0.014494)
feature 213 (0.014444)
feature 138 (0.014188)
feature 135 (0.014150)
feature 164 (0.014134)
feature 231 (0.013893)
feature 131 (0.013690)
feature 126 (0.013350)
feature 152 (0.013143)
feature 27 (0.012359)
feature 161 (0.012022)
feature 56 (0.011645)
feature 40 (0.011635)
feature 153 (0.011566)
feature 57 (0.011482)
feature 58 (0.011444)
feature 106 (0.011333)
inner fold=0
accuracy=0.586956521739
feature 171 (0.057161)
feature 43 (0.026548)
feature 172 (0.022666)
feature 166 (0.022260)
feature 135 (0.019156)
feature 138 (0.018898)
feature 129 (0.018415)
feature 156 (0.017978)
feature 58 (0.017225)
feature 30 (0.017051)
feature 34 (0.016350)
feature 81 (0.016300)
feature 12 (0.014963)
feature 84 (0.014440)
feature 344 (0.014151)
feature 70 (0.013560)
feature 203 (0.013460)
feature 294 (0.013456)
feature 57 (0.013271)
feature 18 (0.013137)
feature 184 (0.012646)
feature 159 (0.012017)
feature 127 (0.011757)
feature 120 (0.011610)
feature 211 (0.011399)
feature 97 (0.011339)
feature 48 (0.010896)
feature 235 (0.010893)
feature 102 (0.010837)
feature 464 (0.010783)
inner fold=1
accuracy=0.652173913043
feature 175 (0.029620)
feature 81 (0.025392)
feature 172 (0.022228)
feature 158 (0.021426)
feature 129 (0.018715)
feature 168 (0.017444)
feature 294 (0.017191)
feature 165 (0.016781)
feature 82 (0.015870)
feature 156 (0.015553)
feature 171 (0.014911)
feature 80 (0.014589)
feature 43 (0.014436)
feature 139 (0.014319)
feature 164 (0.013777)
feature 53 (0.013418)
feature 153 (0.013344)
feature 151 (0.013086)
feature 339 (0.012890)
feature 29 (0.012834)
feature 110 (0.012654)
feature 183 (0.012613)
feature 56 (0.012344)
feature 207 (0.012032)
feature 442 (0.011748)
feature 52 (0.011286)
feature 161 (0.011170)
feature 28 (0.010982)
feature 215 (0.010882)
feature 141 (0.010862)
inner fold=2
accuracy=0.586956521739
feature 81 (0.033915)
feature 175 (0.027623)
feature 127 (0.024891)
feature 123 (0.022758)
feature 156 (0.021063)
feature 294 (0.020096)
feature 165 (0.018667)
feature 174 (0.018287)
feature 102 (0.018242)
feature 231 (0.017860)
feature 272 (0.016579)
feature 203 (0.016561)
feature 58 (0.016079)
feature 202 (0.015370)
feature 134 (0.014792)
feature 168 (0.014473)
feature 180 (0.014078)
feature 24 (0.013810)
feature 126 (0.013503)
feature 166 (0.013266)
feature 107 (0.012546)
feature 109 (0.011830)
feature 28 (0.011703)
feature 52 (0.011679)
feature 30 (0.011539)
feature 235 (0.011187)
feature 110 (0.011020)
feature 155 (0.010773)
feature 12 (0.010727)
feature 122 (0.010685)
inner fold=3
accuracy=0.6
feature 227 (0.025894)
feature 139 (0.024187)
feature 172 (0.022044)
feature 81 (0.021452)
feature 58 (0.020658)
feature 175 (0.020399)
feature 12 (0.019125)
feature 166 (0.017154)
feature 199 (0.014790)
feature 362 (0.014196)
feature 54 (0.014161)
feature 168 (0.014092)
feature 215 (0.013942)
feature 38 (0.013330)
feature 208 (0.013324)
feature 77 (0.013165)
feature 43 (0.012812)
feature 14 (0.011961)
feature 123 (0.011876)
feature 130 (0.011838)
feature 107 (0.011741)
feature 33 (0.011688)
feature 224 (0.011242)
feature 155 (0.011195)
feature 170 (0.010744)
feature 164 (0.010306)
feature 18 (0.010251)
feature 171 (0.010151)
feature 105 (0.009857)
feature 110 (0.009795)
inner fold=4
accuracy=0.488888888889
feature 165 (0.034420)
feature 171 (0.027363)
feature 294 (0.021482)
feature 213 (0.020884)
feature 107 (0.018584)
feature 385 (0.018302)
feature 172 (0.018272)
feature 125 (0.016763)
feature 153 (0.016457)
feature 135 (0.015696)
feature 44 (0.015415)
feature 145 (0.015358)
feature 5 (0.015274)
feature 101 (0.014984)
feature 131 (0.014646)
feature 164 (0.014345)
feature 167 (0.014343)
feature 138 (0.014052)
feature 168 (0.013744)
feature 130 (0.013598)
feature 151 (0.013451)
feature 115 (0.013427)
feature 344 (0.012746)
feature 156 (0.012741)
feature 84 (0.012443)
feature 69 (0.011667)
feature 199 (0.011644)
feature 58 (0.011324)
feature 52 (0.011104)
feature 39 (0.011064)
inner fold=0
accuracy=0.565217391304
feature 80 (0.053253)
feature 81 (0.032525)
feature 69 (0.019344)
feature 78 (0.017152)
feature 46 (0.017003)
feature 45 (0.016765)
feature 173 (0.016660)
feature 155 (0.014581)
feature 84 (0.014029)
feature 129 (0.013632)
feature 82 (0.013615)
feature 121 (0.013606)
feature 151 (0.012719)
feature 128 (0.012556)
feature 47 (0.012402)
feature 172 (0.012255)
feature 159 (0.012156)
feature 54 (0.011671)
feature 166 (0.011498)
feature 142 (0.011340)
feature 344 (0.011294)
feature 109 (0.011250)
feature 122 (0.010997)
feature 4 (0.010990)
feature 125 (0.010735)
feature 164 (0.010588)
feature 182 (0.010426)
feature 130 (0.010249)
feature 137 (0.010186)
feature 50 (0.010185)
inner fold=1
accuracy=0.586956521739
feature 231 (0.027774)
feature 4 (0.027252)
feature 294 (0.025288)
feature 168 (0.023850)
feature 227 (0.020904)
feature 344 (0.019980)
feature 210 (0.018328)
feature 101 (0.018288)
feature 172 (0.017175)
feature 109 (0.015817)
feature 182 (0.015530)
feature 63 (0.015325)
feature 12 (0.015240)
feature 139 (0.014927)
feature 148 (0.014350)
feature 166 (0.013267)
feature 454 (0.012832)
feature 158 (0.012328)
feature 77 (0.011543)
feature 55 (0.011475)
feature 14 (0.011444)
feature 199 (0.011245)
feature 24 (0.011191)
feature 122 (0.010844)
feature 157 (0.010294)
feature 153 (0.010255)
feature 79 (0.010158)
feature 30 (0.010130)
feature 200 (0.009861)
feature 103 (0.009541)
inner fold=2
accuracy=0.521739130435
feature 385 (0.038267)
feature 156 (0.026431)
feature 166 (0.023375)
feature 158 (0.022178)
feature 454 (0.021907)
feature 207 (0.020964)
feature 134 (0.019785)
feature 173 (0.017941)
feature 38 (0.016798)
feature 152 (0.015921)
feature 110 (0.015829)
feature 183 (0.015750)
feature 107 (0.015106)
feature 159 (0.014625)
feature 101 (0.014438)
feature 12 (0.013524)
feature 109 (0.013303)
feature 140 (0.013298)
feature 142 (0.013219)
feature 126 (0.013061)
feature 216 (0.012333)
feature 72 (0.012286)
feature 42 (0.012215)
feature 51 (0.011893)
feature 4 (0.011423)
feature 105 (0.011226)
feature 136 (0.011202)
feature 213 (0.010978)
feature 203 (0.010826)
feature 34 (0.010804)
inner fold=3
accuracy=0.488888888889
feature 168 (0.035419)
feature 46 (0.028095)
feature 84 (0.021415)
feature 172 (0.019055)
feature 381 (0.018357)
feature 38 (0.018274)
feature 139 (0.016522)
feature 227 (0.016496)
feature 199 (0.016139)
feature 169 (0.015968)
feature 148 (0.015732)
feature 158 (0.014968)
feature 294 (0.014695)
feature 1 (0.014527)
feature 136 (0.014173)
feature 182 (0.013835)
feature 211 (0.013830)
feature 188 (0.013780)
feature 56 (0.013425)
feature 4 (0.012234)
feature 126 (0.012023)
feature 215 (0.011535)
feature 127 (0.011136)
feature 97 (0.010944)
feature 216 (0.010941)
feature 81 (0.010904)
feature 109 (0.010709)
feature 131 (0.010148)
feature 79 (0.010079)
feature 192 (0.010067)
inner fold=4
accuracy=0.622222222222

lay_id=4
feature 235 (0.042915)
feature 294 (0.028446)
feature 208 (0.027099)
feature 227 (0.026219)
feature 79 (0.024391)
feature 203 (0.022325)
feature 164 (0.018477)
feature 159 (0.017217)
feature 215 (0.016710)
feature 30 (0.015742)
feature 134 (0.014786)
feature 127 (0.014564)
feature 33 (0.014133)
feature 201 (0.013712)
feature 157 (0.013665)
feature 390 (0.013551)
feature 109 (0.013198)
feature 123 (0.012853)
feature 207 (0.012799)
feature 131 (0.012424)
feature 46 (0.012344)
feature 151 (0.012085)
feature 152 (0.011937)
feature 135 (0.011608)
feature 125 (0.011152)
feature 114 (0.010898)
feature 50 (0.010840)
feature 149 (0.010648)
feature 62 (0.010421)
feature 385 (0.010369)
inner fold=0
accuracy=0.652173913043
feature 203 (0.036865)
feature 44 (0.025330)
feature 123 (0.025113)
feature 58 (0.021327)
feature 168 (0.019919)
feature 12 (0.019181)
feature 155 (0.018583)
feature 131 (0.018172)
feature 80 (0.016863)
feature 171 (0.016483)
feature 81 (0.015757)
feature 42 (0.014453)
feature 122 (0.013663)
feature 134 (0.013391)
feature 173 (0.013315)
feature 56 (0.013180)
feature 207 (0.013033)
feature 120 (0.012785)
feature 213 (0.012597)
feature 30 (0.012493)
feature 125 (0.012489)
feature 149 (0.012022)
feature 55 (0.011334)
feature 82 (0.011313)
feature 142 (0.011016)
feature 57 (0.010674)
feature 188 (0.010674)
feature 294 (0.010516)
feature 126 (0.010466)
feature 139 (0.009841)
inner fold=1
accuracy=0.673913043478
feature 174 (0.032323)
feature 203 (0.030009)
feature 172 (0.025256)
feature 165 (0.024352)
feature 134 (0.024157)
feature 81 (0.018532)
feature 30 (0.016789)
feature 122 (0.016470)
feature 80 (0.016396)
feature 106 (0.016375)
feature 215 (0.015913)
feature 231 (0.015491)
feature 158 (0.015373)
feature 34 (0.014618)
feature 344 (0.013881)
feature 121 (0.013609)
feature 138 (0.013542)
feature 208 (0.013526)
feature 129 (0.013376)
feature 35 (0.012971)
feature 57 (0.012811)
feature 200 (0.012440)
feature 164 (0.012348)
feature 152 (0.012030)
feature 3 (0.012023)
feature 211 (0.011934)
feature 74 (0.011129)
feature 85 (0.011057)
feature 84 (0.010833)
feature 62 (0.010604)
inner fold=2
accuracy=0.521739130435
feature 129 (0.036576)
feature 231 (0.028636)
feature 294 (0.025331)
feature 123 (0.022981)
feature 52 (0.021052)
feature 202 (0.019863)
feature 40 (0.017931)
feature 151 (0.017816)
feature 385 (0.017424)
feature 101 (0.017409)
feature 46 (0.017332)
feature 122 (0.016509)
feature 349 (0.014568)
feature 43 (0.014562)
feature 201 (0.014170)
feature 102 (0.013571)
feature 110 (0.013406)
feature 125 (0.012778)
feature 203 (0.012501)
feature 411 (0.012391)
feature 17 (0.012356)
feature 51 (0.011992)
feature 4 (0.011688)
feature 107 (0.011489)
feature 222 (0.010923)
feature 56 (0.010887)
feature 172 (0.010883)
feature 166 (0.010863)
feature 173 (0.010850)
feature 216 (0.009998)
inner fold=3
accuracy=0.555555555556
feature 137 (0.029104)
feature 30 (0.025526)
feature 174 (0.025094)
feature 134 (0.024899)
feature 129 (0.024814)
feature 208 (0.020691)
feature 110 (0.019758)
feature 165 (0.018411)
feature 78 (0.017967)
feature 14 (0.017092)
feature 344 (0.016778)
feature 203 (0.015942)
feature 171 (0.015826)
feature 385 (0.015006)
feature 159 (0.014086)
feature 168 (0.013921)
feature 211 (0.013858)
feature 51 (0.013638)
feature 106 (0.013301)
feature 48 (0.012467)
feature 349 (0.011016)
feature 62 (0.010702)
feature 227 (0.010591)
feature 209 (0.010166)
feature 275 (0.009953)
feature 210 (0.009916)
feature 126 (0.009812)
feature 42 (0.009760)
feature 222 (0.009616)
feature 114 (0.009336)
inner fold=4
accuracy=0.511111111111
feature 138 (0.025314)
feature 122 (0.024109)
feature 81 (0.022347)
feature 172 (0.020408)
feature 72 (0.019846)
feature 137 (0.018466)
feature 101 (0.017929)
feature 164 (0.016800)
feature 24 (0.016323)
feature 33 (0.015277)
feature 202 (0.014474)
feature 54 (0.013964)
feature 152 (0.013325)
feature 160 (0.013107)
feature 35 (0.012929)
feature 171 (0.012839)
feature 14 (0.012652)
feature 12 (0.012616)
feature 156 (0.012581)
feature 222 (0.012519)
feature 153 (0.012359)
feature 394 (0.011910)
feature 199 (0.011861)
feature 125 (0.011390)
feature 129 (0.010716)
feature 272 (0.010441)
feature 114 (0.010228)
feature 80 (0.010179)
feature 73 (0.010173)
feature 18 (0.009992)
inner fold=0
accuracy=0.630434782609
feature 138 (0.038898)
feature 344 (0.021977)
feature 203 (0.019936)
feature 153 (0.019364)
feature 134 (0.017348)
feature 167 (0.016616)
feature 120 (0.016530)
feature 294 (0.015936)
feature 202 (0.015793)
feature 197 (0.015260)
feature 199 (0.015232)
feature 35 (0.015142)
feature 55 (0.014536)
feature 129 (0.013965)
feature 51 (0.013914)
feature 139 (0.013198)
feature 24 (0.012727)
feature 106 (0.012693)
feature 68 (0.012030)
feature 164 (0.011906)
feature 148 (0.011774)
feature 213 (0.011771)
feature 73 (0.011717)
feature 105 (0.011544)
feature 223 (0.011502)
feature 12 (0.010885)
feature 172 (0.010600)
feature 103 (0.010581)
feature 123 (0.010445)
feature 110 (0.010386)
inner fold=1
accuracy=0.54347826087
feature 208 (0.027458)
feature 158 (0.021138)
feature 110 (0.017994)
feature 81 (0.017713)
feature 80 (0.017222)
feature 164 (0.017162)
feature 122 (0.017086)
feature 52 (0.016724)
feature 123 (0.016561)
feature 213 (0.016118)
feature 134 (0.015607)
feature 30 (0.015398)
feature 210 (0.015301)
feature 43 (0.015045)
feature 24 (0.014600)
feature 109 (0.014589)
feature 168 (0.014012)
feature 235 (0.014010)
feature 209 (0.013630)
feature 138 (0.013554)
feature 62 (0.013521)
feature 146 (0.013377)
feature 5 (0.012743)
feature 231 (0.012691)
feature 33 (0.012359)
feature 174 (0.012079)
feature 169 (0.011722)
feature 78 (0.011605)
feature 155 (0.011141)
feature 35 (0.010432)
inner fold=2
accuracy=0.673913043478
feature 153 (0.037217)
feature 110 (0.024731)
feature 152 (0.023030)
feature 442 (0.022315)
feature 235 (0.021377)
feature 138 (0.020375)
feature 83 (0.020131)
feature 46 (0.020045)
feature 35 (0.019098)
feature 167 (0.017268)
feature 202 (0.016723)
feature 134 (0.016550)
feature 182 (0.015838)
feature 171 (0.015608)
feature 172 (0.014418)
feature 82 (0.014372)
feature 78 (0.013830)
feature 30 (0.013429)
feature 81 (0.012725)
feature 165 (0.012562)
feature 14 (0.012395)
feature 44 (0.012292)
feature 130 (0.011275)
feature 57 (0.011183)
feature 385 (0.010781)
feature 133 (0.010469)
feature 51 (0.010256)
feature 222 (0.010224)
feature 197 (0.010108)
feature 168 (0.009919)
inner fold=3
accuracy=0.755555555556
feature 202 (0.031941)
feature 168 (0.027623)
feature 136 (0.025204)
feature 169 (0.023576)
feature 139 (0.021745)
feature 235 (0.018862)
feature 166 (0.017933)
feature 52 (0.015857)
feature 294 (0.015394)
feature 175 (0.015133)
feature 46 (0.014962)
feature 222 (0.013458)
feature 285 (0.013136)
feature 130 (0.012905)
feature 24 (0.012864)
feature 464 (0.012833)
feature 4 (0.012165)
feature 183 (0.011687)
feature 78 (0.010993)
feature 156 (0.010978)
feature 126 (0.010908)
feature 362 (0.010729)
feature 165 (0.010696)
feature 62 (0.010689)
feature 14 (0.010498)
feature 51 (0.010010)
feature 38 (0.009536)
feature 261 (0.009336)
feature 28 (0.009316)
feature 127 (0.008912)
inner fold=4
accuracy=0.488888888889

outer fold 8
lay_id=0
feature 164 (0.035073)
feature 155 (0.026677)
feature 110 (0.025726)
feature 51 (0.022953)
feature 223 (0.018322)
feature 123 (0.017662)
feature 133 (0.017309)
feature 152 (0.017101)
feature 377 (0.015160)
feature 203 (0.014473)
feature 106 (0.014380)
feature 211 (0.014327)
feature 137 (0.014289)
feature 34 (0.014102)
feature 170 (0.013950)
feature 138 (0.013798)
feature 58 (0.013746)
feature 131 (0.013731)
feature 198 (0.012912)
feature 149 (0.012583)
feature 78 (0.012475)
feature 154 (0.012329)
feature 167 (0.012284)
feature 74 (0.012035)
feature 76 (0.011944)
feature 38 (0.011883)
feature 161 (0.011685)
feature 73 (0.011444)
feature 116 (0.011236)
feature 205 (0.011039)
inner fold=0
accuracy=0.673913043478
feature 125 (0.045766)
feature 290 (0.031162)
feature 0 (0.028033)
feature 124 (0.026381)
feature 116 (0.025472)
feature 167 (0.024944)
feature 212 (0.020670)
feature 408 (0.017695)
feature 35 (0.017652)
feature 119 (0.016909)
feature 184 (0.016727)
feature 53 (0.016619)
feature 160 (0.015959)
feature 199 (0.015479)
feature 10 (0.014551)
feature 139 (0.014543)
feature 137 (0.013991)
feature 149 (0.013761)
feature 207 (0.013416)
feature 227 (0.013108)
feature 203 (0.012139)
feature 126 (0.012125)
feature 52 (0.011933)
feature 407 (0.011798)
feature 220 (0.011582)
feature 48 (0.011311)
feature 78 (0.010556)
feature 26 (0.010453)
feature 105 (0.010151)
feature 123 (0.010072)
inner fold=1
accuracy=0.586956521739
feature 170 (0.035503)
feature 125 (0.034090)
feature 168 (0.026501)
feature 152 (0.024965)
feature 227 (0.020639)
feature 199 (0.019689)
feature 97 (0.019610)
feature 144 (0.018697)
feature 49 (0.016282)
feature 18 (0.016133)
feature 161 (0.016121)
feature 377 (0.014918)
feature 460 (0.014892)
feature 205 (0.014746)
feature 155 (0.014083)
feature 10 (0.013815)
feature 164 (0.013777)
feature 140 (0.013596)
feature 379 (0.013570)
feature 223 (0.012897)
feature 231 (0.012543)
feature 445 (0.012420)
feature 178 (0.012327)
feature 290 (0.012227)
feature 407 (0.011957)
feature 177 (0.011478)
feature 219 (0.011173)
feature 69 (0.010603)
feature 38 (0.010258)
feature 340 (0.010044)
inner fold=2
accuracy=0.608695652174
feature 111 (0.030827)
feature 76 (0.028796)
feature 119 (0.027715)
feature 20 (0.025428)
feature 154 (0.022519)
feature 168 (0.020019)
feature 180 (0.019141)
feature 184 (0.018478)
feature 223 (0.017145)
feature 41 (0.016110)
feature 135 (0.015761)
feature 164 (0.015718)
feature 197 (0.015377)
feature 138 (0.015055)
feature 207 (0.014241)
feature 39 (0.014070)
feature 54 (0.014061)
feature 49 (0.013775)
feature 74 (0.013719)
feature 139 (0.013472)
feature 38 (0.013333)
feature 133 (0.012555)
feature 102 (0.012460)
feature 204 (0.012260)
feature 196 (0.012050)
feature 58 (0.011958)
feature 25 (0.011918)
feature 134 (0.011300)
feature 152 (0.010709)
feature 159 (0.010357)
inner fold=3
accuracy=0.6
feature 152 (0.027368)
feature 227 (0.026964)
feature 30 (0.023959)
feature 119 (0.023262)
feature 184 (0.020200)
feature 231 (0.018934)
feature 38 (0.017829)
feature 223 (0.017042)
feature 171 (0.016674)
feature 209 (0.016451)
feature 132 (0.015873)
feature 134 (0.015801)
feature 167 (0.015536)
feature 290 (0.014530)
feature 153 (0.014378)
feature 26 (0.014303)
feature 54 (0.014167)
feature 164 (0.014144)
feature 76 (0.013730)
feature 4 (0.013331)
feature 29 (0.013130)
feature 51 (0.012926)
feature 98 (0.012495)
feature 0 (0.012406)
feature 168 (0.011694)
feature 20 (0.011640)
feature 144 (0.011627)
feature 149 (0.011001)
feature 106 (0.010772)
feature 450 (0.010703)
inner fold=4
accuracy=0.511111111111
feature 163 (0.029553)
feature 167 (0.028357)
feature 49 (0.023339)
feature 205 (0.023101)
feature 74 (0.021868)
feature 160 (0.020346)
feature 20 (0.020296)
feature 152 (0.020286)
feature 290 (0.019613)
feature 125 (0.019110)
feature 132 (0.017612)
feature 103 (0.016880)
feature 223 (0.016702)
feature 133 (0.015322)
feature 135 (0.015232)
feature 198 (0.014774)
feature 209 (0.014643)
feature 211 (0.014476)
feature 178 (0.013929)
feature 148 (0.013193)
feature 162 (0.013114)
feature 164 (0.011899)
feature 46 (0.011889)
feature 10 (0.011844)
feature 36 (0.011564)
feature 154 (0.011201)
feature 155 (0.010904)
feature 39 (0.010335)
feature 52 (0.010157)
feature 54 (0.010030)
inner fold=0
accuracy=0.45652173913
feature 125 (0.037908)
feature 167 (0.033978)
feature 152 (0.030593)
feature 42 (0.024828)
feature 100 (0.021751)
feature 203 (0.021075)
feature 134 (0.020460)
feature 162 (0.018636)
feature 138 (0.018581)
feature 54 (0.017864)
feature 10 (0.017694)
feature 169 (0.016326)
feature 268 (0.015411)
feature 230 (0.014794)
feature 98 (0.014744)
feature 164 (0.014726)
feature 51 (0.014649)
feature 75 (0.014347)
feature 131 (0.013877)
feature 199 (0.013742)
feature 73 (0.013453)
feature 139 (0.013437)
feature 38 (0.013128)
feature 161 (0.011658)
feature 1 (0.011264)
feature 121 (0.010926)
feature 94 (0.010834)
feature 4 (0.010449)
feature 106 (0.010298)
feature 212 (0.009993)
inner fold=1
accuracy=0.565217391304
feature 167 (0.035791)
feature 131 (0.025852)
feature 152 (0.023669)
feature 125 (0.022741)
feature 77 (0.022688)
feature 340 (0.021408)
feature 198 (0.020825)
feature 10 (0.018286)
feature 39 (0.018182)
feature 53 (0.016746)
feature 138 (0.014623)
feature 42 (0.014575)
feature 23 (0.014191)
feature 227 (0.014106)
feature 37 (0.014012)
feature 354 (0.013562)
feature 199 (0.013221)
feature 51 (0.012757)
feature 100 (0.012080)
feature 184 (0.011469)
feature 177 (0.011448)
feature 80 (0.011273)
feature 14 (0.010892)
feature 32 (0.010711)
feature 283 (0.010364)
feature 157 (0.010098)
feature 75 (0.009893)
feature 268 (0.009658)
feature 74 (0.009472)
feature 302 (0.009254)
inner fold=2
accuracy=0.673913043478
feature 290 (0.036489)
feature 131 (0.029254)
feature 132 (0.027061)
feature 134 (0.026832)
feature 151 (0.026461)
feature 184 (0.021547)
feature 69 (0.019971)
feature 133 (0.018675)
feature 164 (0.017704)
feature 130 (0.015810)
feature 125 (0.015676)
feature 30 (0.015611)
feature 197 (0.014962)
feature 223 (0.014935)
feature 122 (0.014711)
feature 152 (0.014578)
feature 199 (0.014575)
feature 135 (0.014471)
feature 4 (0.013382)
feature 138 (0.012786)
feature 340 (0.012709)
feature 91 (0.012612)
feature 209 (0.012281)
feature 10 (0.012244)
feature 121 (0.011925)
feature 26 (0.011769)
feature 52 (0.011294)
feature 169 (0.010426)
feature 206 (0.010352)
feature 212 (0.010150)
inner fold=3
accuracy=0.666666666667
feature 290 (0.048644)
feature 167 (0.033976)
feature 379 (0.026595)
feature 199 (0.025420)
feature 48 (0.024305)
feature 381 (0.023409)
feature 77 (0.018482)
feature 151 (0.018075)
feature 30 (0.017929)
feature 118 (0.017060)
feature 227 (0.017030)
feature 40 (0.016074)
feature 152 (0.015989)
feature 207 (0.014994)
feature 125 (0.014628)
feature 123 (0.014280)
feature 74 (0.013500)
feature 223 (0.013116)
feature 162 (0.012465)
feature 157 (0.011931)
feature 126 (0.011746)
feature 161 (0.011399)
feature 73 (0.011290)
feature 49 (0.010749)
feature 156 (0.010598)
feature 130 (0.010270)
feature 116 (0.010264)
feature 218 (0.010140)
feature 171 (0.009914)
feature 127 (0.009752)
inner fold=4
accuracy=0.644444444444

lay_id=1
feature 175 (0.022552)
feature 156 (0.021772)
feature 209 (0.019149)
feature 102 (0.019039)
feature 294 (0.018896)
feature 134 (0.018839)
feature 167 (0.017998)
feature 161 (0.017891)
feature 44 (0.017585)
feature 104 (0.015747)
feature 83 (0.015010)
feature 200 (0.014574)
feature 152 (0.014353)
feature 157 (0.014324)
feature 126 (0.013905)
feature 57 (0.013677)
feature 55 (0.013655)
feature 164 (0.013548)
feature 123 (0.013409)
feature 77 (0.013263)
feature 53 (0.012507)
feature 82 (0.012433)
feature 42 (0.012306)
feature 85 (0.012017)
feature 8 (0.011974)
feature 283 (0.011971)
feature 137 (0.011969)
feature 52 (0.011662)
feature 54 (0.011378)
feature 4 (0.010793)
inner fold=0
accuracy=0.565217391304
feature 294 (0.039980)
feature 172 (0.028685)
feature 227 (0.025458)
feature 157 (0.022172)
feature 46 (0.018517)
feature 135 (0.017588)
feature 169 (0.017537)
feature 129 (0.016865)
feature 78 (0.016714)
feature 173 (0.016169)
feature 53 (0.015873)
feature 122 (0.015221)
feature 130 (0.015089)
feature 125 (0.015032)
feature 3 (0.014853)
feature 168 (0.014827)
feature 137 (0.014257)
feature 138 (0.014166)
feature 110 (0.013970)
feature 62 (0.013781)
feature 213 (0.013430)
feature 81 (0.013000)
feature 153 (0.012225)
feature 80 (0.011829)
feature 28 (0.011530)
feature 63 (0.011418)
feature 143 (0.011082)
feature 136 (0.011063)
feature 430 (0.010737)
feature 24 (0.010563)
inner fold=1
accuracy=0.630434782609
feature 148 (0.024037)
feature 14 (0.023559)
feature 173 (0.023380)
feature 127 (0.023354)
feature 207 (0.020584)
feature 203 (0.019873)
feature 165 (0.019562)
feature 109 (0.019082)
feature 81 (0.016696)
feature 294 (0.015058)
feature 129 (0.014665)
feature 70 (0.014339)
feature 168 (0.013810)
feature 53 (0.013520)
feature 101 (0.013228)
feature 161 (0.012932)
feature 84 (0.012569)
feature 102 (0.012308)
feature 156 (0.012012)
feature 97 (0.011726)
feature 46 (0.011493)
feature 51 (0.011356)
feature 151 (0.011251)
feature 43 (0.011244)
feature 34 (0.010755)
feature 285 (0.010333)
feature 137 (0.010242)
feature 235 (0.010174)
feature 336 (0.010057)
feature 176 (0.009913)
inner fold=2
accuracy=0.565217391304
feature 182 (0.024773)
feature 294 (0.022869)
feature 174 (0.022091)
feature 383 (0.019652)
feature 143 (0.019407)
feature 151 (0.018178)
feature 84 (0.017886)
feature 227 (0.017654)
feature 16 (0.016582)
feature 136 (0.016574)
feature 126 (0.016081)
feature 171 (0.015663)
feature 381 (0.014552)
feature 344 (0.014028)
feature 164 (0.013988)
feature 109 (0.013837)
feature 103 (0.013575)
feature 101 (0.012959)
feature 219 (0.012820)
feature 211 (0.012165)
feature 122 (0.012016)
feature 102 (0.011962)
feature 107 (0.011893)
feature 82 (0.011552)
feature 207 (0.011459)
feature 168 (0.011197)
feature 97 (0.011187)
feature 43 (0.011185)
feature 127 (0.011044)
feature 175 (0.010742)
inner fold=3
accuracy=0.577777777778
feature 294 (0.059243)
feature 14 (0.031788)
feature 169 (0.023248)
feature 168 (0.022967)
feature 134 (0.021766)
feature 110 (0.020224)
feature 106 (0.018816)
feature 203 (0.018171)
feature 109 (0.017655)
feature 129 (0.017334)
feature 128 (0.016862)
feature 123 (0.016755)
feature 164 (0.016499)
feature 172 (0.016499)
feature 102 (0.016104)
feature 130 (0.014537)
feature 78 (0.014487)
feature 122 (0.012463)
feature 83 (0.012178)
feature 30 (0.012048)
feature 344 (0.011416)
feature 50 (0.011314)
feature 182 (0.011147)
feature 202 (0.011041)
feature 80 (0.010411)
feature 81 (0.010237)
feature 213 (0.010236)
feature 54 (0.010000)
feature 55 (0.009855)
feature 84 (0.009256)
inner fold=4
accuracy=0.644444444444
feature 231 (0.030431)
feature 100 (0.027466)
feature 209 (0.026353)
feature 188 (0.025628)
feature 142 (0.025345)
feature 110 (0.021561)
feature 156 (0.020409)
feature 134 (0.019731)
feature 53 (0.018505)
feature 30 (0.015879)
feature 148 (0.015681)
feature 2 (0.015452)
feature 138 (0.015258)
feature 44 (0.015078)
feature 52 (0.014983)
feature 275 (0.014440)
feature 160 (0.014029)
feature 159 (0.013757)
feature 82 (0.013234)
feature 137 (0.013206)
feature 143 (0.013181)
feature 381 (0.013024)
feature 152 (0.012585)
feature 165 (0.011892)
feature 55 (0.011709)
feature 62 (0.011420)
feature 43 (0.011288)
feature 215 (0.011104)
feature 60 (0.010483)
feature 139 (0.010314)
inner fold=0
accuracy=0.630434782609
feature 148 (0.028547)
feature 46 (0.028137)
feature 336 (0.025026)
feature 14 (0.022733)
feature 164 (0.021455)
feature 172 (0.019154)
feature 85 (0.018080)
feature 184 (0.017434)
feature 110 (0.016882)
feature 153 (0.016618)
feature 171 (0.016219)
feature 235 (0.016033)
feature 294 (0.015266)
feature 126 (0.014705)
feature 207 (0.014689)
feature 34 (0.014601)
feature 227 (0.013981)
feature 99 (0.013870)
feature 17 (0.013792)
feature 134 (0.013774)
feature 156 (0.013683)
feature 199 (0.013401)
feature 155 (0.012828)
feature 166 (0.012213)
feature 131 (0.011872)
feature 203 (0.011371)
feature 5 (0.010914)
feature 70 (0.010733)
feature 169 (0.010601)
feature 58 (0.010375)
inner fold=1
accuracy=0.608695652174
feature 344 (0.030045)
feature 136 (0.022073)
feature 294 (0.020350)
feature 172 (0.020195)
feature 171 (0.019893)
feature 139 (0.019124)
feature 81 (0.018394)
feature 164 (0.017541)
feature 199 (0.016583)
feature 46 (0.016575)
feature 216 (0.016467)
feature 168 (0.016267)
feature 152 (0.015981)
feature 143 (0.015576)
feature 44 (0.015535)
feature 60 (0.015348)
feature 84 (0.015155)
feature 101 (0.014608)
feature 122 (0.014352)
feature 227 (0.014218)
feature 123 (0.013633)
feature 140 (0.013632)
feature 372 (0.012871)
feature 78 (0.012455)
feature 201 (0.012323)
feature 454 (0.012310)
feature 130 (0.012107)
feature 185 (0.011412)
feature 231 (0.011263)
feature 69 (0.010958)
inner fold=2
accuracy=0.5
feature 18 (0.036941)
feature 81 (0.032135)
feature 136 (0.031282)
feature 148 (0.022809)
feature 454 (0.020521)
feature 156 (0.019049)
feature 4 (0.018138)
feature 173 (0.017622)
feature 174 (0.016229)
feature 216 (0.015832)
feature 126 (0.015622)
feature 128 (0.015606)
feature 211 (0.015591)
feature 12 (0.015444)
feature 192 (0.015393)
feature 54 (0.014974)
feature 210 (0.014837)
feature 14 (0.013457)
feature 1 (0.013402)
feature 184 (0.012682)
feature 175 (0.012556)
feature 152 (0.012215)
feature 29 (0.011020)
feature 82 (0.010898)
feature 138 (0.010895)
feature 294 (0.010773)
feature 33 (0.010737)
feature 135 (0.010382)
feature 209 (0.010257)
feature 30 (0.009881)
inner fold=3
accuracy=0.644444444444
feature 231 (0.042597)
feature 184 (0.026506)
feature 227 (0.025031)
feature 294 (0.023198)
feature 14 (0.019840)
feature 30 (0.019120)
feature 203 (0.018327)
feature 156 (0.017688)
feature 381 (0.016488)
feature 54 (0.016065)
feature 78 (0.015757)
feature 79 (0.015625)
feature 202 (0.015532)
feature 62 (0.015410)
feature 110 (0.015280)
feature 165 (0.015079)
feature 172 (0.014745)
feature 33 (0.014592)
feature 40 (0.014587)
feature 24 (0.013733)
feature 81 (0.013034)
feature 70 (0.012889)
feature 43 (0.012787)
feature 17 (0.012500)
feature 51 (0.012460)
feature 83 (0.011997)
feature 200 (0.011964)
feature 103 (0.011352)
feature 73 (0.011186)
feature 143 (0.011010)
inner fold=4
accuracy=0.644444444444

lay_id=2
feature 109 (0.036356)
feature 138 (0.028447)
feature 153 (0.025268)
feature 30 (0.021209)
feature 123 (0.020834)
feature 231 (0.018728)
feature 173 (0.018410)
feature 172 (0.017639)
feature 166 (0.017612)
feature 148 (0.016916)
feature 203 (0.016787)
feature 129 (0.015946)
feature 122 (0.015550)
feature 142 (0.014959)
feature 121 (0.014883)
feature 4 (0.014231)
feature 159 (0.014027)
feature 53 (0.013909)
feature 78 (0.013516)
feature 184 (0.013197)
feature 157 (0.013188)
feature 55 (0.013056)
feature 85 (0.012920)
feature 134 (0.012279)
feature 165 (0.012089)
feature 34 (0.011763)
feature 60 (0.011507)
feature 38 (0.010781)
feature 167 (0.010390)
feature 0 (0.010273)
inner fold=0
accuracy=0.565217391304
feature 164 (0.026207)
feature 135 (0.023037)
feature 166 (0.022048)
feature 128 (0.021988)
feature 136 (0.019322)
feature 4 (0.018413)
feature 171 (0.018373)
feature 33 (0.018245)
feature 139 (0.018034)
feature 38 (0.017270)
feature 101 (0.016792)
feature 147 (0.015780)
feature 69 (0.015508)
feature 123 (0.015494)
feature 227 (0.015173)
feature 168 (0.014668)
feature 60 (0.014303)
feature 180 (0.014278)
feature 120 (0.014198)
feature 125 (0.014069)
feature 199 (0.013758)
feature 174 (0.013686)
feature 165 (0.013540)
feature 141 (0.013018)
feature 28 (0.012806)
feature 24 (0.012654)
feature 183 (0.012598)
feature 172 (0.011838)
feature 215 (0.011678)
feature 185 (0.011109)
inner fold=1
accuracy=0.652173913043
feature 138 (0.028704)
feature 188 (0.025346)
feature 207 (0.023811)
feature 102 (0.019961)
feature 110 (0.019618)
feature 164 (0.019088)
feature 362 (0.018325)
feature 174 (0.018290)
feature 55 (0.016950)
feature 107 (0.016721)
feature 139 (0.016186)
feature 106 (0.015674)
feature 13 (0.015625)
feature 123 (0.015391)
feature 135 (0.015390)
feature 148 (0.014553)
feature 202 (0.013975)
feature 8 (0.013656)
feature 235 (0.013609)
feature 157 (0.013263)
feature 464 (0.013124)
feature 156 (0.013046)
feature 30 (0.012793)
feature 152 (0.011773)
feature 33 (0.011561)
feature 5 (0.011184)
feature 73 (0.011171)
feature 131 (0.010818)
feature 58 (0.010740)
feature 134 (0.010670)
inner fold=2
accuracy=0.717391304348
feature 138 (0.045881)
feature 44 (0.028549)
feature 123 (0.023444)
feature 58 (0.022307)
feature 227 (0.022113)
feature 80 (0.019491)
feature 60 (0.019350)
feature 115 (0.019177)
feature 109 (0.019170)
feature 78 (0.017850)
feature 199 (0.016080)
feature 121 (0.015412)
feature 77 (0.015059)
feature 63 (0.014460)
feature 30 (0.014325)
feature 99 (0.013958)
feature 157 (0.013578)
feature 235 (0.013548)
feature 151 (0.013339)
feature 203 (0.013248)
feature 126 (0.012859)
feature 145 (0.012625)
feature 110 (0.012495)
feature 129 (0.012463)
feature 52 (0.012232)
feature 158 (0.012122)
feature 83 (0.012101)
feature 223 (0.011762)
feature 79 (0.011530)
feature 68 (0.011500)
inner fold=3
accuracy=0.577777777778
feature 166 (0.030989)
feature 235 (0.024637)
feature 160 (0.024044)
feature 44 (0.021822)
feature 231 (0.021265)
feature 168 (0.020916)
feature 148 (0.019621)
feature 171 (0.017045)
feature 30 (0.016906)
feature 159 (0.015620)
feature 79 (0.015147)
feature 142 (0.014726)
feature 134 (0.014660)
feature 53 (0.014597)
feature 222 (0.014575)
feature 58 (0.014345)
feature 152 (0.014291)
feature 40 (0.013343)
feature 52 (0.013033)
feature 158 (0.013009)
feature 294 (0.012923)
feature 38 (0.012871)
feature 161 (0.012394)
feature 137 (0.012361)
feature 208 (0.012287)
feature 201 (0.012241)
feature 141 (0.012172)
feature 131 (0.012072)
feature 193 (0.011988)
feature 2 (0.011795)
inner fold=4
accuracy=0.555555555556
feature 294 (0.040904)
feature 14 (0.034205)
feature 110 (0.026660)
feature 135 (0.021596)
feature 166 (0.019575)
feature 81 (0.018166)
feature 71 (0.017260)
feature 227 (0.016938)
feature 138 (0.016725)
feature 203 (0.016441)
feature 235 (0.016149)
feature 199 (0.015907)
feature 99 (0.015712)
feature 129 (0.015574)
feature 128 (0.015542)
feature 213 (0.015304)
feature 78 (0.014671)
feature 142 (0.014209)
feature 149 (0.013615)
feature 143 (0.012715)
feature 73 (0.012701)
feature 53 (0.012476)
feature 152 (0.012149)
feature 30 (0.011754)
feature 46 (0.011611)
feature 123 (0.011554)
feature 104 (0.011500)
feature 209 (0.011309)
feature 39 (0.011244)
feature 137 (0.010922)
inner fold=0
accuracy=0.608695652174
feature 161 (0.029241)
feature 136 (0.027704)
feature 14 (0.026440)
feature 172 (0.024543)
feature 203 (0.022626)
feature 209 (0.021410)
feature 344 (0.021226)
feature 44 (0.019252)
feature 123 (0.018381)
feature 38 (0.017519)
feature 231 (0.017137)
feature 52 (0.016908)
feature 105 (0.016839)
feature 216 (0.015314)
feature 185 (0.015118)
feature 165 (0.014795)
feature 134 (0.014461)
feature 142 (0.013784)
feature 143 (0.013606)
feature 81 (0.013289)
feature 166 (0.012557)
feature 85 (0.011780)
feature 171 (0.011666)
feature 156 (0.011638)
feature 208 (0.011468)
feature 272 (0.011023)
feature 0 (0.010693)
feature 169 (0.010686)
feature 4 (0.010555)
feature 223 (0.010445)
inner fold=1
accuracy=0.673913043478
feature 203 (0.032574)
feature 294 (0.029815)
feature 102 (0.024684)
feature 21 (0.022361)
feature 193 (0.019770)
feature 62 (0.019156)
feature 173 (0.018726)
feature 46 (0.018459)
feature 216 (0.017506)
feature 33 (0.015747)
feature 58 (0.015547)
feature 142 (0.015360)
feature 110 (0.015256)
feature 145 (0.014511)
feature 129 (0.014005)
feature 390 (0.013682)
feature 52 (0.013577)
feature 130 (0.013405)
feature 202 (0.013307)
feature 171 (0.012946)
feature 17 (0.012894)
feature 344 (0.012443)
feature 43 (0.012061)
feature 40 (0.012055)
feature 155 (0.011939)
feature 38 (0.011600)
feature 60 (0.011513)
feature 222 (0.011412)
feature 128 (0.011341)
feature 164 (0.011009)
inner fold=2
accuracy=0.652173913043
feature 294 (0.051254)
feature 136 (0.023524)
feature 135 (0.023358)
feature 207 (0.022539)
feature 77 (0.021159)
feature 173 (0.020612)
feature 81 (0.018193)
feature 14 (0.018013)
feature 194 (0.017660)
feature 143 (0.016763)
feature 209 (0.016568)
feature 184 (0.015488)
feature 110 (0.014310)
feature 210 (0.014281)
feature 344 (0.014222)
feature 155 (0.013826)
feature 120 (0.013716)
feature 122 (0.013625)
feature 102 (0.013214)
feature 42 (0.012967)
feature 362 (0.012822)
feature 235 (0.011703)
feature 44 (0.011587)
feature 131 (0.011568)
feature 182 (0.011424)
feature 164 (0.010813)
feature 80 (0.010403)
feature 197 (0.010218)
feature 148 (0.010059)
feature 213 (0.009429)
inner fold=3
accuracy=0.533333333333
feature 153 (0.027065)
feature 38 (0.020785)
feature 227 (0.020616)
feature 156 (0.019620)
feature 344 (0.019588)
feature 166 (0.018882)
feature 129 (0.018492)
feature 148 (0.016930)
feature 50 (0.016796)
feature 454 (0.016769)
feature 46 (0.016622)
feature 136 (0.016097)
feature 154 (0.015939)
feature 159 (0.015299)
feature 125 (0.014748)
feature 110 (0.014562)
feature 43 (0.014327)
feature 175 (0.014008)
feature 44 (0.013695)
feature 135 (0.013378)
feature 84 (0.012534)
feature 80 (0.012523)
feature 123 (0.012450)
feature 58 (0.012280)
feature 171 (0.012229)
feature 231 (0.011969)
feature 24 (0.011923)
feature 74 (0.011724)
feature 235 (0.011173)
feature 142 (0.011173)
inner fold=4
accuracy=0.644444444444

lay_id=3
feature 171 (0.057654)
feature 231 (0.023097)
feature 203 (0.022390)
feature 58 (0.020840)
feature 173 (0.019015)
feature 56 (0.018430)
feature 200 (0.018050)
feature 168 (0.018013)
feature 101 (0.017630)
feature 148 (0.017312)
feature 166 (0.017160)
feature 137 (0.015841)
feature 1 (0.015577)
feature 102 (0.014849)
feature 214 (0.014473)
feature 40 (0.014412)
feature 55 (0.014317)
feature 176 (0.014212)
feature 129 (0.013941)
feature 139 (0.013864)
feature 157 (0.013460)
feature 81 (0.012982)
feature 208 (0.012797)
feature 138 (0.012313)
feature 142 (0.011278)
feature 79 (0.011172)
feature 120 (0.011040)
feature 131 (0.010832)
feature 123 (0.010623)
feature 30 (0.010412)
inner fold=0
accuracy=0.521739130435
feature 33 (0.027069)
feature 126 (0.025871)
feature 294 (0.023377)
feature 84 (0.023147)
feature 110 (0.021744)
feature 153 (0.019714)
feature 130 (0.019541)
feature 156 (0.019538)
feature 30 (0.019526)
feature 213 (0.019095)
feature 102 (0.017504)
feature 40 (0.016395)
feature 77 (0.015537)
feature 171 (0.015434)
feature 17 (0.014983)
feature 148 (0.014924)
feature 46 (0.014408)
feature 185 (0.014120)
feature 99 (0.013980)
feature 34 (0.013620)
feature 155 (0.013263)
feature 114 (0.012780)
feature 51 (0.011975)
feature 188 (0.011961)
feature 43 (0.011901)
feature 142 (0.011732)
feature 120 (0.011724)
feature 169 (0.011551)
feature 68 (0.011392)
feature 358 (0.011253)
inner fold=1
accuracy=0.54347826087
feature 158 (0.023335)
feature 110 (0.019651)
feature 120 (0.019153)
feature 51 (0.018473)
feature 14 (0.018125)
feature 4 (0.017636)
feature 80 (0.017177)
feature 362 (0.017157)
feature 344 (0.016884)
feature 57 (0.016317)
feature 43 (0.015915)
feature 138 (0.015836)
feature 168 (0.015238)
feature 235 (0.014943)
feature 210 (0.014666)
feature 175 (0.014079)
feature 115 (0.013760)
feature 231 (0.013616)
feature 199 (0.013482)
feature 24 (0.013184)
feature 52 (0.013125)
feature 214 (0.012976)
feature 272 (0.012900)
feature 114 (0.012820)
feature 294 (0.012727)
feature 130 (0.012014)
feature 46 (0.011876)
feature 41 (0.011015)
feature 129 (0.010597)
feature 148 (0.010577)
inner fold=2
accuracy=0.673913043478
feature 81 (0.029856)
feature 24 (0.026352)
feature 102 (0.026064)
feature 103 (0.022940)
feature 158 (0.022709)
feature 156 (0.022312)
feature 52 (0.018326)
feature 126 (0.018231)
feature 139 (0.018132)
feature 151 (0.017941)
feature 122 (0.017788)
feature 41 (0.017455)
feature 175 (0.015909)
feature 123 (0.015705)
feature 196 (0.014658)
feature 5 (0.014375)
feature 165 (0.013118)
feature 166 (0.012489)
feature 80 (0.012063)
feature 129 (0.011712)
feature 85 (0.011302)
feature 110 (0.010700)
feature 34 (0.010566)
feature 43 (0.010378)
feature 27 (0.010253)
feature 144 (0.010139)
feature 152 (0.009895)
feature 82 (0.009876)
feature 55 (0.009601)
feature 74 (0.009558)
inner fold=3
accuracy=0.6
feature 166 (0.029110)
feature 129 (0.025816)
feature 139 (0.023127)
feature 81 (0.019619)
feature 227 (0.018161)
feature 199 (0.018076)
feature 104 (0.017133)
feature 101 (0.017052)
feature 115 (0.016985)
feature 58 (0.016032)
feature 385 (0.015980)
feature 362 (0.015592)
feature 148 (0.015042)
feature 125 (0.014762)
feature 216 (0.014652)
feature 142 (0.014344)
feature 172 (0.013839)
feature 153 (0.013593)
feature 171 (0.013414)
feature 107 (0.012990)
feature 128 (0.012549)
feature 135 (0.011471)
feature 131 (0.011132)
feature 43 (0.011105)
feature 60 (0.011021)
feature 78 (0.010886)
feature 136 (0.010884)
feature 152 (0.010872)
feature 82 (0.010559)
feature 62 (0.010524)
inner fold=4
accuracy=0.666666666667
feature 109 (0.025232)
feature 110 (0.022832)
feature 24 (0.021374)
feature 174 (0.019203)
feature 171 (0.018691)
feature 114 (0.017928)
feature 167 (0.016474)
feature 172 (0.016072)
feature 385 (0.015626)
feature 129 (0.015037)
feature 227 (0.014941)
feature 358 (0.014894)
feature 294 (0.014639)
feature 39 (0.014563)
feature 340 (0.014047)
feature 56 (0.013996)
feature 122 (0.013989)
feature 272 (0.013712)
feature 148 (0.013669)
feature 77 (0.013451)
feature 52 (0.013359)
feature 151 (0.013068)
feature 5 (0.012297)
feature 213 (0.012203)
feature 142 (0.012121)
feature 408 (0.011888)
feature 12 (0.011860)
feature 126 (0.011212)
feature 145 (0.011077)
feature 104 (0.010872)
inner fold=0
accuracy=0.673913043478
feature 46 (0.029820)
feature 344 (0.028211)
feature 164 (0.027780)
feature 166 (0.027083)
feature 110 (0.025963)
feature 211 (0.025815)
feature 152 (0.025242)
feature 148 (0.025144)
feature 171 (0.019043)
feature 80 (0.018155)
feature 44 (0.017701)
feature 227 (0.017215)
feature 215 (0.017155)
feature 84 (0.015822)
feature 123 (0.015642)
feature 55 (0.014366)
feature 138 (0.013858)
feature 52 (0.013114)
feature 136 (0.012851)
feature 12 (0.012734)
feature 79 (0.012611)
feature 165 (0.011563)
feature 141 (0.011381)
feature 203 (0.011108)
feature 139 (0.011043)
feature 213 (0.010991)
feature 168 (0.010746)
feature 105 (0.010665)
feature 30 (0.010640)
feature 196 (0.009765)
inner fold=1
accuracy=0.695652173913
feature 294 (0.038423)
feature 81 (0.032811)
feature 53 (0.032778)
feature 231 (0.030283)
feature 227 (0.025969)
feature 4 (0.022207)
feature 173 (0.022030)
feature 100 (0.019495)
feature 42 (0.017356)
feature 155 (0.017300)
feature 56 (0.015923)
feature 166 (0.015475)
feature 203 (0.014897)
feature 71 (0.014831)
feature 385 (0.013647)
feature 110 (0.013604)
feature 209 (0.013066)
feature 138 (0.012846)
feature 213 (0.012764)
feature 172 (0.012469)
feature 142 (0.012337)
feature 82 (0.012027)
feature 171 (0.011723)
feature 165 (0.011640)
feature 184 (0.011304)
feature 54 (0.010440)
feature 454 (0.010396)
feature 362 (0.010114)
feature 164 (0.010010)
feature 24 (0.009923)
inner fold=2
accuracy=0.586956521739
feature 136 (0.030353)
feature 110 (0.028449)
feature 172 (0.027089)
feature 42 (0.022766)
feature 156 (0.019165)
feature 101 (0.016533)
feature 200 (0.016442)
feature 199 (0.016082)
feature 381 (0.016030)
feature 57 (0.015966)
feature 227 (0.015907)
feature 344 (0.015886)
feature 454 (0.015703)
feature 148 (0.015664)
feature 138 (0.014170)
feature 44 (0.013096)
feature 77 (0.013060)
feature 157 (0.012600)
feature 1 (0.012145)
feature 78 (0.012133)
feature 203 (0.012078)
feature 362 (0.012059)
feature 184 (0.011199)
feature 83 (0.010932)
feature 171 (0.010830)
feature 107 (0.010820)
feature 222 (0.010803)
feature 58 (0.010637)
feature 133 (0.010631)
feature 30 (0.010342)
inner fold=3
accuracy=0.488888888889
feature 110 (0.027528)
feature 294 (0.024526)
feature 152 (0.022749)
feature 235 (0.022499)
feature 227 (0.020692)
feature 202 (0.020190)
feature 109 (0.019544)
feature 126 (0.017415)
feature 213 (0.017035)
feature 3 (0.016721)
feature 171 (0.016714)
feature 48 (0.016652)
feature 136 (0.016586)
feature 381 (0.016360)
feature 80 (0.016270)
feature 102 (0.015855)
feature 14 (0.014463)
feature 145 (0.013336)
feature 52 (0.012792)
feature 43 (0.012487)
feature 24 (0.011987)
feature 21 (0.010920)
feature 175 (0.010859)
feature 1 (0.010687)
feature 81 (0.010314)
feature 30 (0.010175)
feature 168 (0.010118)
feature 5 (0.010029)
feature 340 (0.009910)
feature 166 (0.009885)
inner fold=4
accuracy=0.666666666667

lay_id=4
feature 344 (0.033688)
feature 294 (0.022643)
feature 138 (0.022567)
feature 173 (0.020646)
feature 390 (0.020354)
feature 42 (0.017561)
feature 136 (0.017440)
feature 235 (0.017261)
feature 181 (0.016165)
feature 184 (0.016023)
feature 46 (0.015782)
feature 166 (0.014982)
feature 227 (0.014967)
feature 81 (0.014323)
feature 123 (0.013491)
feature 5 (0.013084)
feature 85 (0.013038)
feature 95 (0.012912)
feature 385 (0.012791)
feature 63 (0.012626)
feature 211 (0.012434)
feature 122 (0.012322)
feature 126 (0.012290)
feature 56 (0.012039)
feature 55 (0.011973)
feature 381 (0.011714)
feature 52 (0.011573)
feature 201 (0.011561)
feature 153 (0.011540)
feature 79 (0.011520)
inner fold=0
accuracy=0.630434782609
feature 120 (0.032035)
feature 159 (0.032024)
feature 172 (0.027428)
feature 44 (0.021380)
feature 188 (0.020965)
feature 82 (0.019340)
feature 174 (0.017597)
feature 135 (0.017280)
feature 152 (0.015704)
feature 203 (0.015362)
feature 194 (0.015138)
feature 110 (0.013986)
feature 1 (0.013913)
feature 157 (0.013800)
feature 50 (0.013592)
feature 182 (0.012955)
feature 166 (0.012760)
feature 70 (0.012281)
feature 390 (0.011742)
feature 151 (0.011354)
feature 175 (0.011293)
feature 222 (0.011173)
feature 285 (0.011077)
feature 123 (0.011055)
feature 77 (0.010978)
feature 129 (0.010849)
feature 210 (0.010708)
feature 181 (0.010652)
feature 202 (0.010333)
feature 184 (0.010274)
inner fold=1
accuracy=0.608695652174
feature 174 (0.024836)
feature 57 (0.024298)
feature 105 (0.021555)
feature 81 (0.019947)
feature 2 (0.019610)
feature 200 (0.019247)
feature 168 (0.017977)
feature 203 (0.017571)
feature 134 (0.017037)
feature 56 (0.016868)
feature 155 (0.016782)
feature 152 (0.016620)
feature 167 (0.016023)
feature 110 (0.015263)
feature 54 (0.015079)
feature 153 (0.014950)
feature 156 (0.014012)
feature 172 (0.013907)
feature 109 (0.013886)
feature 97 (0.013425)
feature 46 (0.013238)
feature 173 (0.012604)
feature 294 (0.012481)
feature 344 (0.012393)
feature 24 (0.011948)
feature 131 (0.011925)
feature 55 (0.011554)
feature 188 (0.011506)
feature 62 (0.011475)
feature 36 (0.011215)
inner fold=2
accuracy=0.5
feature 46 (0.021374)
feature 4 (0.020930)
feature 344 (0.018418)
feature 201 (0.018223)
feature 6 (0.017280)
feature 166 (0.017268)
feature 139 (0.016695)
feature 148 (0.016544)
feature 174 (0.016232)
feature 126 (0.015075)
feature 52 (0.014730)
feature 78 (0.014641)
feature 172 (0.014614)
feature 130 (0.014091)
feature 125 (0.013665)
feature 62 (0.013349)
feature 173 (0.013296)
feature 105 (0.013086)
feature 175 (0.012897)
feature 103 (0.012871)
feature 171 (0.012786)
feature 44 (0.012498)
feature 140 (0.012009)
feature 157 (0.011889)
feature 73 (0.011836)
feature 209 (0.011532)
feature 56 (0.011435)
feature 122 (0.011358)
feature 138 (0.011275)
feature 152 (0.011131)
inner fold=3
accuracy=0.444444444444
feature 81 (0.033195)
feature 48 (0.024392)
feature 138 (0.023431)
feature 14 (0.020575)
feature 110 (0.018656)
feature 33 (0.018533)
feature 134 (0.017815)
feature 142 (0.017604)
feature 129 (0.017005)
feature 235 (0.016516)
feature 136 (0.016278)
feature 156 (0.015618)
feature 42 (0.015511)
feature 102 (0.015226)
feature 114 (0.015174)
feature 166 (0.014873)
feature 35 (0.014701)
feature 46 (0.014666)
feature 130 (0.013868)
feature 126 (0.013858)
feature 148 (0.013543)
feature 57 (0.012592)
feature 194 (0.011868)
feature 78 (0.011815)
feature 172 (0.011714)
feature 123 (0.011524)
feature 137 (0.011038)
feature 28 (0.011003)
feature 30 (0.010624)
feature 51 (0.010357)
inner fold=4
accuracy=0.644444444444
feature 171 (0.038942)
feature 138 (0.029350)
feature 381 (0.021098)
feature 29 (0.020662)
feature 159 (0.020363)
feature 54 (0.018020)
feature 44 (0.017823)
feature 153 (0.017430)
feature 120 (0.015756)
feature 127 (0.015283)
feature 125 (0.015224)
feature 81 (0.014908)
feature 213 (0.014577)
feature 12 (0.014039)
feature 78 (0.013875)
feature 4 (0.013083)
feature 58 (0.012952)
feature 203 (0.012793)
feature 155 (0.012532)
feature 148 (0.012284)
feature 222 (0.011613)
feature 151 (0.011548)
feature 100 (0.011341)
feature 14 (0.011189)
feature 214 (0.011183)
feature 207 (0.011141)
feature 57 (0.010863)
feature 55 (0.010564)
feature 27 (0.010100)
feature 167 (0.010047)
inner fold=0
accuracy=0.565217391304
feature 344 (0.036295)
feature 81 (0.025834)
feature 120 (0.025713)
feature 122 (0.024719)
feature 202 (0.023793)
feature 171 (0.023144)
feature 155 (0.022933)
feature 138 (0.021761)
feature 143 (0.018266)
feature 223 (0.017812)
feature 200 (0.017746)
feature 129 (0.017318)
feature 211 (0.017290)
feature 168 (0.017255)
feature 145 (0.016819)
feature 57 (0.016616)
feature 134 (0.016592)
feature 77 (0.016262)
feature 43 (0.015997)
feature 152 (0.015877)
feature 12 (0.015661)
feature 184 (0.014853)
feature 183 (0.014242)
feature 133 (0.012715)
feature 4 (0.012010)
feature 34 (0.011520)
feature 227 (0.011279)
feature 63 (0.011091)
feature 104 (0.009618)
feature 55 (0.009491)
inner fold=1
accuracy=0.478260869565
feature 166 (0.028438)
feature 171 (0.027733)
feature 34 (0.024126)
feature 123 (0.023519)
feature 156 (0.021325)
feature 213 (0.021238)
feature 114 (0.020698)
feature 110 (0.020326)
feature 43 (0.018576)
feature 165 (0.018353)
feature 231 (0.018240)
feature 129 (0.016350)
feature 208 (0.015822)
feature 174 (0.015820)
feature 3 (0.015408)
feature 70 (0.015289)
feature 120 (0.014648)
feature 334 (0.014316)
feature 107 (0.014114)
feature 81 (0.012862)
feature 82 (0.012755)
feature 58 (0.012424)
feature 294 (0.012374)
feature 62 (0.011795)
feature 139 (0.011337)
feature 362 (0.011222)
feature 60 (0.011032)
feature 33 (0.010914)
feature 162 (0.010821)
feature 2 (0.010644)
inner fold=2
accuracy=0.608695652174
feature 235 (0.029554)
feature 56 (0.022576)
feature 14 (0.022265)
feature 168 (0.020468)
feature 2 (0.019261)
feature 294 (0.018721)
feature 24 (0.018403)
feature 21 (0.017975)
feature 202 (0.017495)
feature 52 (0.017457)
feature 139 (0.017281)
feature 272 (0.016618)
feature 156 (0.015653)
feature 77 (0.015563)
feature 164 (0.015436)
feature 166 (0.015290)
feature 55 (0.015135)
feature 78 (0.014941)
feature 157 (0.014735)
feature 138 (0.014539)
feature 169 (0.013879)
feature 123 (0.013644)
feature 110 (0.013233)
feature 58 (0.013154)
feature 134 (0.012389)
feature 188 (0.011616)
feature 46 (0.011614)
feature 120 (0.011448)
feature 81 (0.011364)
feature 131 (0.011328)
inner fold=3
accuracy=0.711111111111
feature 136 (0.028282)
feature 153 (0.021481)
feature 53 (0.020599)
feature 38 (0.020446)
feature 135 (0.018814)
feature 172 (0.018514)
feature 207 (0.017729)
feature 70 (0.016778)
feature 340 (0.016512)
feature 110 (0.016396)
feature 14 (0.015854)
feature 168 (0.015819)
feature 222 (0.015391)
feature 148 (0.015350)
feature 50 (0.015267)
feature 167 (0.014571)
feature 123 (0.014526)
feature 43 (0.014220)
feature 231 (0.012920)
feature 62 (0.012265)
feature 261 (0.011217)
feature 3 (0.011177)
feature 115 (0.010970)
feature 121 (0.010817)
feature 127 (0.010798)
feature 33 (0.010707)
feature 44 (0.010639)
feature 157 (0.010565)
feature 235 (0.010500)
feature 134 (0.009870)
inner fold=4
accuracy=0.511111111111

lay_id=5
feature 42 (0.032370)
feature 158 (0.029153)
feature 120 (0.026018)
feature 227 (0.024605)
feature 4 (0.023843)
feature 34 (0.022734)
feature 159 (0.020924)
feature 235 (0.018613)
feature 362 (0.017517)
feature 115 (0.016585)
feature 344 (0.016392)
feature 231 (0.014927)
feature 44 (0.014663)
feature 157 (0.014614)
feature 135 (0.014475)
feature 171 (0.014192)
feature 18 (0.013931)
feature 182 (0.012464)
feature 58 (0.012216)
feature 77 (0.011972)
feature 103 (0.011943)
feature 152 (0.011898)
feature 272 (0.011639)
feature 188 (0.011515)
feature 79 (0.011272)
feature 85 (0.011239)
feature 165 (0.010801)
feature 62 (0.010683)
feature 80 (0.010537)
feature 166 (0.010438)
inner fold=0
accuracy=0.630434782609
feature 227 (0.065179)
feature 235 (0.027353)
feature 175 (0.026827)
feature 38 (0.025119)
feature 78 (0.020869)
feature 231 (0.018576)
feature 81 (0.018391)
feature 136 (0.017764)
feature 110 (0.016510)
feature 157 (0.016240)
feature 84 (0.015828)
feature 115 (0.015475)
feature 390 (0.015103)
feature 101 (0.014488)
feature 168 (0.013875)
feature 455 (0.013568)
feature 55 (0.013506)
feature 213 (0.013394)
feature 166 (0.012919)
feature 50 (0.012879)
feature 109 (0.012666)
feature 114 (0.012642)
feature 223 (0.012159)
feature 208 (0.011848)
feature 197 (0.011842)
feature 188 (0.011809)
feature 155 (0.011690)
feature 156 (0.011473)
feature 30 (0.011396)
feature 33 (0.011332)
inner fold=1
accuracy=0.54347826087
feature 155 (0.035851)
feature 34 (0.027574)
feature 107 (0.021875)
feature 171 (0.020718)
feature 110 (0.020407)
feature 14 (0.019369)
feature 235 (0.018535)
feature 30 (0.017566)
feature 130 (0.017374)
feature 77 (0.017331)
feature 70 (0.017092)
feature 129 (0.016954)
feature 163 (0.016918)
feature 123 (0.016735)
feature 102 (0.016398)
feature 381 (0.015469)
feature 172 (0.015429)
feature 272 (0.015414)
feature 175 (0.015302)
feature 157 (0.015254)
feature 137 (0.014657)
feature 166 (0.014126)
feature 4 (0.013588)
feature 53 (0.013572)
feature 135 (0.013017)
feature 216 (0.012855)
feature 18 (0.012800)
feature 136 (0.012765)
feature 55 (0.012434)
feature 115 (0.011724)
inner fold=2
accuracy=0.673913043478
feature 381 (0.032050)
feature 294 (0.026902)
feature 114 (0.022256)
feature 164 (0.021486)
feature 110 (0.020327)
feature 167 (0.017976)
feature 109 (0.017566)
feature 148 (0.015939)
feature 131 (0.015609)
feature 166 (0.015541)
feature 210 (0.014513)
feature 84 (0.014464)
feature 156 (0.014378)
feature 344 (0.013609)
feature 182 (0.013463)
feature 28 (0.013435)
feature 52 (0.012441)
feature 151 (0.012365)
feature 101 (0.011663)
feature 227 (0.011542)
feature 99 (0.011324)
feature 127 (0.011194)
feature 174 (0.011173)
feature 159 (0.010940)
feature 368 (0.010903)
feature 160 (0.010694)
feature 78 (0.010372)
feature 175 (0.010339)
feature 58 (0.010106)
feature 201 (0.009910)
inner fold=3
accuracy=0.577777777778
feature 84 (0.044166)
feature 188 (0.023234)
feature 55 (0.023040)
feature 213 (0.021337)
feature 68 (0.020659)
feature 300 (0.020121)
feature 184 (0.019824)
feature 168 (0.019727)
feature 123 (0.019453)
feature 30 (0.019378)
feature 235 (0.018913)
feature 127 (0.018767)
feature 129 (0.018731)
feature 0 (0.018534)
feature 182 (0.014900)
feature 227 (0.012913)
feature 362 (0.011872)
feature 169 (0.010818)
feature 141 (0.010685)
feature 171 (0.010292)
feature 294 (0.010292)
feature 45 (0.010223)
feature 53 (0.010206)
feature 139 (0.010100)
feature 155 (0.009961)
feature 12 (0.009948)
feature 138 (0.009902)
feature 172 (0.009844)
feature 79 (0.009568)
feature 143 (0.009377)
inner fold=4
accuracy=0.555555555556
feature 164 (0.024699)
feature 152 (0.024261)
feature 171 (0.023525)
feature 168 (0.019871)
feature 52 (0.019038)
feature 231 (0.018554)
feature 53 (0.017412)
feature 30 (0.017172)
feature 211 (0.016937)
feature 176 (0.015649)
feature 203 (0.015448)
feature 114 (0.015407)
feature 136 (0.014910)
feature 29 (0.014881)
feature 215 (0.014714)
feature 213 (0.014171)
feature 101 (0.013976)
feature 381 (0.013762)
feature 57 (0.013623)
feature 81 (0.013052)
feature 210 (0.012891)
feature 110 (0.012755)
feature 235 (0.012666)
feature 137 (0.012473)
feature 151 (0.012448)
feature 166 (0.012167)
feature 135 (0.012040)
feature 134 (0.011943)
feature 27 (0.011585)
feature 80 (0.011375)
inner fold=0
accuracy=0.739130434783
feature 136 (0.036750)
feature 203 (0.033510)
feature 171 (0.030839)
feature 42 (0.028419)
feature 38 (0.027164)
feature 173 (0.025679)
feature 56 (0.021775)
feature 294 (0.020009)
feature 12 (0.018399)
feature 156 (0.017690)
feature 215 (0.017436)
feature 184 (0.016526)
feature 344 (0.016387)
feature 130 (0.016374)
feature 50 (0.015095)
feature 57 (0.014958)
feature 53 (0.014327)
feature 123 (0.013469)
feature 188 (0.012812)
feature 3 (0.012417)
feature 197 (0.012340)
feature 235 (0.012216)
feature 106 (0.012178)
feature 18 (0.011896)
feature 109 (0.011729)
feature 209 (0.010706)
feature 174 (0.010489)
feature 214 (0.010407)
feature 196 (0.010002)
feature 464 (0.009889)
inner fold=1
accuracy=0.586956521739
feature 203 (0.046749)
feature 136 (0.033899)
feature 235 (0.023054)
feature 33 (0.021084)
feature 231 (0.019115)
feature 137 (0.018939)
feature 158 (0.018849)
feature 199 (0.018634)
feature 24 (0.018011)
feature 383 (0.017981)
feature 109 (0.017516)
feature 175 (0.016542)
feature 74 (0.015802)
feature 156 (0.015791)
feature 272 (0.014328)
feature 129 (0.014295)
feature 172 (0.014049)
feature 56 (0.013542)
feature 208 (0.013374)
feature 106 (0.013310)
feature 287 (0.012689)
feature 344 (0.011977)
feature 18 (0.011950)
feature 171 (0.011507)
feature 15 (0.010865)
feature 52 (0.010816)
feature 84 (0.010813)
feature 16 (0.010535)
feature 168 (0.010510)
feature 152 (0.009890)
inner fold=2
accuracy=0.521739130435
feature 110 (0.049269)
feature 136 (0.026218)
feature 114 (0.023660)
feature 294 (0.023456)
feature 84 (0.023136)
feature 157 (0.022438)
feature 107 (0.020134)
feature 156 (0.020096)
feature 164 (0.019856)
feature 142 (0.017846)
feature 44 (0.017058)
feature 18 (0.016535)
feature 155 (0.015717)
feature 138 (0.015390)
feature 137 (0.015347)
feature 166 (0.015034)
feature 208 (0.014356)
feature 29 (0.012373)
feature 122 (0.012140)
feature 58 (0.012054)
feature 135 (0.011931)
feature 175 (0.011865)
feature 55 (0.011843)
feature 12 (0.011685)
feature 63 (0.011423)
feature 129 (0.011309)
feature 77 (0.010711)
feature 51 (0.010181)
feature 216 (0.010155)
feature 213 (0.010127)
inner fold=3
accuracy=0.666666666667
feature 166 (0.028648)
feature 203 (0.026710)
feature 231 (0.022789)
feature 377 (0.021369)
feature 175 (0.018799)
feature 157 (0.018661)
feature 235 (0.018318)
feature 101 (0.017131)
feature 79 (0.016587)
feature 110 (0.016343)
feature 82 (0.016156)
feature 153 (0.015016)
feature 127 (0.014987)
feature 30 (0.014938)
feature 84 (0.014711)
feature 158 (0.014644)
feature 188 (0.013370)
feature 102 (0.013302)
feature 4 (0.013143)
feature 216 (0.012622)
feature 103 (0.012616)
feature 18 (0.011713)
feature 227 (0.011669)
feature 344 (0.011553)
feature 17 (0.011472)
feature 78 (0.011155)
feature 134 (0.011075)
feature 123 (0.010969)
feature 155 (0.010844)
feature 186 (0.010588)
inner fold=4
accuracy=0.577777777778

lay_id=6
feature 169 (0.024210)
feature 207 (0.019789)
feature 3 (0.019642)
feature 24 (0.019193)
feature 164 (0.018480)
feature 35 (0.017270)
feature 175 (0.017072)
feature 203 (0.015722)
feature 135 (0.015552)
feature 172 (0.015041)
feature 46 (0.015036)
feature 99 (0.015031)
feature 166 (0.014556)
feature 73 (0.014049)
feature 30 (0.014004)
feature 34 (0.013846)
feature 12 (0.013554)
feature 14 (0.013213)
feature 173 (0.013135)
feature 125 (0.013032)
feature 50 (0.012885)
feature 121 (0.012665)
feature 81 (0.012610)
feature 154 (0.012346)
feature 153 (0.012202)
feature 381 (0.012199)
feature 128 (0.012071)
feature 235 (0.011848)
feature 200 (0.011459)
feature 69 (0.011307)
inner fold=0
accuracy=0.54347826087
feature 174 (0.027646)
feature 208 (0.026256)
feature 164 (0.021147)
feature 123 (0.018119)
feature 34 (0.018038)
feature 159 (0.016666)
feature 80 (0.016509)
feature 156 (0.016234)
feature 169 (0.015993)
feature 142 (0.015746)
feature 145 (0.015527)
feature 122 (0.015411)
feature 30 (0.014921)
feature 58 (0.014539)
feature 132 (0.014486)
feature 138 (0.014224)
feature 294 (0.013750)
feature 75 (0.013494)
feature 52 (0.013160)
feature 182 (0.013047)
feature 62 (0.012552)
feature 344 (0.012375)
feature 184 (0.011846)
feature 109 (0.011813)
feature 100 (0.011732)
feature 207 (0.011687)
feature 381 (0.011675)
feature 57 (0.011516)
feature 234 (0.010837)
feature 358 (0.010833)
inner fold=1
accuracy=0.586956521739
feature 215 (0.027541)
feature 169 (0.023843)
feature 123 (0.022738)
feature 294 (0.022238)
feature 5 (0.020029)
feature 227 (0.019814)
feature 222 (0.019277)
feature 55 (0.018776)
feature 153 (0.017534)
feature 46 (0.016911)
feature 136 (0.016824)
feature 128 (0.016129)
feature 52 (0.015797)
feature 24 (0.015321)
feature 168 (0.014723)
feature 126 (0.014630)
feature 51 (0.014114)
feature 138 (0.013554)
feature 44 (0.013407)
feature 137 (0.013180)
feature 166 (0.012482)
feature 34 (0.012320)
feature 110 (0.011985)
feature 0 (0.011924)
feature 129 (0.011526)
feature 175 (0.011484)
feature 202 (0.010921)
feature 81 (0.010720)
feature 82 (0.010394)
feature 4 (0.010310)
inner fold=2
accuracy=0.521739130435
feature 344 (0.039495)
feature 174 (0.029535)
feature 171 (0.026652)
feature 110 (0.022100)
feature 231 (0.020552)
feature 138 (0.019074)
feature 203 (0.018767)
feature 102 (0.018344)
feature 129 (0.018218)
feature 155 (0.017874)
feature 272 (0.016874)
feature 114 (0.015307)
feature 14 (0.015228)
feature 157 (0.014918)
feature 188 (0.014228)
feature 294 (0.014060)
feature 152 (0.013202)
feature 136 (0.012987)
feature 208 (0.012554)
feature 201 (0.012391)
feature 3 (0.012125)
feature 53 (0.012109)
feature 173 (0.011839)
feature 79 (0.011837)
feature 125 (0.011021)
feature 29 (0.010648)
feature 167 (0.010367)
feature 77 (0.010284)
feature 172 (0.010283)
feature 130 (0.009495)
inner fold=3
accuracy=0.711111111111
feature 171 (0.025508)
feature 151 (0.024419)
feature 294 (0.022606)
feature 203 (0.022092)
feature 43 (0.020177)
feature 44 (0.019416)
feature 235 (0.019397)
feature 129 (0.018067)
feature 208 (0.017962)
feature 138 (0.016699)
feature 231 (0.016630)
feature 142 (0.015674)
feature 411 (0.014862)
feature 227 (0.014622)
feature 126 (0.014610)
feature 362 (0.013894)
feature 172 (0.013641)
feature 155 (0.013627)
feature 131 (0.013578)
feature 442 (0.013218)
feature 14 (0.012989)
feature 58 (0.012881)
feature 106 (0.012225)
feature 147 (0.012222)
feature 115 (0.011688)
feature 84 (0.011561)
feature 60 (0.011342)
feature 73 (0.010786)
feature 110 (0.010780)
feature 46 (0.010748)
inner fold=4
accuracy=0.6
feature 294 (0.049855)
feature 215 (0.037618)
feature 30 (0.021933)
feature 79 (0.020757)
feature 246 (0.018723)
feature 156 (0.018080)
feature 134 (0.017179)
feature 381 (0.016242)
feature 181 (0.015710)
feature 129 (0.015630)
feature 46 (0.015370)
feature 174 (0.015114)
feature 155 (0.014767)
feature 70 (0.014520)
feature 159 (0.014459)
feature 344 (0.013886)
feature 18 (0.013276)
feature 34 (0.012723)
feature 182 (0.012543)
feature 104 (0.012287)
feature 165 (0.011826)
feature 109 (0.011705)
feature 110 (0.011350)
feature 114 (0.011153)
feature 390 (0.010611)
feature 102 (0.010252)
feature 58 (0.009814)
feature 203 (0.009764)
feature 138 (0.009762)
feature 12 (0.009755)
inner fold=0
accuracy=0.586956521739
feature 294 (0.040658)
feature 72 (0.021904)
feature 123 (0.019509)
feature 192 (0.019251)
feature 134 (0.019134)
feature 110 (0.018755)
feature 210 (0.017866)
feature 44 (0.017613)
feature 57 (0.017554)
feature 30 (0.016688)
feature 48 (0.016431)
feature 180 (0.016354)
feature 37 (0.015731)
feature 129 (0.014169)
feature 126 (0.013407)
feature 152 (0.013165)
feature 156 (0.012318)
feature 43 (0.012213)
feature 104 (0.011665)
feature 46 (0.011369)
feature 78 (0.011285)
feature 209 (0.011274)
feature 283 (0.011230)
feature 55 (0.011228)
feature 130 (0.011200)
feature 135 (0.010993)
feature 158 (0.010843)
feature 97 (0.010728)
feature 193 (0.010290)
feature 234 (0.010249)
inner fold=1
accuracy=0.565217391304
feature 159 (0.028882)
feature 134 (0.027771)
feature 169 (0.022140)
feature 294 (0.021488)
feature 185 (0.021451)
feature 24 (0.021237)
feature 44 (0.019589)
feature 213 (0.019058)
feature 101 (0.017408)
feature 109 (0.017389)
feature 14 (0.016932)
feature 81 (0.016673)
feature 148 (0.016564)
feature 151 (0.016362)
feature 142 (0.016172)
feature 127 (0.015983)
feature 18 (0.014505)
feature 138 (0.013736)
feature 137 (0.013677)
feature 211 (0.013661)
feature 135 (0.012945)
feature 83 (0.012860)
feature 122 (0.012838)
feature 123 (0.012325)
feature 184 (0.012181)
feature 34 (0.011891)
feature 173 (0.011881)
feature 110 (0.011454)
feature 165 (0.011240)
feature 107 (0.011216)
inner fold=2
accuracy=0.586956521739
feature 203 (0.029570)
feature 209 (0.026541)
feature 142 (0.026513)
feature 159 (0.022977)
feature 166 (0.022860)
feature 4 (0.019889)
feature 43 (0.017866)
feature 385 (0.017558)
feature 141 (0.015982)
feature 101 (0.014809)
feature 294 (0.014739)
feature 79 (0.014494)
feature 227 (0.014175)
feature 57 (0.014157)
feature 128 (0.013962)
feature 139 (0.013814)
feature 153 (0.013360)
feature 152 (0.012569)
feature 82 (0.012104)
feature 194 (0.011830)
feature 136 (0.011487)
feature 120 (0.011418)
feature 81 (0.010766)
feature 104 (0.010712)
feature 202 (0.010664)
feature 170 (0.010379)
feature 134 (0.010339)
feature 1 (0.010283)
feature 390 (0.010110)
feature 46 (0.010043)
inner fold=3
accuracy=0.622222222222
feature 294 (0.050381)
feature 202 (0.027485)
feature 166 (0.027373)
feature 101 (0.027181)
feature 58 (0.022819)
feature 129 (0.020265)
feature 171 (0.016237)
feature 147 (0.015123)
feature 344 (0.014865)
feature 158 (0.014602)
feature 184 (0.014459)
feature 210 (0.013650)
feature 272 (0.013300)
feature 14 (0.013272)
feature 103 (0.013115)
feature 54 (0.011910)
feature 38 (0.011579)
feature 231 (0.011486)
feature 56 (0.011410)
feature 163 (0.011384)
feature 222 (0.011184)
feature 336 (0.010748)
feature 83 (0.010489)
feature 42 (0.010122)
feature 84 (0.009845)
feature 13 (0.009765)
feature 44 (0.009631)
feature 164 (0.009590)
feature 33 (0.009246)
feature 203 (0.009148)
inner fold=4
accuracy=0.6

lay_id=7
feature 81 (0.035923)
feature 171 (0.027812)
feature 137 (0.025941)
feature 134 (0.025758)
feature 110 (0.022062)
feature 383 (0.021990)
feature 34 (0.021427)
feature 231 (0.020019)
feature 294 (0.019897)
feature 129 (0.019233)
feature 152 (0.017354)
feature 128 (0.017090)
feature 58 (0.016512)
feature 46 (0.014913)
feature 120 (0.014775)
feature 208 (0.013807)
feature 126 (0.013517)
feature 106 (0.013494)
feature 215 (0.012893)
feature 35 (0.012598)
feature 153 (0.012399)
feature 138 (0.012242)
feature 385 (0.011945)
feature 139 (0.011818)
feature 141 (0.011766)
feature 165 (0.011405)
feature 101 (0.011241)
feature 166 (0.010905)
feature 188 (0.010890)
feature 18 (0.010811)
inner fold=0
accuracy=0.586956521739
feature 172 (0.031706)
feature 168 (0.026841)
feature 202 (0.023797)
feature 139 (0.020221)
feature 381 (0.020134)
feature 100 (0.017523)
feature 62 (0.016421)
feature 235 (0.016364)
feature 78 (0.015390)
feature 167 (0.015213)
feature 223 (0.014569)
feature 174 (0.014338)
feature 207 (0.014313)
feature 63 (0.013948)
feature 157 (0.013730)
feature 129 (0.013574)
feature 109 (0.013484)
feature 183 (0.012975)
feature 53 (0.012955)
feature 171 (0.012326)
feature 79 (0.012297)
feature 81 (0.012286)
feature 44 (0.012200)
feature 15 (0.011679)
feature 70 (0.011347)
feature 203 (0.011175)
feature 209 (0.011044)
feature 126 (0.010970)
feature 29 (0.010432)
feature 294 (0.010395)
inner fold=1
accuracy=0.652173913043
feature 156 (0.031224)
feature 129 (0.028608)
feature 46 (0.028600)
feature 110 (0.027866)
feature 201 (0.025118)
feature 294 (0.024626)
feature 142 (0.024260)
feature 227 (0.023882)
feature 172 (0.023079)
feature 157 (0.019439)
feature 80 (0.019160)
feature 155 (0.015732)
feature 139 (0.015456)
feature 62 (0.015206)
feature 193 (0.015070)
feature 135 (0.014476)
feature 454 (0.014326)
feature 166 (0.013730)
feature 209 (0.013410)
feature 381 (0.013242)
feature 34 (0.013234)
feature 53 (0.013033)
feature 108 (0.012707)
feature 148 (0.012360)
feature 14 (0.011787)
feature 165 (0.011558)
feature 174 (0.010932)
feature 120 (0.010793)
feature 100 (0.010305)
feature 344 (0.010304)
inner fold=2
accuracy=0.652173913043
feature 55 (0.029302)
feature 209 (0.022574)
feature 97 (0.020454)
feature 174 (0.019832)
feature 129 (0.018632)
feature 62 (0.017773)
feature 294 (0.017384)
feature 200 (0.017103)
feature 78 (0.017004)
feature 166 (0.016611)
feature 171 (0.016115)
feature 69 (0.015792)
feature 52 (0.015329)
feature 152 (0.015208)
feature 137 (0.014680)
feature 14 (0.014474)
feature 143 (0.014442)
feature 99 (0.014404)
feature 5 (0.014373)
feature 207 (0.014185)
feature 57 (0.013428)
feature 202 (0.013061)
feature 172 (0.012941)
feature 383 (0.012813)
feature 79 (0.012760)
feature 155 (0.012579)
feature 336 (0.011840)
feature 110 (0.011723)
feature 60 (0.011463)
feature 184 (0.010999)
inner fold=3
accuracy=0.555555555556
feature 168 (0.035303)
feature 171 (0.030684)
feature 235 (0.022452)
feature 137 (0.022099)
feature 211 (0.020251)
feature 40 (0.019887)
feature 34 (0.019553)
feature 142 (0.018083)
feature 227 (0.017849)
feature 128 (0.016834)
feature 35 (0.015484)
feature 183 (0.015259)
feature 110 (0.014659)
feature 381 (0.014455)
feature 121 (0.014293)
feature 344 (0.014038)
feature 127 (0.013786)
feature 362 (0.013633)
feature 81 (0.013220)
feature 159 (0.013005)
feature 55 (0.012378)
feature 14 (0.012255)
feature 58 (0.012009)
feature 209 (0.011839)
feature 156 (0.011795)
feature 73 (0.011559)
feature 120 (0.010822)
feature 33 (0.010679)
feature 5 (0.010345)
feature 210 (0.010268)
inner fold=4
accuracy=0.666666666667
feature 136 (0.027755)
feature 126 (0.027347)
feature 129 (0.021990)
feature 203 (0.020885)
feature 181 (0.019619)
feature 175 (0.019125)
feature 123 (0.018636)
feature 235 (0.017181)
feature 231 (0.016105)
feature 227 (0.015854)
feature 57 (0.015655)
feature 172 (0.015406)
feature 104 (0.015335)
feature 156 (0.014563)
feature 202 (0.014145)
feature 294 (0.013972)
feature 168 (0.013945)
feature 50 (0.013857)
feature 142 (0.013563)
feature 84 (0.013448)
feature 171 (0.013188)
feature 336 (0.013056)
feature 56 (0.012993)
feature 135 (0.011970)
feature 210 (0.011941)
feature 166 (0.011935)
feature 207 (0.011935)
feature 109 (0.011873)
feature 52 (0.011448)
feature 42 (0.011003)
inner fold=0
accuracy=0.586956521739
feature 51 (0.029918)
feature 174 (0.029124)
feature 78 (0.024306)
feature 109 (0.024160)
feature 130 (0.023588)
feature 50 (0.021430)
feature 153 (0.018649)
feature 101 (0.018483)
feature 34 (0.018296)
feature 126 (0.018001)
feature 156 (0.017904)
feature 44 (0.017500)
feature 97 (0.016733)
feature 227 (0.016236)
feature 163 (0.016194)
feature 102 (0.015847)
feature 285 (0.014309)
feature 136 (0.013201)
feature 84 (0.012552)
feature 214 (0.012427)
feature 70 (0.012401)
feature 3 (0.012170)
feature 234 (0.012089)
feature 30 (0.011603)
feature 148 (0.010926)
feature 4 (0.010700)
feature 172 (0.010594)
feature 160 (0.010592)
feature 104 (0.010281)
feature 183 (0.010233)
inner fold=1
accuracy=0.673913043478
feature 166 (0.041970)
feature 294 (0.023035)
feature 129 (0.020210)
feature 169 (0.019111)
feature 122 (0.017484)
feature 82 (0.016442)
feature 101 (0.016337)
feature 110 (0.016274)
feature 148 (0.016052)
feature 135 (0.015940)
feature 48 (0.015390)
feature 214 (0.014986)
feature 202 (0.014841)
feature 168 (0.014456)
feature 115 (0.014415)
feature 182 (0.013576)
feature 159 (0.013254)
feature 97 (0.012946)
feature 102 (0.012496)
feature 165 (0.012439)
feature 381 (0.012362)
feature 156 (0.012169)
feature 183 (0.011976)
feature 362 (0.011967)
feature 231 (0.011904)
feature 188 (0.011785)
feature 213 (0.011556)
feature 123 (0.011528)
feature 155 (0.011056)
feature 139 (0.010683)
inner fold=2
accuracy=0.521739130435
feature 449 (0.031667)
feature 294 (0.028323)
feature 101 (0.027210)
feature 139 (0.023791)
feature 235 (0.021113)
feature 73 (0.020996)
feature 131 (0.019488)
feature 231 (0.019390)
feature 165 (0.017951)
feature 44 (0.016138)
feature 172 (0.014276)
feature 115 (0.014148)
feature 142 (0.014082)
feature 109 (0.013687)
feature 100 (0.012778)
feature 151 (0.012038)
feature 158 (0.011691)
feature 28 (0.011619)
feature 103 (0.011575)
feature 200 (0.011555)
feature 377 (0.011543)
feature 171 (0.011506)
feature 34 (0.011126)
feature 138 (0.011125)
feature 47 (0.010946)
feature 159 (0.010602)
feature 55 (0.010256)
feature 97 (0.010086)
feature 125 (0.009822)
feature 60 (0.009743)
inner fold=3
accuracy=0.6
feature 137 (0.023144)
feature 227 (0.022768)
feature 294 (0.022555)
feature 174 (0.022215)
feature 145 (0.019985)
feature 69 (0.017551)
feature 166 (0.016668)
feature 172 (0.016221)
feature 81 (0.015353)
feature 125 (0.015208)
feature 123 (0.015170)
feature 62 (0.014987)
feature 247 (0.014191)
feature 44 (0.013520)
feature 85 (0.012905)
feature 122 (0.012807)
feature 110 (0.012246)
feature 77 (0.012187)
feature 156 (0.012154)
feature 78 (0.012095)
feature 43 (0.011922)
feature 24 (0.011851)
feature 213 (0.011832)
feature 219 (0.011387)
feature 208 (0.011256)
feature 46 (0.011102)
feature 148 (0.011065)
feature 235 (0.010733)
feature 51 (0.010711)
feature 41 (0.010647)
inner fold=4
accuracy=0.688888888889

lay_id=8
feature 175 (0.023398)
feature 60 (0.023398)
feature 46 (0.019887)
feature 272 (0.017943)
feature 349 (0.016433)
feature 156 (0.016254)
feature 30 (0.015812)
feature 168 (0.015742)
feature 97 (0.015700)
feature 62 (0.015304)
feature 84 (0.015084)
feature 17 (0.014410)
feature 102 (0.014385)
feature 138 (0.014185)
feature 57 (0.014165)
feature 137 (0.013390)
feature 377 (0.013066)
feature 129 (0.012976)
feature 171 (0.012868)
feature 70 (0.011931)
feature 44 (0.011794)
feature 127 (0.011713)
feature 184 (0.011526)
feature 101 (0.011367)
feature 4 (0.011335)
feature 13 (0.011290)
feature 78 (0.011269)
feature 5 (0.011129)
feature 174 (0.010981)
feature 181 (0.010752)
inner fold=0
accuracy=0.5
feature 12 (0.028452)
feature 235 (0.026150)
feature 109 (0.023631)
feature 210 (0.023227)
feature 171 (0.022471)
feature 215 (0.018792)
feature 101 (0.017606)
feature 24 (0.017291)
feature 128 (0.016264)
feature 57 (0.016193)
feature 184 (0.015731)
feature 77 (0.015367)
feature 152 (0.015104)
feature 344 (0.015093)
feature 222 (0.015029)
feature 136 (0.014733)
feature 130 (0.014556)
feature 123 (0.014183)
feature 202 (0.013129)
feature 163 (0.012719)
feature 62 (0.012503)
feature 56 (0.012340)
feature 120 (0.012289)
feature 2 (0.011951)
feature 249 (0.011783)
feature 362 (0.011604)
feature 63 (0.011225)
feature 157 (0.011071)
feature 223 (0.010226)
feature 135 (0.009949)
inner fold=1
accuracy=0.630434782609
feature 129 (0.025820)
feature 57 (0.025721)
feature 209 (0.022692)
feature 109 (0.021270)
feature 34 (0.019352)
feature 135 (0.019192)
feature 3 (0.017964)
feature 171 (0.017838)
feature 294 (0.016785)
feature 14 (0.015708)
feature 38 (0.015589)
feature 193 (0.014470)
feature 126 (0.014350)
feature 110 (0.014279)
feature 174 (0.014166)
feature 168 (0.014057)
feature 60 (0.013472)
feature 175 (0.013139)
feature 30 (0.013094)
feature 272 (0.012714)
feature 120 (0.012180)
feature 131 (0.012100)
feature 81 (0.011961)
feature 21 (0.011931)
feature 211 (0.011855)
feature 203 (0.011707)
feature 107 (0.011533)
feature 52 (0.010762)
feature 137 (0.010599)
feature 125 (0.010418)
inner fold=2
accuracy=0.608695652174
feature 101 (0.026459)
feature 81 (0.025857)
feature 110 (0.024824)
feature 107 (0.023171)
feature 2 (0.022858)
feature 153 (0.019412)
feature 46 (0.015364)
feature 70 (0.015274)
feature 173 (0.014603)
feature 168 (0.014433)
feature 151 (0.014328)
feature 122 (0.013661)
feature 235 (0.013581)
feature 227 (0.013196)
feature 33 (0.013046)
feature 85 (0.012911)
feature 30 (0.012453)
feature 156 (0.012440)
feature 3 (0.012392)
feature 90 (0.012350)
feature 60 (0.012174)
feature 58 (0.012117)
feature 157 (0.012041)
feature 83 (0.011888)
feature 172 (0.011833)
feature 202 (0.011802)
feature 385 (0.011653)
feature 142 (0.011618)
feature 223 (0.011107)
feature 164 (0.010846)
inner fold=3
accuracy=0.622222222222
feature 50 (0.030188)
feature 171 (0.023479)
feature 110 (0.022961)
feature 143 (0.022145)
feature 182 (0.021547)
feature 231 (0.021457)
feature 81 (0.020775)
feature 164 (0.020019)
feature 84 (0.016887)
feature 188 (0.016424)
feature 168 (0.016383)
feature 137 (0.015660)
feature 133 (0.015480)
feature 77 (0.015133)
feature 175 (0.014244)
feature 215 (0.014046)
feature 153 (0.013635)
feature 235 (0.013635)
feature 174 (0.013603)
feature 213 (0.013385)
feature 163 (0.013222)
feature 159 (0.012641)
feature 78 (0.012271)
feature 210 (0.011944)
feature 115 (0.011881)
feature 454 (0.011503)
feature 227 (0.011020)
feature 34 (0.010918)
feature 156 (0.010853)
feature 79 (0.010834)
inner fold=4
accuracy=0.711111111111
feature 188 (0.029575)
feature 172 (0.026206)
feature 175 (0.021341)
feature 213 (0.018746)
feature 79 (0.018690)
feature 84 (0.018608)
feature 38 (0.017248)
feature 207 (0.016759)
feature 464 (0.016470)
feature 107 (0.016108)
feature 64 (0.015943)
feature 155 (0.015800)
feature 203 (0.015441)
feature 157 (0.015247)
feature 166 (0.014881)
feature 133 (0.013950)
feature 275 (0.013715)
feature 42 (0.013089)
feature 14 (0.012888)
feature 110 (0.012880)
feature 159 (0.012795)
feature 129 (0.012695)
feature 123 (0.012519)
feature 136 (0.012158)
feature 12 (0.011978)
feature 80 (0.011790)
feature 227 (0.011421)
feature 16 (0.011365)
feature 29 (0.011354)
feature 137 (0.010026)
inner fold=0
accuracy=0.717391304348
feature 81 (0.035781)
feature 80 (0.031428)
feature 202 (0.028513)
feature 77 (0.025763)
feature 30 (0.024658)
feature 70 (0.023214)
feature 135 (0.021212)
feature 114 (0.020106)
feature 155 (0.019656)
feature 344 (0.018444)
feature 174 (0.018375)
feature 275 (0.016633)
feature 136 (0.016401)
feature 171 (0.013848)
feature 158 (0.013722)
feature 123 (0.012789)
feature 215 (0.012761)
feature 34 (0.012621)
feature 29 (0.011893)
feature 151 (0.011667)
feature 227 (0.011647)
feature 104 (0.011539)
feature 148 (0.011521)
feature 141 (0.011343)
feature 214 (0.011197)
feature 56 (0.010860)
feature 82 (0.010737)
feature 63 (0.010620)
feature 159 (0.010163)
feature 53 (0.010111)
inner fold=1
accuracy=0.586956521739
feature 168 (0.030462)
feature 14 (0.026298)
feature 46 (0.025493)
feature 164 (0.020453)
feature 227 (0.019190)
feature 38 (0.018862)
feature 43 (0.018710)
feature 231 (0.017678)
feature 139 (0.017644)
feature 12 (0.017600)
feature 184 (0.016504)
feature 172 (0.016075)
feature 5 (0.015895)
feature 215 (0.014961)
feature 44 (0.014929)
feature 28 (0.014697)
feature 151 (0.014482)
feature 50 (0.014228)
feature 138 (0.014069)
feature 464 (0.013189)
feature 19 (0.012848)
feature 78 (0.012833)
feature 156 (0.012780)
feature 381 (0.012174)
feature 159 (0.011938)
feature 411 (0.011786)
feature 148 (0.011691)
feature 77 (0.011493)
feature 344 (0.011041)
feature 99 (0.010218)
inner fold=2
accuracy=0.652173913043
feature 227 (0.059908)
feature 171 (0.043026)
feature 294 (0.033320)
feature 168 (0.023614)
feature 172 (0.022047)
feature 130 (0.016491)
feature 127 (0.016271)
feature 128 (0.015736)
feature 56 (0.015627)
feature 385 (0.015441)
feature 166 (0.015331)
feature 203 (0.013633)
feature 50 (0.013076)
feature 383 (0.012412)
feature 138 (0.012309)
feature 145 (0.012290)
feature 213 (0.012130)
feature 42 (0.012048)
feature 1 (0.012027)
feature 362 (0.011928)
feature 84 (0.011816)
feature 123 (0.011671)
feature 14 (0.011668)
feature 40 (0.011456)
feature 344 (0.010847)
feature 29 (0.010494)
feature 152 (0.010392)
feature 102 (0.010037)
feature 101 (0.010019)
feature 148 (0.009925)
inner fold=3
accuracy=0.622222222222
feature 227 (0.034519)
feature 336 (0.028780)
feature 14 (0.024469)
feature 129 (0.023878)
feature 123 (0.022649)
feature 46 (0.022472)
feature 142 (0.022376)
feature 136 (0.021904)
feature 34 (0.021528)
feature 58 (0.018238)
feature 114 (0.016585)
feature 203 (0.015978)
feature 213 (0.015658)
feature 3 (0.014158)
feature 12 (0.014058)
feature 109 (0.013687)
feature 107 (0.013408)
feature 85 (0.013374)
feature 166 (0.013119)
feature 171 (0.013100)
feature 79 (0.012772)
feature 80 (0.012537)
feature 51 (0.012453)
feature 101 (0.012031)
feature 8 (0.012007)
feature 202 (0.011964)
feature 63 (0.011733)
feature 143 (0.011602)
feature 77 (0.011383)
feature 156 (0.011306)
inner fold=4
accuracy=0.511111111111

lay_id=9
feature 142 (0.026070)
feature 56 (0.024027)
feature 18 (0.023616)
feature 136 (0.023074)
feature 129 (0.022892)
feature 43 (0.022678)
feature 167 (0.019967)
feature 174 (0.019722)
feature 81 (0.019306)
feature 235 (0.017790)
feature 122 (0.015277)
feature 175 (0.015158)
feature 155 (0.014518)
feature 156 (0.014284)
feature 184 (0.013990)
feature 152 (0.013417)
feature 40 (0.013374)
feature 126 (0.012918)
feature 77 (0.012865)
feature 100 (0.012668)
feature 106 (0.012259)
feature 21 (0.012218)
feature 385 (0.012164)
feature 4 (0.011612)
feature 349 (0.011528)
feature 153 (0.011299)
feature 159 (0.010835)
feature 39 (0.010736)
feature 172 (0.010637)
feature 168 (0.010483)
inner fold=0
accuracy=0.565217391304
feature 102 (0.030046)
feature 120 (0.024670)
feature 199 (0.023901)
feature 175 (0.022643)
feature 14 (0.020989)
feature 192 (0.020296)
feature 157 (0.019548)
feature 139 (0.018595)
feature 52 (0.017178)
feature 73 (0.016348)
feature 227 (0.014673)
feature 340 (0.014240)
feature 165 (0.014181)
feature 211 (0.013940)
feature 81 (0.013421)
feature 77 (0.013044)
feature 168 (0.012872)
feature 127 (0.012008)
feature 137 (0.011812)
feature 385 (0.011793)
feature 128 (0.011231)
feature 381 (0.011123)
feature 155 (0.010717)
feature 390 (0.010679)
feature 51 (0.010346)
feature 208 (0.010227)
feature 152 (0.009980)
feature 171 (0.009969)
feature 136 (0.009671)
feature 214 (0.009630)
inner fold=1
accuracy=0.608695652174
feature 168 (0.031658)
feature 131 (0.022139)
feature 231 (0.021818)
feature 134 (0.021591)
feature 362 (0.019703)
feature 58 (0.019646)
feature 110 (0.019636)
feature 159 (0.019561)
feature 166 (0.018270)
feature 142 (0.017522)
feature 33 (0.017328)
feature 83 (0.017022)
feature 222 (0.016440)
feature 208 (0.015946)
feature 16 (0.015610)
feature 138 (0.015120)
feature 128 (0.014889)
feature 53 (0.014364)
feature 105 (0.013753)
feature 344 (0.013375)
feature 24 (0.013302)
feature 137 (0.013253)
feature 126 (0.012821)
feature 80 (0.012119)
feature 235 (0.011917)
feature 381 (0.011076)
feature 101 (0.010975)
feature 136 (0.010501)
feature 139 (0.010156)
feature 442 (0.009995)
inner fold=2
accuracy=0.586956521739
feature 166 (0.029642)
feature 57 (0.024557)
feature 33 (0.022452)
feature 138 (0.021391)
feature 30 (0.020315)
feature 129 (0.019507)
feature 171 (0.018870)
feature 125 (0.018054)
feature 38 (0.017709)
feature 172 (0.016033)
feature 235 (0.015473)
feature 143 (0.014320)
feature 464 (0.014016)
feature 156 (0.013202)
feature 40 (0.013115)
feature 29 (0.013108)
feature 141 (0.013086)
feature 227 (0.012997)
feature 110 (0.012842)
feature 234 (0.012655)
feature 155 (0.012616)
feature 84 (0.012616)
feature 159 (0.011847)
feature 139 (0.011370)
feature 131 (0.011321)
feature 36 (0.011223)
feature 82 (0.011095)
feature 209 (0.011093)
feature 114 (0.010885)
feature 71 (0.010459)
inner fold=3
accuracy=0.688888888889
feature 383 (0.023974)
feature 14 (0.023173)
feature 203 (0.021924)
feature 99 (0.021459)
feature 222 (0.020343)
feature 109 (0.019222)
feature 174 (0.018891)
feature 134 (0.018699)
feature 129 (0.018571)
feature 172 (0.018549)
feature 52 (0.018356)
feature 294 (0.018283)
feature 12 (0.016883)
feature 34 (0.016639)
feature 156 (0.016521)
feature 171 (0.015797)
feature 183 (0.015620)
feature 125 (0.014530)
feature 168 (0.014321)
feature 175 (0.014249)
feature 30 (0.013973)
feature 231 (0.013589)
feature 208 (0.013251)
feature 137 (0.013161)
feature 381 (0.012791)
feature 202 (0.012498)
feature 114 (0.012173)
feature 131 (0.010990)
feature 33 (0.010898)
feature 135 (0.010827)
inner fold=4
accuracy=0.533333333333
feature 231 (0.032511)
feature 344 (0.027430)
feature 171 (0.021787)
feature 188 (0.021683)
feature 109 (0.019780)
feature 129 (0.019555)
feature 77 (0.018938)
feature 152 (0.017753)
feature 135 (0.017578)
feature 208 (0.017334)
feature 40 (0.017042)
feature 222 (0.016542)
feature 174 (0.015701)
feature 172 (0.013748)
feature 131 (0.013682)
feature 214 (0.013354)
feature 130 (0.013346)
feature 148 (0.013261)
feature 182 (0.013171)
feature 34 (0.013089)
feature 164 (0.012810)
feature 107 (0.012789)
feature 209 (0.012782)
feature 272 (0.012590)
feature 294 (0.012563)
feature 104 (0.012507)
feature 29 (0.012379)
feature 110 (0.012341)
feature 163 (0.012328)
feature 84 (0.011416)
inner fold=0
accuracy=0.586956521739
feature 157 (0.021580)
feature 102 (0.018810)
feature 138 (0.018675)
feature 231 (0.018144)
feature 78 (0.017833)
feature 200 (0.017431)
feature 131 (0.017107)
feature 81 (0.017052)
feature 33 (0.016832)
feature 156 (0.016583)
feature 108 (0.015461)
feature 344 (0.015399)
feature 283 (0.014643)
feature 44 (0.014233)
feature 194 (0.013707)
feature 144 (0.013675)
feature 152 (0.013132)
feature 184 (0.012288)
feature 135 (0.012032)
feature 142 (0.011840)
feature 97 (0.011810)
feature 171 (0.011500)
feature 412 (0.010547)
feature 188 (0.010353)
feature 172 (0.010182)
feature 207 (0.010004)
feature 227 (0.009923)
feature 163 (0.009848)
feature 148 (0.009590)
feature 123 (0.009507)
inner fold=1
accuracy=0.608695652174
feature 171 (0.025548)
feature 40 (0.025540)
feature 164 (0.022862)
feature 73 (0.019907)
feature 12 (0.018501)
feature 100 (0.018096)
feature 285 (0.018070)
feature 129 (0.017780)
feature 81 (0.017227)
feature 62 (0.015518)
feature 134 (0.015436)
feature 107 (0.015247)
feature 156 (0.014254)
feature 135 (0.014193)
feature 79 (0.014126)
feature 210 (0.013816)
feature 122 (0.013384)
feature 120 (0.013214)
feature 30 (0.012984)
feature 110 (0.012974)
feature 28 (0.012779)
feature 29 (0.012485)
feature 115 (0.011402)
feature 177 (0.011134)
feature 294 (0.010460)
feature 213 (0.010110)
feature 77 (0.009901)
feature 60 (0.009875)
feature 165 (0.009776)
feature 146 (0.009693)
inner fold=2
accuracy=0.521739130435
feature 171 (0.032056)
feature 46 (0.028525)
feature 12 (0.024874)
feature 207 (0.024797)
feature 30 (0.021792)
feature 44 (0.020814)
feature 40 (0.020522)
feature 294 (0.020289)
feature 344 (0.019088)
feature 172 (0.017590)
feature 78 (0.016446)
feature 231 (0.016327)
feature 211 (0.016001)
feature 29 (0.015832)
feature 126 (0.013699)
feature 152 (0.013592)
feature 56 (0.013263)
feature 57 (0.012796)
feature 22 (0.012460)
feature 197 (0.012407)
feature 1 (0.012234)
feature 5 (0.012039)
feature 159 (0.011957)
feature 213 (0.011890)
feature 101 (0.011150)
feature 107 (0.011127)
feature 173 (0.011062)
feature 81 (0.010778)
feature 38 (0.010497)
feature 157 (0.010319)
inner fold=3
accuracy=0.622222222222
feature 126 (0.030055)
feature 159 (0.025345)
feature 381 (0.021745)
feature 137 (0.021660)
feature 134 (0.021302)
feature 216 (0.020271)
feature 44 (0.019813)
feature 294 (0.019348)
feature 38 (0.016797)
feature 78 (0.016446)
feature 77 (0.016409)
feature 14 (0.016064)
feature 211 (0.015424)
feature 231 (0.015088)
feature 5 (0.014660)
feature 127 (0.014083)
feature 157 (0.013666)
feature 201 (0.013632)
feature 161 (0.012941)
feature 21 (0.012538)
feature 155 (0.012232)
feature 34 (0.012003)
feature 36 (0.011995)
feature 52 (0.011784)
feature 175 (0.011637)
feature 227 (0.011579)
feature 131 (0.011504)
feature 123 (0.011250)
feature 165 (0.011144)
feature 192 (0.010877)
inner fold=4
accuracy=0.6

lay_id=10
feature 53 (0.034883)
feature 200 (0.027743)
feature 54 (0.023821)
feature 81 (0.023265)
feature 55 (0.022340)
feature 78 (0.020521)
feature 209 (0.018055)
feature 294 (0.017124)
feature 202 (0.016157)
feature 138 (0.015630)
feature 174 (0.015272)
feature 227 (0.014659)
feature 127 (0.014474)
feature 120 (0.014344)
feature 73 (0.013399)
feature 34 (0.013200)
feature 129 (0.013171)
feature 166 (0.012816)
feature 173 (0.012109)
feature 107 (0.011897)
feature 165 (0.010876)
feature 37 (0.010744)
feature 5 (0.010738)
feature 208 (0.010635)
feature 48 (0.010199)
feature 158 (0.009922)
feature 14 (0.009898)
feature 77 (0.009890)
feature 135 (0.009636)
feature 231 (0.009254)
inner fold=0
accuracy=0.608695652174
feature 44 (0.042334)
feature 81 (0.029335)
feature 171 (0.024977)
feature 138 (0.020403)
feature 120 (0.020278)
feature 51 (0.020158)
feature 174 (0.019340)
feature 130 (0.019333)
feature 152 (0.016868)
feature 139 (0.016039)
feature 383 (0.015463)
feature 175 (0.015194)
feature 142 (0.015191)
feature 109 (0.015049)
feature 157 (0.014776)
feature 30 (0.014601)
feature 50 (0.014329)
feature 294 (0.014186)
feature 55 (0.014172)
feature 200 (0.014157)
feature 213 (0.014143)
feature 125 (0.013962)
feature 272 (0.012729)
feature 167 (0.011951)
feature 45 (0.011618)
feature 155 (0.011511)
feature 104 (0.011223)
feature 57 (0.011157)
feature 211 (0.010928)
feature 110 (0.010906)
inner fold=1
accuracy=0.673913043478
feature 136 (0.023644)
feature 53 (0.022603)
feature 209 (0.018927)
feature 171 (0.018333)
feature 125 (0.016873)
feature 97 (0.016764)
feature 30 (0.016323)
feature 58 (0.015560)
feature 231 (0.015539)
feature 152 (0.015142)
feature 55 (0.014991)
feature 126 (0.014393)
feature 129 (0.013951)
feature 2 (0.013943)
feature 157 (0.013818)
feature 214 (0.012345)
feature 131 (0.012269)
feature 294 (0.012047)
feature 22 (0.011979)
feature 108 (0.011837)
feature 199 (0.011498)
feature 84 (0.011053)
feature 224 (0.011009)
feature 202 (0.010836)
feature 135 (0.010569)
feature 148 (0.010558)
feature 372 (0.010486)
feature 184 (0.010427)
feature 81 (0.010358)
feature 139 (0.010328)
inner fold=2
accuracy=0.478260869565
feature 231 (0.025098)
feature 53 (0.023388)
feature 148 (0.023334)
feature 172 (0.022451)
feature 33 (0.021238)
feature 52 (0.019956)
feature 210 (0.019058)
feature 227 (0.017099)
feature 125 (0.016632)
feature 120 (0.015670)
feature 35 (0.015495)
feature 213 (0.015247)
feature 81 (0.014401)
feature 153 (0.013840)
feature 200 (0.013483)
feature 122 (0.013351)
feature 55 (0.013221)
feature 344 (0.013158)
feature 110 (0.012838)
feature 155 (0.012529)
feature 0 (0.012049)
feature 57 (0.011463)
feature 158 (0.011119)
feature 130 (0.011065)
feature 164 (0.010701)
feature 174 (0.010686)
feature 173 (0.010668)
feature 34 (0.010543)
feature 38 (0.010316)
feature 156 (0.010194)
inner fold=3
accuracy=0.555555555556
feature 227 (0.024825)
feature 171 (0.023765)
feature 173 (0.023482)
feature 381 (0.022960)
feature 139 (0.021751)
feature 143 (0.021198)
feature 155 (0.018962)
feature 125 (0.017818)
feature 164 (0.017398)
feature 110 (0.016588)
feature 105 (0.016072)
feature 294 (0.014570)
feature 77 (0.014561)
feature 200 (0.014467)
feature 78 (0.014294)
feature 38 (0.014222)
feature 63 (0.014058)
feature 138 (0.013869)
feature 174 (0.013379)
feature 209 (0.013254)
feature 172 (0.012673)
feature 54 (0.011485)
feature 5 (0.011291)
feature 207 (0.011218)
feature 18 (0.010809)
feature 210 (0.010661)
feature 156 (0.010576)
feature 153 (0.010284)
feature 454 (0.009914)
feature 101 (0.009891)
inner fold=4
accuracy=0.711111111111
feature 55 (0.033867)
feature 138 (0.024679)
feature 166 (0.022490)
feature 171 (0.022104)
feature 136 (0.021113)
feature 210 (0.020898)
feature 84 (0.020824)
feature 100 (0.020274)
feature 56 (0.020265)
feature 235 (0.017742)
feature 77 (0.017162)
feature 168 (0.016586)
feature 294 (0.016308)
feature 157 (0.015726)
feature 134 (0.015153)
feature 182 (0.014583)
feature 38 (0.014410)
feature 139 (0.014374)
feature 203 (0.014318)
feature 200 (0.014014)
feature 105 (0.013938)
feature 194 (0.013757)
feature 188 (0.013728)
feature 163 (0.013172)
feature 207 (0.012677)
feature 57 (0.011928)
feature 161 (0.011258)
feature 123 (0.011005)
feature 41 (0.010747)
feature 81 (0.010591)
inner fold=0
accuracy=0.5
feature 46 (0.024435)
feature 383 (0.024417)
feature 176 (0.022258)
feature 152 (0.019534)
feature 182 (0.019150)
feature 80 (0.018693)
feature 24 (0.017508)
feature 131 (0.017491)
feature 138 (0.016716)
feature 171 (0.016708)
feature 174 (0.016179)
feature 136 (0.015860)
feature 175 (0.015544)
feature 106 (0.014747)
feature 142 (0.013792)
feature 21 (0.013715)
feature 122 (0.013678)
feature 78 (0.013549)
feature 211 (0.013444)
feature 222 (0.012714)
feature 202 (0.012584)
feature 214 (0.012331)
feature 12 (0.012324)
feature 129 (0.012284)
feature 45 (0.012166)
feature 44 (0.011874)
feature 168 (0.011814)
feature 5 (0.011722)
feature 137 (0.011610)
feature 35 (0.011490)
inner fold=1
accuracy=0.673913043478
feature 156 (0.041514)
feature 46 (0.030962)
feature 171 (0.029517)
feature 24 (0.029115)
feature 294 (0.026898)
feature 159 (0.023459)
feature 135 (0.021688)
feature 166 (0.021005)
feature 137 (0.020500)
feature 183 (0.018147)
feature 129 (0.017202)
feature 175 (0.016482)
feature 42 (0.015957)
feature 126 (0.015821)
feature 56 (0.014843)
feature 110 (0.013578)
feature 153 (0.012597)
feature 53 (0.012587)
feature 114 (0.012285)
feature 14 (0.011898)
feature 122 (0.011641)
feature 138 (0.011540)
feature 30 (0.011097)
feature 104 (0.010838)
feature 38 (0.010503)
feature 62 (0.010124)
feature 148 (0.009802)
feature 155 (0.009792)
feature 27 (0.009643)
feature 100 (0.009514)
inner fold=2
accuracy=0.54347826087
feature 156 (0.029836)
feature 110 (0.024508)
feature 172 (0.023007)
feature 129 (0.022691)
feature 173 (0.022485)
feature 138 (0.021652)
feature 34 (0.019358)
feature 231 (0.017991)
feature 81 (0.017900)
feature 14 (0.017620)
feature 143 (0.017605)
feature 385 (0.017396)
feature 131 (0.016943)
feature 5 (0.014225)
feature 58 (0.014098)
feature 234 (0.014076)
feature 0 (0.013760)
feature 203 (0.013398)
feature 188 (0.013089)
feature 57 (0.013040)
feature 219 (0.013019)
feature 209 (0.012144)
feature 183 (0.011763)
feature 42 (0.011527)
feature 56 (0.011021)
feature 101 (0.010916)
feature 21 (0.010862)
feature 383 (0.010488)
feature 8 (0.010367)
feature 18 (0.010233)
inner fold=3
accuracy=0.622222222222
feature 172 (0.037558)
feature 44 (0.024197)
feature 174 (0.022615)
feature 134 (0.019975)
feature 227 (0.019199)
feature 34 (0.018357)
feature 158 (0.017678)
feature 109 (0.016701)
feature 123 (0.016465)
feature 171 (0.016430)
feature 173 (0.016422)
feature 142 (0.015699)
feature 412 (0.015452)
feature 152 (0.015077)
feature 62 (0.014796)
feature 454 (0.014717)
feature 83 (0.014062)
feature 38 (0.013935)
feature 28 (0.013506)
feature 362 (0.013240)
feature 157 (0.012792)
feature 156 (0.012465)
feature 63 (0.012231)
feature 18 (0.011705)
feature 203 (0.011117)
feature 385 (0.011091)
feature 30 (0.010809)
feature 160 (0.010700)
feature 58 (0.010478)
feature 275 (0.010029)
inner fold=4
accuracy=0.577777777778

lay_id=11
feature 129 (0.024145)
feature 171 (0.023277)
feature 52 (0.021428)
feature 148 (0.021322)
feature 53 (0.020988)
feature 14 (0.020503)
feature 55 (0.019452)
feature 81 (0.018813)
feature 231 (0.017809)
feature 34 (0.017148)
feature 134 (0.017087)
feature 123 (0.017069)
feature 156 (0.016249)
feature 48 (0.016017)
feature 42 (0.015148)
feature 38 (0.015048)
feature 130 (0.014640)
feature 82 (0.014491)
feature 151 (0.013677)
feature 105 (0.013624)
feature 183 (0.013289)
feature 294 (0.012206)
feature 4 (0.011951)
feature 208 (0.011890)
feature 344 (0.011722)
feature 46 (0.011401)
feature 385 (0.010406)
feature 412 (0.010213)
feature 104 (0.009793)
feature 159 (0.009741)
inner fold=0
accuracy=0.608695652174
feature 101 (0.025986)
feature 159 (0.023679)
feature 156 (0.022245)
feature 142 (0.020018)
feature 171 (0.019778)
feature 84 (0.019753)
feature 14 (0.019142)
feature 4 (0.018396)
feature 168 (0.018275)
feature 53 (0.017233)
feature 109 (0.015011)
feature 272 (0.014723)
feature 81 (0.014699)
feature 152 (0.014601)
feature 134 (0.014431)
feature 160 (0.013964)
feature 55 (0.013248)
feature 184 (0.012960)
feature 33 (0.012743)
feature 80 (0.012383)
feature 227 (0.012370)
feature 78 (0.012289)
feature 154 (0.012109)
feature 121 (0.012064)
feature 385 (0.012024)
feature 18 (0.011977)
feature 46 (0.011976)
feature 123 (0.011763)
feature 141 (0.011636)
feature 235 (0.010560)
inner fold=1
accuracy=0.608695652174
feature 158 (0.027643)
feature 109 (0.027537)
feature 156 (0.025835)
feature 97 (0.021091)
feature 46 (0.019107)
feature 78 (0.018893)
feature 227 (0.016548)
feature 175 (0.016431)
feature 211 (0.016099)
feature 40 (0.015004)
feature 231 (0.014771)
feature 464 (0.014425)
feature 442 (0.014103)
feature 213 (0.013886)
feature 12 (0.013417)
feature 105 (0.013394)
feature 294 (0.012453)
feature 55 (0.012203)
feature 209 (0.012189)
feature 110 (0.011907)
feature 77 (0.011747)
feature 362 (0.011698)
feature 131 (0.011633)
feature 126 (0.011621)
feature 34 (0.011337)
feature 138 (0.011088)
feature 80 (0.010963)
feature 123 (0.010815)
feature 235 (0.010428)
feature 69 (0.010263)
inner fold=2
accuracy=0.586956521739
feature 80 (0.027364)
feature 128 (0.023571)
feature 171 (0.020393)
feature 68 (0.020162)
feature 137 (0.020131)
feature 165 (0.018159)
feature 156 (0.017095)
feature 134 (0.016674)
feature 14 (0.016655)
feature 294 (0.016230)
feature 69 (0.015249)
feature 81 (0.015206)
feature 39 (0.013866)
feature 129 (0.013505)
feature 227 (0.013371)
feature 164 (0.013078)
feature 188 (0.013034)
feature 40 (0.012817)
feature 139 (0.012769)
feature 44 (0.012697)
feature 158 (0.012678)
feature 12 (0.012612)
feature 19 (0.012338)
feature 78 (0.012333)
feature 159 (0.011489)
feature 126 (0.011095)
feature 180 (0.011030)
feature 34 (0.010936)
feature 46 (0.010843)
feature 29 (0.010653)
inner fold=3
accuracy=0.555555555556
feature 110 (0.036242)
feature 231 (0.030285)
feature 151 (0.022128)
feature 123 (0.021485)
feature 171 (0.019879)
feature 412 (0.018822)
feature 84 (0.017190)
feature 156 (0.017170)
feature 81 (0.016928)
feature 161 (0.016771)
feature 285 (0.015707)
feature 182 (0.015499)
feature 5 (0.014999)
feature 159 (0.014728)
feature 172 (0.014188)
feature 210 (0.012973)
feature 223 (0.012626)
feature 188 (0.012466)
feature 142 (0.012185)
feature 101 (0.011510)
feature 164 (0.010951)
feature 173 (0.010927)
feature 46 (0.010443)
feature 58 (0.010381)
feature 134 (0.010266)
feature 135 (0.009815)
feature 115 (0.009803)
feature 55 (0.009770)
feature 56 (0.009656)
feature 24 (0.009330)
inner fold=4
accuracy=0.644444444444
feature 136 (0.024176)
feature 294 (0.023293)
feature 44 (0.023181)
feature 14 (0.022996)
feature 171 (0.021619)
feature 134 (0.021037)
feature 73 (0.020573)
feature 30 (0.020406)
feature 231 (0.019953)
feature 175 (0.019939)
feature 139 (0.019661)
feature 151 (0.017803)
feature 159 (0.015993)
feature 381 (0.015846)
feature 166 (0.015686)
feature 168 (0.015219)
feature 182 (0.014192)
feature 210 (0.013728)
feature 24 (0.013380)
feature 58 (0.012693)
feature 385 (0.012146)
feature 148 (0.012066)
feature 102 (0.011847)
feature 12 (0.011828)
feature 213 (0.011022)
feature 157 (0.010278)
feature 173 (0.009815)
feature 141 (0.009731)
feature 125 (0.009635)
feature 84 (0.009629)
inner fold=0
accuracy=0.608695652174
feature 156 (0.033048)
feature 294 (0.028356)
feature 199 (0.027234)
feature 129 (0.026878)
feature 157 (0.021332)
feature 166 (0.019999)
feature 126 (0.019944)
feature 174 (0.019252)
feature 123 (0.018724)
feature 136 (0.018066)
feature 138 (0.017726)
feature 285 (0.016753)
feature 134 (0.016148)
feature 207 (0.016101)
feature 44 (0.016054)
feature 77 (0.015964)
feature 30 (0.015392)
feature 152 (0.013123)
feature 100 (0.012312)
feature 131 (0.012102)
feature 159 (0.011636)
feature 81 (0.011147)
feature 55 (0.010961)
feature 14 (0.010648)
feature 163 (0.010429)
feature 69 (0.009756)
feature 58 (0.009514)
feature 275 (0.009404)
feature 349 (0.009242)
feature 114 (0.009078)
inner fold=1
accuracy=0.630434782609
feature 168 (0.038113)
feature 159 (0.031314)
feature 136 (0.028878)
feature 153 (0.024424)
feature 294 (0.023426)
feature 131 (0.022166)
feature 29 (0.022038)
feature 102 (0.019210)
feature 142 (0.017621)
feature 123 (0.017370)
feature 171 (0.016458)
feature 30 (0.015320)
feature 231 (0.014870)
feature 120 (0.014159)
feature 46 (0.014007)
feature 51 (0.013841)
feature 21 (0.013704)
feature 157 (0.012682)
feature 203 (0.012362)
feature 155 (0.012228)
feature 152 (0.012174)
feature 164 (0.011852)
feature 12 (0.011619)
feature 156 (0.011616)
feature 227 (0.011077)
feature 80 (0.011014)
feature 122 (0.010912)
feature 135 (0.010618)
feature 60 (0.010355)
feature 147 (0.010176)
inner fold=2
accuracy=0.652173913043
feature 44 (0.035211)
feature 227 (0.026799)
feature 174 (0.026529)
feature 143 (0.024509)
feature 166 (0.022384)
feature 29 (0.020512)
feature 294 (0.019850)
feature 81 (0.017892)
feature 78 (0.017855)
feature 168 (0.017848)
feature 134 (0.017607)
feature 151 (0.017293)
feature 141 (0.015296)
feature 207 (0.014365)
feature 344 (0.014349)
feature 138 (0.014222)
feature 215 (0.014043)
feature 156 (0.013918)
feature 21 (0.013585)
feature 24 (0.013003)
feature 449 (0.012902)
feature 148 (0.012617)
feature 199 (0.012509)
feature 36 (0.012507)
feature 171 (0.012437)
feature 109 (0.011233)
feature 34 (0.011095)
feature 130 (0.011026)
feature 106 (0.011012)
feature 126 (0.010727)
inner fold=3
accuracy=0.533333333333
feature 159 (0.034033)
feature 216 (0.026981)
feature 222 (0.026291)
feature 43 (0.024923)
feature 126 (0.023758)
feature 157 (0.021745)
feature 213 (0.020785)
feature 227 (0.019070)
feature 137 (0.018432)
feature 174 (0.017288)
feature 14 (0.016715)
feature 24 (0.015771)
feature 165 (0.015045)
feature 143 (0.014534)
feature 172 (0.014322)
feature 44 (0.014313)
feature 210 (0.014141)
feature 73 (0.014085)
feature 46 (0.013809)
feature 209 (0.013736)
feature 63 (0.013263)
feature 358 (0.013250)
feature 81 (0.012834)
feature 123 (0.012425)
feature 121 (0.011704)
feature 141 (0.010739)
feature 201 (0.010273)
feature 54 (0.010092)
feature 114 (0.009974)
feature 42 (0.009874)
inner fold=4
accuracy=0.666666666667

lay_id=12
feature 227 (0.031002)
feature 157 (0.025568)
feature 152 (0.020633)
feature 123 (0.020253)
feature 169 (0.018798)
feature 155 (0.018154)
feature 381 (0.018123)
feature 105 (0.017573)
feature 202 (0.016342)
feature 168 (0.015827)
feature 171 (0.014827)
feature 34 (0.014736)
feature 4 (0.014240)
feature 106 (0.013949)
feature 129 (0.013664)
feature 101 (0.013301)
feature 56 (0.013265)
feature 42 (0.012818)
feature 30 (0.012806)
feature 57 (0.012604)
feature 14 (0.012367)
feature 142 (0.012207)
feature 12 (0.011871)
feature 136 (0.011817)
feature 231 (0.011756)
feature 174 (0.011181)
feature 172 (0.010873)
feature 125 (0.010701)
feature 454 (0.010467)
feature 81 (0.010459)
inner fold=0
accuracy=0.565217391304
feature 135 (0.038283)
feature 294 (0.027360)
feature 136 (0.025347)
feature 153 (0.023408)
feature 166 (0.020355)
feature 172 (0.018717)
feature 171 (0.018107)
feature 145 (0.017394)
feature 164 (0.016377)
feature 0 (0.015295)
feature 55 (0.014674)
feature 134 (0.014436)
feature 227 (0.014430)
feature 53 (0.014237)
feature 188 (0.013359)
feature 123 (0.013150)
feature 3 (0.012743)
feature 139 (0.012694)
feature 208 (0.012661)
feature 5 (0.012410)
feature 412 (0.012352)
feature 46 (0.012183)
feature 122 (0.011464)
feature 411 (0.011281)
feature 77 (0.011204)
feature 78 (0.011112)
feature 185 (0.011086)
feature 120 (0.010927)
feature 175 (0.010818)
feature 110 (0.010090)
inner fold=1
accuracy=0.652173913043
feature 171 (0.044765)
feature 294 (0.036973)
feature 381 (0.022947)
feature 174 (0.020885)
feature 46 (0.020281)
feature 123 (0.019999)
feature 165 (0.018974)
feature 130 (0.018871)
feature 129 (0.018429)
feature 235 (0.017977)
feature 62 (0.016905)
feature 80 (0.016820)
feature 166 (0.016693)
feature 28 (0.016265)
feature 44 (0.014726)
feature 454 (0.013927)
feature 17 (0.013031)
feature 78 (0.012906)
feature 172 (0.012687)
feature 159 (0.012573)
feature 54 (0.012206)
feature 50 (0.011398)
feature 170 (0.011332)
feature 385 (0.011272)
feature 71 (0.011093)
feature 81 (0.011038)
feature 126 (0.010897)
feature 43 (0.010821)
feature 164 (0.010798)
feature 249 (0.010336)
inner fold=2
accuracy=0.630434782609
feature 109 (0.045592)
feature 126 (0.034225)
feature 174 (0.024872)
feature 35 (0.024857)
feature 100 (0.020943)
feature 202 (0.019770)
feature 231 (0.019653)
feature 134 (0.019574)
feature 81 (0.018398)
feature 172 (0.018241)
feature 203 (0.017534)
feature 136 (0.017204)
feature 129 (0.017109)
feature 128 (0.016250)
feature 114 (0.014440)
feature 166 (0.014402)
feature 24 (0.014086)
feature 51 (0.013432)
feature 137 (0.012378)
feature 30 (0.012376)
feature 381 (0.012107)
feature 200 (0.012041)
feature 63 (0.011885)
feature 103 (0.011870)
feature 102 (0.011669)
feature 55 (0.010541)
feature 36 (0.010516)
feature 385 (0.010426)
feature 211 (0.010363)
feature 168 (0.010045)
inner fold=3
accuracy=0.622222222222
feature 294 (0.026731)
feature 55 (0.025748)
feature 101 (0.023747)
feature 50 (0.022558)
feature 174 (0.019985)
feature 235 (0.018916)
feature 156 (0.017629)
feature 136 (0.016969)
feature 125 (0.016583)
feature 56 (0.016411)
feature 58 (0.016193)
feature 8 (0.016186)
feature 109 (0.015826)
feature 213 (0.015579)
feature 153 (0.015107)
feature 54 (0.013698)
feature 168 (0.013261)
feature 152 (0.013168)
feature 14 (0.012875)
feature 134 (0.012607)
feature 203 (0.012573)
feature 165 (0.011905)
feature 123 (0.011449)
feature 127 (0.011428)
feature 46 (0.011276)
feature 171 (0.011239)
feature 2 (0.010966)
feature 35 (0.010826)
feature 358 (0.010820)
feature 183 (0.010613)
inner fold=4
accuracy=0.622222222222
feature 227 (0.056435)
feature 34 (0.032811)
feature 53 (0.026589)
feature 171 (0.021774)
feature 272 (0.020077)
feature 188 (0.018250)
feature 294 (0.017103)
feature 381 (0.016646)
feature 172 (0.016269)
feature 3 (0.015961)
feature 109 (0.015615)
feature 202 (0.014948)
feature 159 (0.014405)
feature 156 (0.014213)
feature 131 (0.014153)
feature 30 (0.014031)
feature 46 (0.013808)
feature 106 (0.013807)
feature 69 (0.012298)
feature 24 (0.012250)
feature 74 (0.011429)
feature 63 (0.011359)
feature 231 (0.011250)
feature 136 (0.010965)
feature 194 (0.010953)
feature 122 (0.010856)
feature 203 (0.010821)
feature 42 (0.010795)
feature 211 (0.010678)
feature 100 (0.010484)
inner fold=0
accuracy=0.673913043478
feature 184 (0.023152)
feature 155 (0.021736)
feature 81 (0.020697)
feature 82 (0.020094)
feature 145 (0.020038)
feature 123 (0.019590)
feature 56 (0.019219)
feature 173 (0.016728)
feature 12 (0.016725)
feature 44 (0.016673)
feature 172 (0.016372)
feature 194 (0.015865)
feature 227 (0.015788)
feature 294 (0.014982)
feature 156 (0.013072)
feature 203 (0.013030)
feature 344 (0.012999)
feature 57 (0.012782)
feature 95 (0.012682)
feature 41 (0.012379)
feature 101 (0.012243)
feature 24 (0.012228)
feature 358 (0.011258)
feature 138 (0.011202)
feature 30 (0.011168)
feature 174 (0.011083)
feature 211 (0.010986)
feature 109 (0.010957)
feature 134 (0.010818)
feature 151 (0.010708)
inner fold=1
accuracy=0.652173913043
feature 30 (0.030656)
feature 168 (0.028769)
feature 142 (0.028608)
feature 172 (0.019415)
feature 171 (0.017673)
feature 166 (0.016639)
feature 80 (0.015695)
feature 231 (0.015639)
feature 131 (0.015214)
feature 5 (0.014766)
feature 214 (0.014562)
feature 344 (0.014048)
feature 216 (0.013962)
feature 101 (0.013657)
feature 385 (0.013640)
feature 152 (0.013314)
feature 105 (0.012679)
feature 157 (0.012510)
feature 123 (0.012433)
feature 24 (0.012202)
feature 4 (0.011925)
feature 165 (0.011666)
feature 136 (0.011608)
feature 235 (0.011453)
feature 227 (0.011162)
feature 14 (0.011153)
feature 62 (0.010815)
feature 174 (0.010770)
feature 224 (0.010607)
feature 50 (0.009974)
inner fold=2
accuracy=0.54347826087
feature 123 (0.033873)
feature 235 (0.026646)
feature 104 (0.024215)
feature 172 (0.023698)
feature 42 (0.023547)
feature 203 (0.020896)
feature 44 (0.020272)
feature 164 (0.019754)
feature 130 (0.017945)
feature 110 (0.017542)
feature 114 (0.017087)
feature 174 (0.016845)
feature 171 (0.015844)
feature 81 (0.015620)
feature 383 (0.014180)
feature 148 (0.013736)
feature 46 (0.012831)
feature 24 (0.012694)
feature 43 (0.011661)
feature 163 (0.011356)
feature 28 (0.011282)
feature 79 (0.011172)
feature 33 (0.010807)
feature 122 (0.010553)
feature 101 (0.010152)
feature 385 (0.009700)
feature 166 (0.009678)
feature 109 (0.009372)
feature 107 (0.009195)
feature 188 (0.008946)
inner fold=3
accuracy=0.6
feature 148 (0.036502)
feature 235 (0.031543)
feature 171 (0.031409)
feature 46 (0.030897)
feature 344 (0.023561)
feature 164 (0.022580)
feature 174 (0.020164)
feature 53 (0.018577)
feature 130 (0.014819)
feature 216 (0.014505)
feature 58 (0.014305)
feature 152 (0.014156)
feature 56 (0.014140)
feature 141 (0.013698)
feature 84 (0.013482)
feature 14 (0.012719)
feature 202 (0.012424)
feature 43 (0.011826)
feature 166 (0.011761)
feature 213 (0.011686)
feature 156 (0.011335)
feature 107 (0.011141)
feature 135 (0.011032)
feature 173 (0.010617)
feature 184 (0.010062)
feature 44 (0.010050)
feature 126 (0.010018)
feature 151 (0.009887)
feature 51 (0.009859)
feature 172 (0.009855)
inner fold=4
accuracy=0.711111111111

outer fold 9
lay_id=0
feature 132 (0.032879)
feature 227 (0.026589)
feature 106 (0.024820)
feature 163 (0.022244)
feature 218 (0.020542)
feature 131 (0.020148)
feature 211 (0.019530)
feature 124 (0.019107)
feature 164 (0.016497)
feature 168 (0.015867)
feature 32 (0.015302)
feature 40 (0.014802)
feature 51 (0.014139)
feature 134 (0.013717)
feature 155 (0.013505)
feature 143 (0.013110)
feature 78 (0.012797)
feature 42 (0.012521)
feature 56 (0.012461)
feature 137 (0.011620)
feature 154 (0.011489)
feature 203 (0.011196)
feature 161 (0.011193)
feature 116 (0.011141)
feature 50 (0.011066)
feature 26 (0.011031)
feature 220 (0.010748)
feature 207 (0.010460)
feature 133 (0.010384)
feature 75 (0.009864)
inner fold=0
accuracy=0.608695652174
feature 125 (0.049582)
feature 167 (0.034457)
feature 119 (0.023303)
feature 199 (0.021296)
feature 34 (0.020819)
feature 58 (0.018892)
feature 170 (0.018351)
feature 102 (0.017709)
feature 290 (0.016744)
feature 53 (0.016512)
feature 30 (0.016369)
feature 49 (0.016367)
feature 141 (0.016048)
feature 153 (0.015153)
feature 160 (0.015056)
feature 155 (0.014625)
feature 144 (0.014484)
feature 212 (0.014353)
feature 219 (0.014280)
feature 206 (0.013105)
feature 130 (0.012133)
feature 47 (0.011926)
feature 377 (0.011915)
feature 46 (0.011767)
feature 52 (0.011706)
feature 42 (0.011471)
feature 116 (0.011364)
feature 78 (0.010732)
feature 51 (0.010414)
feature 76 (0.010135)
inner fold=1
accuracy=0.54347826087
feature 52 (0.029491)
feature 231 (0.027995)
feature 170 (0.021904)
feature 40 (0.021239)
feature 290 (0.021201)
feature 164 (0.019064)
feature 209 (0.018822)
feature 169 (0.018536)
feature 76 (0.017472)
feature 106 (0.017461)
feature 116 (0.017353)
feature 119 (0.016117)
feature 77 (0.015598)
feature 78 (0.015286)
feature 152 (0.014589)
feature 171 (0.014102)
feature 51 (0.013967)
feature 59 (0.013931)
feature 135 (0.013490)
feature 93 (0.013349)
feature 211 (0.012373)
feature 147 (0.011657)
feature 103 (0.011579)
feature 31 (0.011176)
feature 197 (0.011174)
feature 140 (0.010941)
feature 100 (0.010210)
feature 118 (0.010003)
feature 68 (0.009897)
feature 66 (0.009808)
inner fold=2
accuracy=0.630434782609
feature 40 (0.036062)
feature 51 (0.035753)
feature 170 (0.032204)
feature 42 (0.029597)
feature 180 (0.022565)
feature 199 (0.022271)
feature 162 (0.019125)
feature 49 (0.017669)
feature 205 (0.016853)
feature 379 (0.016433)
feature 126 (0.016294)
feature 167 (0.015965)
feature 52 (0.015293)
feature 268 (0.015067)
feature 76 (0.014821)
feature 131 (0.014614)
feature 204 (0.014148)
feature 93 (0.012703)
feature 169 (0.012463)
feature 155 (0.012395)
feature 65 (0.012395)
feature 152 (0.012237)
feature 147 (0.010994)
feature 77 (0.010480)
feature 46 (0.010091)
feature 373 (0.009972)
feature 358 (0.009744)
feature 111 (0.009714)
feature 80 (0.009552)
feature 165 (0.009210)
inner fold=3
accuracy=0.555555555556
feature 290 (0.033576)
feature 156 (0.029284)
feature 138 (0.026708)
feature 48 (0.025189)
feature 168 (0.024111)
feature 124 (0.023397)
feature 119 (0.023057)
feature 199 (0.020218)
feature 77 (0.019834)
feature 26 (0.017802)
feature 42 (0.017714)
feature 127 (0.016238)
feature 134 (0.014604)
feature 227 (0.014384)
feature 52 (0.014292)
feature 197 (0.014130)
feature 210 (0.013811)
feature 145 (0.013452)
feature 51 (0.013422)
feature 99 (0.013167)
feature 171 (0.013077)
feature 153 (0.013018)
feature 178 (0.012993)
feature 218 (0.012355)
feature 132 (0.011782)
feature 103 (0.011317)
feature 155 (0.011226)
feature 336 (0.010982)
feature 78 (0.010944)
feature 121 (0.010910)
inner fold=4
accuracy=0.711111111111
feature 290 (0.030825)
feature 164 (0.027943)
feature 223 (0.023098)
feature 39 (0.022679)
feature 152 (0.022624)
feature 125 (0.021268)
feature 227 (0.020656)
feature 105 (0.019962)
feature 8 (0.015599)
feature 54 (0.014364)
feature 168 (0.013749)
feature 170 (0.013347)
feature 154 (0.013345)
feature 20 (0.012823)
feature 103 (0.012610)
feature 134 (0.012498)
feature 51 (0.012350)
feature 390 (0.012245)
feature 167 (0.011974)
feature 1 (0.011862)
feature 138 (0.011857)
feature 199 (0.011821)
feature 148 (0.011760)
feature 65 (0.011246)
feature 50 (0.010982)
feature 409 (0.010978)
feature 381 (0.010939)
feature 144 (0.010922)
feature 126 (0.010651)
feature 31 (0.010570)
inner fold=0
accuracy=0.565217391304
feature 42 (0.048833)
feature 164 (0.033762)
feature 167 (0.033113)
feature 152 (0.027384)
feature 170 (0.019763)
feature 155 (0.016123)
feature 29 (0.015408)
feature 223 (0.015162)
feature 130 (0.014930)
feature 34 (0.014868)
feature 168 (0.014852)
feature 268 (0.014599)
feature 206 (0.014555)
feature 125 (0.014095)
feature 74 (0.013575)
feature 218 (0.013507)
feature 153 (0.013458)
feature 148 (0.013151)
feature 198 (0.012694)
feature 10 (0.012139)
feature 52 (0.012124)
feature 199 (0.012020)
feature 59 (0.011963)
feature 39 (0.011618)
feature 38 (0.011452)
feature 119 (0.010761)
feature 123 (0.010385)
feature 227 (0.010118)
feature 62 (0.009948)
feature 195 (0.009872)
inner fold=1
accuracy=0.652173913043
feature 77 (0.037137)
feature 167 (0.031445)
feature 227 (0.027948)
feature 340 (0.025197)
feature 106 (0.020622)
feature 184 (0.018821)
feature 152 (0.017129)
feature 212 (0.016785)
feature 131 (0.016615)
feature 129 (0.015787)
feature 47 (0.015494)
feature 126 (0.014909)
feature 159 (0.014634)
feature 171 (0.014571)
feature 134 (0.014566)
feature 271 (0.014183)
feature 149 (0.014126)
feature 379 (0.013094)
feature 10 (0.012934)
feature 151 (0.012362)
feature 155 (0.011700)
feature 164 (0.011261)
feature 22 (0.011157)
feature 283 (0.011069)
feature 450 (0.010826)
feature 122 (0.010331)
feature 1 (0.010240)
feature 54 (0.009912)
feature 178 (0.009484)
feature 147 (0.009231)
inner fold=2
accuracy=0.586956521739
feature 167 (0.045153)
feature 169 (0.030334)
feature 49 (0.027916)
feature 53 (0.026792)
feature 42 (0.023871)
feature 290 (0.023499)
feature 199 (0.023196)
feature 144 (0.022954)
feature 77 (0.021201)
feature 76 (0.019913)
feature 125 (0.018628)
feature 209 (0.016030)
feature 223 (0.014904)
feature 26 (0.014761)
feature 162 (0.014732)
feature 154 (0.013278)
feature 210 (0.012993)
feature 51 (0.012885)
feature 98 (0.012341)
feature 231 (0.012090)
feature 18 (0.011607)
feature 121 (0.011502)
feature 175 (0.011331)
feature 74 (0.011274)
feature 46 (0.011192)
feature 151 (0.010522)
feature 218 (0.010067)
feature 180 (0.009676)
feature 134 (0.009551)
feature 106 (0.009036)
inner fold=3
accuracy=0.488888888889
feature 227 (0.045431)
feature 290 (0.035107)
feature 110 (0.029211)
feature 40 (0.019616)
feature 58 (0.019611)
feature 130 (0.018702)
feature 118 (0.018699)
feature 44 (0.018608)
feature 49 (0.018370)
feature 209 (0.017899)
feature 119 (0.017400)
feature 151 (0.017285)
feature 231 (0.016366)
feature 8 (0.016340)
feature 160 (0.016080)
feature 134 (0.014993)
feature 105 (0.014374)
feature 74 (0.013683)
feature 59 (0.013190)
feature 127 (0.013040)
feature 125 (0.012704)
feature 162 (0.012550)
feature 190 (0.012461)
feature 129 (0.011887)
feature 144 (0.011694)
feature 161 (0.011454)
feature 41 (0.011443)
feature 76 (0.011090)
feature 17 (0.010931)
feature 178 (0.010689)
inner fold=4
accuracy=0.511111111111

lay_id=1
feature 12 (0.023324)
feature 294 (0.022013)
feature 63 (0.020768)
feature 81 (0.020164)
feature 85 (0.019675)
feature 102 (0.019408)
feature 135 (0.018235)
feature 4 (0.017129)
feature 126 (0.016191)
feature 79 (0.015869)
feature 214 (0.015110)
feature 44 (0.014444)
feature 84 (0.014432)
feature 57 (0.014364)
feature 78 (0.012527)
feature 110 (0.012486)
feature 166 (0.012230)
feature 213 (0.011788)
feature 156 (0.011757)
feature 29 (0.011641)
feature 128 (0.011616)
feature 137 (0.011345)
feature 148 (0.011238)
feature 134 (0.011042)
feature 73 (0.010970)
feature 121 (0.010752)
feature 168 (0.010603)
feature 175 (0.010380)
feature 36 (0.010225)
feature 394 (0.010080)
inner fold=0
accuracy=0.586956521739
feature 106 (0.031129)
feature 171 (0.024506)
feature 135 (0.023754)
feature 203 (0.022599)
feature 167 (0.020211)
feature 172 (0.018055)
feature 153 (0.017052)
feature 115 (0.016957)
feature 174 (0.016399)
feature 209 (0.016191)
feature 51 (0.015728)
feature 110 (0.014984)
feature 123 (0.014059)
feature 97 (0.013751)
feature 151 (0.013156)
feature 207 (0.013121)
feature 53 (0.011948)
feature 454 (0.011932)
feature 24 (0.011550)
feature 129 (0.011481)
feature 40 (0.011414)
feature 157 (0.010886)
feature 159 (0.010492)
feature 362 (0.010390)
feature 103 (0.010353)
feature 158 (0.010344)
feature 211 (0.010195)
feature 82 (0.010148)
feature 165 (0.010070)
feature 55 (0.010058)
inner fold=1
accuracy=0.630434782609
feature 81 (0.054419)
feature 168 (0.029735)
feature 128 (0.022461)
feature 159 (0.019599)
feature 227 (0.019075)
feature 294 (0.018569)
feature 110 (0.018563)
feature 199 (0.018366)
feature 12 (0.018186)
feature 46 (0.018161)
feature 105 (0.017731)
feature 207 (0.017487)
feature 174 (0.017391)
feature 97 (0.017144)
feature 18 (0.016214)
feature 43 (0.014591)
feature 114 (0.014565)
feature 164 (0.014489)
feature 208 (0.014296)
feature 143 (0.014162)
feature 139 (0.013529)
feature 129 (0.013522)
feature 47 (0.013441)
feature 24 (0.013341)
feature 53 (0.013219)
feature 216 (0.012381)
feature 231 (0.012187)
feature 171 (0.012110)
feature 126 (0.012045)
feature 214 (0.011899)
inner fold=2
accuracy=0.652173913043
feature 122 (0.023595)
feature 138 (0.023477)
feature 184 (0.022073)
feature 135 (0.021663)
feature 81 (0.021167)
feature 34 (0.021105)
feature 4 (0.020471)
feature 143 (0.019073)
feature 383 (0.019073)
feature 173 (0.018796)
feature 52 (0.018155)
feature 227 (0.017895)
feature 182 (0.017040)
feature 171 (0.016556)
feature 63 (0.016178)
feature 54 (0.015740)
feature 130 (0.015652)
feature 294 (0.014726)
feature 194 (0.014639)
feature 115 (0.014634)
feature 158 (0.014366)
feature 77 (0.014146)
feature 1 (0.013369)
feature 208 (0.012122)
feature 83 (0.012102)
feature 30 (0.011777)
feature 362 (0.011430)
feature 84 (0.011266)
feature 172 (0.011085)
feature 102 (0.010657)
inner fold=3
accuracy=0.533333333333
feature 14 (0.033233)
feature 44 (0.032159)
feature 294 (0.031614)
feature 84 (0.026514)
feature 129 (0.022493)
feature 169 (0.021794)
feature 123 (0.018104)
feature 5 (0.017535)
feature 208 (0.017236)
feature 134 (0.016071)
feature 167 (0.016071)
feature 139 (0.015626)
feature 43 (0.014669)
feature 164 (0.014447)
feature 213 (0.013744)
feature 175 (0.013685)
feature 52 (0.013641)
feature 152 (0.013233)
feature 172 (0.012818)
feature 60 (0.012793)
feature 272 (0.012260)
feature 58 (0.011881)
feature 55 (0.011821)
feature 46 (0.011798)
feature 199 (0.011624)
feature 42 (0.011422)
feature 174 (0.011231)
feature 70 (0.010215)
feature 36 (0.010120)
feature 4 (0.009587)
inner fold=4
accuracy=0.511111111111
feature 142 (0.040119)
feature 168 (0.031444)
feature 209 (0.025672)
feature 294 (0.023853)
feature 53 (0.019415)
feature 47 (0.019407)
feature 46 (0.018636)
feature 60 (0.018321)
feature 12 (0.017854)
feature 211 (0.017488)
feature 134 (0.016865)
feature 100 (0.016730)
feature 135 (0.015453)
feature 231 (0.014850)
feature 362 (0.014579)
feature 275 (0.013993)
feature 235 (0.013637)
feature 81 (0.013608)
feature 109 (0.013386)
feature 151 (0.013385)
feature 165 (0.012671)
feature 70 (0.012430)
feature 138 (0.012347)
feature 184 (0.011753)
feature 216 (0.011463)
feature 80 (0.011228)
feature 152 (0.011201)
feature 72 (0.011106)
feature 28 (0.011049)
feature 51 (0.010608)
inner fold=0
accuracy=0.586956521739
feature 46 (0.031313)
feature 34 (0.031118)
feature 78 (0.030691)
feature 168 (0.025117)
feature 171 (0.023520)
feature 12 (0.021112)
feature 156 (0.020375)
feature 5 (0.020113)
feature 18 (0.019272)
feature 203 (0.018534)
feature 53 (0.017656)
feature 79 (0.016961)
feature 164 (0.015669)
feature 142 (0.014653)
feature 80 (0.012703)
feature 172 (0.012598)
feature 51 (0.012309)
feature 167 (0.012187)
feature 54 (0.011881)
feature 174 (0.011682)
feature 120 (0.011512)
feature 14 (0.011344)
feature 152 (0.011247)
feature 235 (0.010946)
feature 148 (0.010939)
feature 147 (0.010258)
feature 222 (0.009672)
feature 200 (0.009501)
feature 166 (0.009401)
feature 114 (0.009359)
inner fold=1
accuracy=0.695652173913
feature 136 (0.037592)
feature 231 (0.035584)
feature 138 (0.020676)
feature 200 (0.020440)
feature 81 (0.020373)
feature 294 (0.018321)
feature 158 (0.017001)
feature 50 (0.016291)
feature 53 (0.016107)
feature 168 (0.016103)
feature 211 (0.013947)
feature 166 (0.013520)
feature 110 (0.013428)
feature 62 (0.013403)
feature 153 (0.013348)
feature 109 (0.013175)
feature 235 (0.013164)
feature 134 (0.012885)
feature 122 (0.012655)
feature 164 (0.012622)
feature 46 (0.012597)
feature 60 (0.012458)
feature 208 (0.011961)
feature 173 (0.011847)
feature 77 (0.011595)
feature 127 (0.011565)
feature 129 (0.011295)
feature 18 (0.010849)
feature 57 (0.010524)
feature 82 (0.010429)
inner fold=2
accuracy=0.695652173913
feature 81 (0.032905)
feature 82 (0.031304)
feature 18 (0.025147)
feature 84 (0.023827)
feature 44 (0.023803)
feature 29 (0.022484)
feature 156 (0.021271)
feature 216 (0.020066)
feature 152 (0.017455)
feature 57 (0.017010)
feature 12 (0.016779)
feature 148 (0.016748)
feature 79 (0.016497)
feature 46 (0.016202)
feature 235 (0.015517)
feature 171 (0.014374)
feature 138 (0.013644)
feature 211 (0.013226)
feature 28 (0.012433)
feature 128 (0.012202)
feature 454 (0.012036)
feature 140 (0.011786)
feature 166 (0.011674)
feature 120 (0.011659)
feature 77 (0.010778)
feature 103 (0.010403)
feature 158 (0.009805)
feature 165 (0.009779)
feature 53 (0.009764)
feature 168 (0.009449)
inner fold=3
accuracy=0.622222222222
feature 14 (0.030403)
feature 81 (0.025081)
feature 165 (0.024807)
feature 172 (0.024040)
feature 46 (0.023985)
feature 231 (0.022890)
feature 171 (0.020163)
feature 54 (0.020071)
feature 122 (0.019871)
feature 42 (0.017848)
feature 235 (0.017746)
feature 12 (0.017624)
feature 138 (0.017535)
feature 213 (0.016845)
feature 208 (0.016746)
feature 200 (0.016339)
feature 166 (0.015959)
feature 227 (0.015216)
feature 377 (0.014540)
feature 167 (0.014461)
feature 110 (0.013256)
feature 175 (0.012948)
feature 216 (0.011697)
feature 33 (0.011480)
feature 159 (0.011153)
feature 114 (0.010984)
feature 151 (0.010713)
feature 77 (0.010228)
feature 131 (0.010077)
feature 287 (0.009716)
inner fold=4
accuracy=0.555555555556

lay_id=2
feature 173 (0.035039)
feature 109 (0.032047)
feature 138 (0.028811)
feature 344 (0.024828)
feature 172 (0.022396)
feature 168 (0.021754)
feature 81 (0.019941)
feature 123 (0.019413)
feature 131 (0.019176)
feature 122 (0.017590)
feature 152 (0.017088)
feature 214 (0.016035)
feature 82 (0.016005)
feature 55 (0.015401)
feature 52 (0.015210)
feature 454 (0.014921)
feature 114 (0.014746)
feature 134 (0.014626)
feature 129 (0.014158)
feature 151 (0.013919)
feature 80 (0.013616)
feature 194 (0.013587)
feature 157 (0.013419)
feature 110 (0.013195)
feature 77 (0.013038)
feature 21 (0.012930)
feature 1 (0.012424)
feature 136 (0.012247)
feature 209 (0.012153)
feature 139 (0.011891)
inner fold=0
accuracy=0.717391304348
feature 171 (0.033994)
feature 136 (0.030698)
feature 213 (0.023562)
feature 155 (0.020697)
feature 153 (0.020397)
feature 139 (0.019894)
feature 46 (0.019029)
feature 62 (0.018276)
feature 159 (0.018187)
feature 53 (0.017784)
feature 101 (0.016984)
feature 120 (0.016393)
feature 138 (0.015611)
feature 381 (0.014618)
feature 55 (0.014576)
feature 77 (0.014556)
feature 166 (0.014463)
feature 156 (0.013758)
feature 231 (0.013042)
feature 14 (0.012814)
feature 411 (0.012645)
feature 199 (0.012577)
feature 134 (0.012142)
feature 151 (0.011908)
feature 168 (0.011575)
feature 396 (0.010616)
feature 84 (0.010385)
feature 167 (0.010316)
feature 184 (0.009876)
feature 114 (0.009636)
inner fold=1
accuracy=0.630434782609
feature 171 (0.034043)
feature 30 (0.031183)
feature 362 (0.027762)
feature 12 (0.024292)
feature 138 (0.022976)
feature 79 (0.021799)
feature 55 (0.017902)
feature 161 (0.017558)
feature 52 (0.016805)
feature 46 (0.016297)
feature 156 (0.015386)
feature 114 (0.015375)
feature 153 (0.014536)
feature 464 (0.014230)
feature 133 (0.013719)
feature 148 (0.013417)
feature 130 (0.013395)
feature 110 (0.013041)
feature 143 (0.013040)
feature 109 (0.013017)
feature 173 (0.012546)
feature 235 (0.011755)
feature 285 (0.011016)
feature 131 (0.010849)
feature 69 (0.010324)
feature 127 (0.010317)
feature 184 (0.010105)
feature 166 (0.010081)
feature 185 (0.010039)
feature 71 (0.009487)
inner fold=2
accuracy=0.782608695652
feature 84 (0.037276)
feature 171 (0.034775)
feature 129 (0.029898)
feature 58 (0.025103)
feature 106 (0.022204)
feature 46 (0.018385)
feature 55 (0.017880)
feature 164 (0.016766)
feature 227 (0.015058)
feature 203 (0.014691)
feature 77 (0.014642)
feature 142 (0.014527)
feature 153 (0.013778)
feature 247 (0.013417)
feature 80 (0.013193)
feature 301 (0.012699)
feature 5 (0.012503)
feature 209 (0.012365)
feature 33 (0.011820)
feature 213 (0.011657)
feature 12 (0.011590)
feature 14 (0.011400)
feature 57 (0.011158)
feature 137 (0.010861)
feature 102 (0.010843)
feature 216 (0.010424)
feature 104 (0.010298)
feature 52 (0.010138)
feature 29 (0.010073)
feature 38 (0.009933)
inner fold=3
accuracy=0.511111111111
feature 126 (0.034047)
feature 159 (0.029617)
feature 30 (0.027695)
feature 46 (0.021544)
feature 44 (0.021352)
feature 110 (0.020875)
feature 53 (0.019116)
feature 134 (0.017213)
feature 165 (0.016925)
feature 84 (0.016823)
feature 235 (0.016755)
feature 55 (0.016655)
feature 169 (0.016503)
feature 372 (0.016066)
feature 158 (0.014810)
feature 103 (0.014207)
feature 167 (0.013463)
feature 47 (0.013325)
feature 33 (0.012766)
feature 4 (0.012397)
feature 272 (0.012238)
feature 106 (0.012150)
feature 1 (0.012107)
feature 231 (0.011952)
feature 18 (0.011940)
feature 172 (0.011480)
feature 139 (0.011218)
feature 199 (0.011156)
feature 160 (0.011026)
feature 38 (0.010975)
inner fold=4
accuracy=0.555555555556
feature 294 (0.031621)
feature 171 (0.029370)
feature 184 (0.021747)
feature 14 (0.021712)
feature 42 (0.020020)
feature 156 (0.019209)
feature 110 (0.019142)
feature 136 (0.018958)
feature 166 (0.018373)
feature 102 (0.018186)
feature 142 (0.017955)
feature 125 (0.017454)
feature 188 (0.016953)
feature 173 (0.016869)
feature 38 (0.016064)
feature 51 (0.015666)
feature 157 (0.015002)
feature 174 (0.014564)
feature 126 (0.013826)
feature 138 (0.012415)
feature 104 (0.012163)
feature 55 (0.011842)
feature 97 (0.011781)
feature 149 (0.011646)
feature 199 (0.011630)
feature 168 (0.011516)
feature 61 (0.011383)
feature 430 (0.011380)
feature 62 (0.011194)
feature 161 (0.010828)
inner fold=0
accuracy=0.695652173913
feature 294 (0.029199)
feature 381 (0.029013)
feature 123 (0.023651)
feature 216 (0.021252)
feature 129 (0.021228)
feature 142 (0.019935)
feature 110 (0.019881)
feature 168 (0.019323)
feature 136 (0.019224)
feature 34 (0.018146)
feature 193 (0.016897)
feature 157 (0.016747)
feature 120 (0.016431)
feature 81 (0.016094)
feature 26 (0.015511)
feature 5 (0.015031)
feature 143 (0.014583)
feature 165 (0.014003)
feature 211 (0.013302)
feature 171 (0.012885)
feature 33 (0.011837)
feature 224 (0.011584)
feature 78 (0.011427)
feature 272 (0.011030)
feature 52 (0.010640)
feature 24 (0.010467)
feature 153 (0.010193)
feature 53 (0.010053)
feature 21 (0.009988)
feature 231 (0.009969)
inner fold=1
accuracy=0.565217391304
feature 171 (0.037284)
feature 110 (0.029131)
feature 208 (0.028418)
feature 30 (0.023710)
feature 156 (0.023692)
feature 0 (0.019723)
feature 174 (0.019515)
feature 130 (0.018678)
feature 12 (0.018601)
feature 53 (0.018260)
feature 126 (0.016687)
feature 46 (0.016563)
feature 203 (0.014549)
feature 152 (0.013670)
feature 172 (0.013369)
feature 148 (0.012794)
feature 123 (0.012776)
feature 362 (0.012254)
feature 144 (0.012172)
feature 137 (0.011852)
feature 344 (0.011759)
feature 173 (0.010929)
feature 159 (0.010842)
feature 151 (0.010799)
feature 103 (0.010744)
feature 57 (0.010562)
feature 294 (0.010458)
feature 95 (0.010329)
feature 207 (0.009960)
feature 155 (0.009895)
inner fold=2
accuracy=0.586956521739
feature 294 (0.031825)
feature 155 (0.026894)
feature 390 (0.024704)
feature 136 (0.021454)
feature 175 (0.020843)
feature 275 (0.020535)
feature 14 (0.018969)
feature 12 (0.018793)
feature 100 (0.018626)
feature 122 (0.018561)
feature 158 (0.018533)
feature 148 (0.018316)
feature 344 (0.016699)
feature 143 (0.016246)
feature 130 (0.014627)
feature 207 (0.014179)
feature 159 (0.014116)
feature 137 (0.013748)
feature 52 (0.013592)
feature 173 (0.013568)
feature 153 (0.013334)
feature 110 (0.012905)
feature 44 (0.012651)
feature 235 (0.012133)
feature 83 (0.011163)
feature 42 (0.010690)
feature 13 (0.010456)
feature 123 (0.010361)
feature 211 (0.010329)
feature 231 (0.010172)
inner fold=3
accuracy=0.577777777778
feature 159 (0.032611)
feature 129 (0.029019)
feature 131 (0.026961)
feature 464 (0.021359)
feature 120 (0.020790)
feature 156 (0.019156)
feature 209 (0.018752)
feature 70 (0.018208)
feature 60 (0.017422)
feature 84 (0.016597)
feature 172 (0.015627)
feature 58 (0.014434)
feature 227 (0.014083)
feature 171 (0.013498)
feature 272 (0.013213)
feature 344 (0.012965)
feature 202 (0.012274)
feature 160 (0.011922)
feature 52 (0.011916)
feature 152 (0.011865)
feature 44 (0.011832)
feature 38 (0.010922)
feature 17 (0.010805)
feature 207 (0.010733)
feature 110 (0.010642)
feature 107 (0.010555)
feature 174 (0.010479)
feature 18 (0.010288)
feature 15 (0.010188)
feature 135 (0.009925)
inner fold=4
accuracy=0.6

lay_id=3
feature 203 (0.028315)
feature 55 (0.027641)
feature 81 (0.023366)
feature 166 (0.020006)
feature 57 (0.019599)
feature 173 (0.019281)
feature 148 (0.018969)
feature 294 (0.017300)
feature 213 (0.016769)
feature 216 (0.016006)
feature 14 (0.014389)
feature 272 (0.013806)
feature 39 (0.013544)
feature 80 (0.012983)
feature 53 (0.012577)
feature 46 (0.012251)
feature 153 (0.011829)
feature 172 (0.011764)
feature 344 (0.011573)
feature 18 (0.011469)
feature 24 (0.011301)
feature 84 (0.010753)
feature 160 (0.010729)
feature 122 (0.010595)
feature 139 (0.010468)
feature 44 (0.010267)
feature 159 (0.010172)
feature 102 (0.010112)
feature 174 (0.010006)
feature 161 (0.009601)
inner fold=0
accuracy=0.695652173913
feature 136 (0.026241)
feature 182 (0.023574)
feature 161 (0.023282)
feature 80 (0.021063)
feature 294 (0.018312)
feature 30 (0.018086)
feature 155 (0.016667)
feature 153 (0.016405)
feature 156 (0.015723)
feature 141 (0.015375)
feature 14 (0.015226)
feature 207 (0.015113)
feature 235 (0.014767)
feature 38 (0.014713)
feature 43 (0.014367)
feature 1 (0.014133)
feature 227 (0.013969)
feature 5 (0.013095)
feature 122 (0.012785)
feature 114 (0.012743)
feature 57 (0.011925)
feature 97 (0.011837)
feature 55 (0.011350)
feature 396 (0.011339)
feature 213 (0.011159)
feature 159 (0.011123)
feature 48 (0.010870)
feature 29 (0.010647)
feature 214 (0.010474)
feature 63 (0.010353)
inner fold=1
accuracy=0.478260869565
feature 171 (0.031021)
feature 175 (0.024151)
feature 231 (0.023395)
feature 127 (0.022478)
feature 58 (0.022454)
feature 215 (0.021734)
feature 344 (0.016136)
feature 142 (0.015508)
feature 21 (0.014808)
feature 104 (0.014597)
feature 57 (0.014415)
feature 5 (0.014208)
feature 110 (0.013289)
feature 42 (0.013047)
feature 412 (0.012895)
feature 145 (0.012844)
feature 55 (0.012100)
feature 136 (0.011862)
feature 14 (0.011828)
feature 4 (0.011576)
feature 166 (0.011212)
feature 385 (0.011151)
feature 209 (0.011139)
feature 101 (0.010829)
feature 38 (0.010645)
feature 172 (0.010449)
feature 156 (0.010442)
feature 199 (0.010413)
feature 222 (0.010362)
feature 211 (0.010339)
inner fold=2
accuracy=0.608695652174
feature 81 (0.032154)
feature 58 (0.031070)
feature 44 (0.027520)
feature 235 (0.021879)
feature 55 (0.021259)
feature 78 (0.018691)
feature 77 (0.018479)
feature 158 (0.017343)
feature 126 (0.016234)
feature 153 (0.015514)
feature 104 (0.014683)
feature 57 (0.014378)
feature 35 (0.014082)
feature 145 (0.013977)
feature 157 (0.013002)
feature 3 (0.012694)
feature 0 (0.012647)
feature 110 (0.011945)
feature 203 (0.011806)
feature 170 (0.011732)
feature 102 (0.011671)
feature 97 (0.011428)
feature 194 (0.011253)
feature 84 (0.011069)
feature 454 (0.010798)
feature 165 (0.010081)
feature 109 (0.010023)
feature 276 (0.010015)
feature 62 (0.009491)
feature 161 (0.009215)
inner fold=3
accuracy=0.666666666667
feature 81 (0.036465)
feature 171 (0.021959)
feature 48 (0.018818)
feature 201 (0.018792)
feature 166 (0.017579)
feature 46 (0.017238)
feature 123 (0.016517)
feature 35 (0.016430)
feature 131 (0.015582)
feature 231 (0.015205)
feature 95 (0.014910)
feature 24 (0.014746)
feature 148 (0.013456)
feature 5 (0.013032)
feature 215 (0.013013)
feature 158 (0.012702)
feature 294 (0.012214)
feature 125 (0.012205)
feature 164 (0.012176)
feature 235 (0.011761)
feature 362 (0.011676)
feature 213 (0.011508)
feature 78 (0.011478)
feature 172 (0.011416)
feature 160 (0.011332)
feature 127 (0.011112)
feature 126 (0.011056)
feature 139 (0.010943)
feature 179 (0.010612)
feature 29 (0.010427)
inner fold=4
accuracy=0.644444444444
feature 14 (0.024296)
feature 294 (0.023373)
feature 142 (0.022951)
feature 194 (0.022334)
feature 156 (0.020560)
feature 153 (0.020364)
feature 134 (0.018765)
feature 112 (0.018522)
feature 168 (0.018110)
feature 110 (0.017831)
feature 44 (0.016731)
feature 174 (0.016417)
feature 15 (0.016365)
feature 145 (0.015378)
feature 77 (0.014461)
feature 130 (0.014336)
feature 344 (0.013997)
feature 109 (0.013855)
feature 2 (0.013748)
feature 187 (0.013676)
feature 78 (0.013538)
feature 179 (0.012782)
feature 148 (0.012652)
feature 136 (0.012620)
feature 38 (0.012474)
feature 167 (0.012417)
feature 147 (0.012268)
feature 184 (0.011689)
feature 131 (0.011687)
feature 53 (0.011628)
inner fold=0
accuracy=0.630434782609
feature 294 (0.035332)
feature 55 (0.033891)
feature 56 (0.029654)
feature 79 (0.020742)
feature 344 (0.020383)
feature 139 (0.020264)
feature 231 (0.020206)
feature 157 (0.018895)
feature 5 (0.018652)
feature 213 (0.018419)
feature 209 (0.018320)
feature 46 (0.017665)
feature 152 (0.016835)
feature 78 (0.016446)
feature 136 (0.016234)
feature 151 (0.015787)
feature 126 (0.014408)
feature 133 (0.013869)
feature 84 (0.013446)
feature 131 (0.012742)
feature 199 (0.012489)
feature 44 (0.012461)
feature 184 (0.012238)
feature 43 (0.012105)
feature 30 (0.011986)
feature 53 (0.011848)
feature 153 (0.011468)
feature 145 (0.011456)
feature 81 (0.011376)
feature 110 (0.011350)
inner fold=1
accuracy=0.630434782609
feature 231 (0.047386)
feature 175 (0.030973)
feature 81 (0.025378)
feature 62 (0.024144)
feature 58 (0.021644)
feature 1 (0.020875)
feature 159 (0.020541)
feature 151 (0.020022)
feature 174 (0.017317)
feature 0 (0.016614)
feature 102 (0.016511)
feature 166 (0.016395)
feature 51 (0.016280)
feature 209 (0.016043)
feature 227 (0.015411)
feature 172 (0.013897)
feature 125 (0.013843)
feature 52 (0.013806)
feature 155 (0.013446)
feature 235 (0.013429)
feature 157 (0.013310)
feature 164 (0.013006)
feature 153 (0.012893)
feature 168 (0.012865)
feature 84 (0.011862)
feature 134 (0.011656)
feature 127 (0.011625)
feature 4 (0.011207)
feature 301 (0.011180)
feature 188 (0.010129)
inner fold=2
accuracy=0.608695652174
feature 203 (0.038901)
feature 231 (0.033470)
feature 42 (0.029516)
feature 163 (0.027601)
feature 168 (0.024285)
feature 362 (0.019911)
feature 294 (0.019269)
feature 148 (0.018506)
feature 52 (0.018071)
feature 136 (0.018000)
feature 172 (0.017548)
feature 29 (0.015242)
feature 156 (0.014763)
feature 183 (0.013040)
feature 171 (0.013029)
feature 101 (0.012626)
feature 454 (0.012578)
feature 46 (0.012004)
feature 103 (0.011586)
feature 30 (0.011356)
feature 222 (0.011182)
feature 175 (0.011036)
feature 0 (0.011035)
feature 142 (0.010808)
feature 157 (0.010763)
feature 120 (0.010371)
feature 110 (0.010319)
feature 188 (0.010182)
feature 55 (0.009895)
feature 114 (0.009791)
inner fold=3
accuracy=0.577777777778
feature 84 (0.034784)
feature 294 (0.028877)
feature 168 (0.025409)
feature 157 (0.024886)
feature 105 (0.020941)
feature 18 (0.020714)
feature 231 (0.017961)
feature 78 (0.016680)
feature 272 (0.016410)
feature 70 (0.015799)
feature 44 (0.015503)
feature 227 (0.015373)
feature 214 (0.015275)
feature 110 (0.015040)
feature 81 (0.014946)
feature 115 (0.014464)
feature 213 (0.014248)
feature 122 (0.013907)
feature 12 (0.013822)
feature 158 (0.013459)
feature 207 (0.013123)
feature 69 (0.013011)
feature 175 (0.012122)
feature 156 (0.012071)
feature 222 (0.011957)
feature 50 (0.010066)
feature 131 (0.009869)
feature 172 (0.009844)
feature 142 (0.009580)
feature 1 (0.009506)
inner fold=4
accuracy=0.688888888889

lay_id=4
feature 166 (0.030536)
feature 82 (0.027388)
feature 208 (0.026923)
feature 130 (0.026844)
feature 102 (0.018994)
feature 182 (0.018452)
feature 153 (0.017597)
feature 159 (0.015503)
feature 235 (0.015333)
feature 106 (0.015313)
feature 194 (0.015284)
feature 126 (0.015224)
feature 214 (0.014976)
feature 56 (0.014341)
feature 79 (0.014254)
feature 80 (0.013704)
feature 223 (0.013017)
feature 201 (0.012895)
feature 344 (0.012610)
feature 152 (0.012353)
feature 84 (0.012235)
feature 114 (0.012109)
feature 157 (0.012000)
feature 24 (0.011647)
feature 60 (0.011377)
feature 103 (0.011207)
feature 222 (0.011003)
feature 216 (0.010713)
feature 146 (0.010551)
feature 165 (0.010249)
inner fold=0
accuracy=0.54347826087
feature 139 (0.026949)
feature 123 (0.022906)
feature 203 (0.020455)
feature 160 (0.019880)
feature 3 (0.019311)
feature 33 (0.018955)
feature 231 (0.017134)
feature 120 (0.016975)
feature 60 (0.016684)
feature 38 (0.016658)
feature 44 (0.016293)
feature 46 (0.015829)
feature 153 (0.015813)
feature 77 (0.015633)
feature 40 (0.015465)
feature 78 (0.015308)
feature 168 (0.015171)
feature 181 (0.015116)
feature 30 (0.015023)
feature 70 (0.013873)
feature 163 (0.012526)
feature 71 (0.012352)
feature 142 (0.012279)
feature 272 (0.011963)
feature 110 (0.011954)
feature 194 (0.011573)
feature 235 (0.011267)
feature 12 (0.010532)
feature 151 (0.010296)
feature 50 (0.010103)
inner fold=1
accuracy=0.652173913043
feature 99 (0.028774)
feature 0 (0.020531)
feature 294 (0.020028)
feature 115 (0.019333)
feature 171 (0.017744)
feature 53 (0.017477)
feature 14 (0.017115)
feature 227 (0.016050)
feature 200 (0.015638)
feature 84 (0.015592)
feature 164 (0.014473)
feature 182 (0.014018)
feature 81 (0.013587)
feature 275 (0.013377)
feature 58 (0.013289)
feature 46 (0.013115)
feature 78 (0.012988)
feature 82 (0.012703)
feature 35 (0.012611)
feature 172 (0.012489)
feature 168 (0.012428)
feature 110 (0.012394)
feature 143 (0.012255)
feature 71 (0.011935)
feature 208 (0.011934)
feature 194 (0.011806)
feature 174 (0.011426)
feature 4 (0.011252)
feature 60 (0.010964)
feature 231 (0.009939)
inner fold=2
accuracy=0.608695652174
feature 55 (0.029967)
feature 3 (0.021170)
feature 166 (0.019940)
feature 168 (0.019237)
feature 84 (0.018613)
feature 216 (0.018334)
feature 133 (0.017833)
feature 174 (0.017174)
feature 152 (0.017087)
feature 157 (0.016726)
feature 128 (0.016363)
feature 52 (0.015406)
feature 294 (0.014220)
feature 46 (0.014191)
feature 77 (0.013551)
feature 208 (0.013415)
feature 349 (0.013058)
feature 21 (0.012864)
feature 301 (0.012850)
feature 81 (0.012663)
feature 136 (0.012601)
feature 179 (0.012400)
feature 15 (0.012333)
feature 201 (0.011979)
feature 82 (0.011798)
feature 129 (0.011705)
feature 18 (0.011318)
feature 344 (0.011060)
feature 107 (0.010867)
feature 381 (0.010861)
inner fold=3
accuracy=0.6
feature 210 (0.026974)
feature 0 (0.025245)
feature 48 (0.021649)
feature 161 (0.020418)
feature 213 (0.019748)
feature 173 (0.019682)
feature 134 (0.019680)
feature 34 (0.019463)
feature 174 (0.017873)
feature 51 (0.017751)
feature 208 (0.017382)
feature 138 (0.016948)
feature 102 (0.016197)
feature 141 (0.015665)
feature 159 (0.014802)
feature 216 (0.014765)
feature 135 (0.014324)
feature 60 (0.014316)
feature 137 (0.014075)
feature 53 (0.014062)
feature 57 (0.013973)
feature 171 (0.012362)
feature 99 (0.012337)
feature 168 (0.012316)
feature 58 (0.010644)
feature 166 (0.010377)
feature 52 (0.010285)
feature 294 (0.009673)
feature 193 (0.009443)
feature 79 (0.009342)
inner fold=4
accuracy=0.577777777778
feature 81 (0.040947)
feature 294 (0.040256)
feature 171 (0.029145)
feature 12 (0.023371)
feature 110 (0.022560)
feature 1 (0.022439)
feature 106 (0.021776)
feature 138 (0.020126)
feature 84 (0.018377)
feature 120 (0.017067)
feature 105 (0.016432)
feature 123 (0.016252)
feature 114 (0.016240)
feature 100 (0.014832)
feature 153 (0.014656)
feature 134 (0.013716)
feature 63 (0.013445)
feature 135 (0.013381)
feature 60 (0.011988)
feature 149 (0.011694)
feature 170 (0.011500)
feature 216 (0.011097)
feature 174 (0.010787)
feature 213 (0.010675)
feature 202 (0.010549)
feature 168 (0.010329)
feature 165 (0.009903)
feature 26 (0.009090)
feature 188 (0.009072)
feature 148 (0.008977)
inner fold=0
accuracy=0.586956521739
feature 129 (0.035490)
feature 2 (0.032572)
feature 156 (0.029901)
feature 138 (0.025621)
feature 81 (0.024110)
feature 294 (0.023027)
feature 172 (0.023016)
feature 166 (0.021872)
feature 120 (0.019214)
feature 214 (0.019020)
feature 203 (0.017602)
feature 184 (0.017451)
feature 200 (0.016050)
feature 53 (0.013939)
feature 80 (0.013396)
feature 202 (0.013120)
feature 79 (0.012927)
feature 171 (0.012843)
feature 142 (0.012497)
feature 55 (0.012474)
feature 46 (0.012419)
feature 143 (0.012288)
feature 126 (0.011937)
feature 121 (0.011934)
feature 84 (0.011885)
feature 222 (0.011102)
feature 148 (0.010952)
feature 155 (0.010111)
feature 213 (0.009812)
feature 344 (0.009517)
inner fold=1
accuracy=0.630434782609
feature 81 (0.036948)
feature 82 (0.024819)
feature 211 (0.024467)
feature 166 (0.023770)
feature 208 (0.022934)
feature 0 (0.018487)
feature 120 (0.017997)
feature 110 (0.017348)
feature 138 (0.017213)
feature 62 (0.015864)
feature 146 (0.015717)
feature 28 (0.014617)
feature 44 (0.014522)
feature 4 (0.013195)
feature 168 (0.012553)
feature 227 (0.012492)
feature 51 (0.012408)
feature 143 (0.012086)
feature 153 (0.012065)
feature 231 (0.011905)
feature 114 (0.011841)
feature 349 (0.011790)
feature 235 (0.011555)
feature 38 (0.011518)
feature 43 (0.011202)
feature 128 (0.011010)
feature 115 (0.010912)
feature 155 (0.010837)
feature 53 (0.010677)
feature 130 (0.010578)
inner fold=2
accuracy=0.630434782609
feature 174 (0.031426)
feature 235 (0.030003)
feature 0 (0.026504)
feature 138 (0.021995)
feature 114 (0.020921)
feature 143 (0.020426)
feature 47 (0.018987)
feature 81 (0.018775)
feature 148 (0.018559)
feature 146 (0.018293)
feature 56 (0.018157)
feature 202 (0.017679)
feature 171 (0.016456)
feature 152 (0.015414)
feature 46 (0.015389)
feature 173 (0.015344)
feature 172 (0.015109)
feature 184 (0.014337)
feature 137 (0.014175)
feature 231 (0.013940)
feature 165 (0.013223)
feature 139 (0.013214)
feature 1 (0.013106)
feature 103 (0.012583)
feature 126 (0.012419)
feature 123 (0.011910)
feature 155 (0.011461)
feature 294 (0.011295)
feature 161 (0.010908)
feature 157 (0.010801)
inner fold=3
accuracy=0.688888888889
feature 203 (0.028033)
feature 123 (0.027932)
feature 135 (0.020415)
feature 137 (0.018777)
feature 159 (0.018644)
feature 131 (0.018388)
feature 110 (0.018300)
feature 38 (0.018042)
feature 168 (0.017651)
feature 133 (0.017172)
feature 158 (0.015135)
feature 57 (0.013558)
feature 53 (0.013491)
feature 381 (0.013344)
feature 188 (0.013225)
feature 148 (0.013171)
feature 46 (0.012670)
feature 214 (0.012239)
feature 173 (0.012122)
feature 0 (0.012021)
feature 235 (0.011986)
feature 166 (0.011964)
feature 4 (0.011644)
feature 143 (0.011486)
feature 81 (0.011458)
feature 390 (0.011347)
feature 15 (0.011212)
feature 165 (0.011146)
feature 161 (0.011006)
feature 115 (0.010742)
inner fold=4
accuracy=0.688888888889

lay_id=5
feature 362 (0.026221)
feature 120 (0.022473)
feature 138 (0.020405)
feature 44 (0.019384)
feature 84 (0.018406)
feature 115 (0.018380)
feature 125 (0.018067)
feature 156 (0.017449)
feature 158 (0.017205)
feature 82 (0.016732)
feature 28 (0.016250)
feature 46 (0.015657)
feature 172 (0.015456)
feature 209 (0.014102)
feature 166 (0.013586)
feature 285 (0.013569)
feature 153 (0.013400)
feature 63 (0.013395)
feature 134 (0.013362)
feature 107 (0.012900)
feature 340 (0.011990)
feature 203 (0.011979)
feature 58 (0.011353)
feature 397 (0.011347)
feature 39 (0.011178)
feature 169 (0.010806)
feature 50 (0.010464)
feature 135 (0.010303)
feature 163 (0.010193)
feature 51 (0.010140)
inner fold=0
accuracy=0.652173913043
feature 168 (0.036679)
feature 235 (0.035876)
feature 84 (0.029062)
feature 44 (0.026834)
feature 4 (0.023311)
feature 227 (0.020319)
feature 123 (0.018981)
feature 83 (0.018388)
feature 115 (0.017573)
feature 129 (0.017556)
feature 14 (0.016327)
feature 136 (0.015667)
feature 174 (0.015620)
feature 114 (0.013764)
feature 156 (0.013755)
feature 18 (0.013615)
feature 143 (0.013361)
feature 110 (0.013343)
feature 169 (0.012356)
feature 210 (0.011988)
feature 125 (0.011955)
feature 209 (0.011561)
feature 102 (0.011298)
feature 107 (0.011178)
feature 159 (0.011132)
feature 78 (0.011099)
feature 171 (0.010971)
feature 22 (0.010801)
feature 203 (0.010524)
feature 208 (0.010032)
inner fold=1
accuracy=0.565217391304
feature 129 (0.028728)
feature 171 (0.027533)
feature 84 (0.024602)
feature 184 (0.023560)
feature 164 (0.018222)
feature 48 (0.017757)
feature 139 (0.017598)
feature 107 (0.017195)
feature 14 (0.016650)
feature 174 (0.016003)
feature 102 (0.015866)
feature 231 (0.015531)
feature 52 (0.015097)
feature 227 (0.014253)
feature 78 (0.013934)
feature 110 (0.012918)
feature 115 (0.012724)
feature 28 (0.012489)
feature 2 (0.012362)
feature 209 (0.012140)
feature 30 (0.012126)
feature 125 (0.011834)
feature 156 (0.011234)
feature 122 (0.011088)
feature 158 (0.010874)
feature 34 (0.009944)
feature 75 (0.009597)
feature 152 (0.009408)
feature 29 (0.009340)
feature 80 (0.009232)
inner fold=2
accuracy=0.586956521739
feature 174 (0.022304)
feature 168 (0.022254)
feature 211 (0.020960)
feature 44 (0.019894)
feature 123 (0.018993)
feature 56 (0.018885)
feature 2 (0.018365)
feature 157 (0.017387)
feature 173 (0.016598)
feature 120 (0.015223)
feature 53 (0.015076)
feature 54 (0.014890)
feature 81 (0.014854)
feature 84 (0.014566)
feature 358 (0.014324)
feature 377 (0.014007)
feature 109 (0.013071)
feature 167 (0.012627)
feature 184 (0.011867)
feature 97 (0.011839)
feature 156 (0.011662)
feature 107 (0.011605)
feature 161 (0.011582)
feature 52 (0.011379)
feature 140 (0.011297)
feature 152 (0.011067)
feature 80 (0.010868)
feature 153 (0.010861)
feature 166 (0.010845)
feature 199 (0.010438)
inner fold=3
accuracy=0.644444444444
feature 84 (0.039545)
feature 235 (0.028090)
feature 18 (0.025875)
feature 157 (0.025093)
feature 208 (0.024461)
feature 173 (0.024083)
feature 202 (0.022854)
feature 30 (0.022530)
feature 120 (0.017365)
feature 171 (0.017018)
feature 145 (0.015661)
feature 79 (0.015309)
feature 184 (0.015270)
feature 39 (0.014183)
feature 344 (0.014097)
feature 156 (0.013862)
feature 68 (0.013679)
feature 168 (0.013392)
feature 123 (0.012597)
feature 152 (0.012248)
feature 385 (0.012154)
feature 21 (0.012030)
feature 52 (0.011349)
feature 209 (0.010804)
feature 82 (0.010757)
feature 231 (0.010593)
feature 81 (0.010344)
feature 128 (0.010001)
feature 159 (0.009870)
feature 44 (0.009599)
inner fold=4
accuracy=0.577777777778
feature 171 (0.029597)
feature 174 (0.028885)
feature 55 (0.027508)
feature 84 (0.021836)
feature 30 (0.021610)
feature 152 (0.020952)
feature 208 (0.020720)
feature 130 (0.019713)
feature 182 (0.016533)
feature 156 (0.016508)
feature 203 (0.016086)
feature 2 (0.015660)
feature 60 (0.015286)
feature 82 (0.014524)
feature 213 (0.014292)
feature 131 (0.012986)
feature 294 (0.012829)
feature 53 (0.012707)
feature 167 (0.012664)
feature 128 (0.012201)
feature 81 (0.012176)
feature 101 (0.012154)
feature 176 (0.011072)
feature 51 (0.010765)
feature 157 (0.010741)
feature 129 (0.010465)
feature 173 (0.010336)
feature 207 (0.010276)
feature 136 (0.009750)
feature 14 (0.009290)
inner fold=0
accuracy=0.652173913043
feature 81 (0.031306)
feature 294 (0.023339)
feature 84 (0.022540)
feature 136 (0.021931)
feature 208 (0.019469)
feature 188 (0.019216)
feature 24 (0.018815)
feature 109 (0.018574)
feature 173 (0.017725)
feature 235 (0.017359)
feature 171 (0.017185)
feature 2 (0.017139)
feature 174 (0.016791)
feature 199 (0.015516)
feature 141 (0.015360)
feature 142 (0.015096)
feature 138 (0.015085)
feature 222 (0.014601)
feature 12 (0.014589)
feature 172 (0.014254)
feature 156 (0.013747)
feature 158 (0.013725)
feature 168 (0.013406)
feature 56 (0.013176)
feature 215 (0.013001)
feature 211 (0.012553)
feature 82 (0.012524)
feature 180 (0.012391)
feature 105 (0.011516)
feature 214 (0.011512)
inner fold=1
accuracy=0.673913043478
feature 203 (0.036892)
feature 81 (0.024601)
feature 294 (0.024484)
feature 275 (0.024209)
feature 83 (0.020245)
feature 110 (0.020229)
feature 199 (0.019792)
feature 105 (0.019542)
feature 171 (0.018548)
feature 78 (0.017690)
feature 170 (0.017404)
feature 272 (0.015852)
feature 134 (0.014763)
feature 21 (0.014387)
feature 107 (0.014343)
feature 151 (0.014104)
feature 194 (0.013635)
feature 56 (0.013546)
feature 115 (0.013259)
feature 362 (0.013001)
feature 136 (0.012666)
feature 148 (0.011625)
feature 84 (0.011623)
feature 100 (0.011510)
feature 126 (0.011491)
feature 139 (0.010929)
feature 135 (0.010605)
feature 372 (0.010548)
feature 131 (0.010454)
feature 16 (0.010325)
inner fold=2
accuracy=0.652173913043
feature 12 (0.036827)
feature 55 (0.030782)
feature 128 (0.025963)
feature 174 (0.020937)
feature 51 (0.020671)
feature 164 (0.020447)
feature 137 (0.020057)
feature 81 (0.020054)
feature 3 (0.018998)
feature 34 (0.016451)
feature 130 (0.015823)
feature 171 (0.014660)
feature 58 (0.014210)
feature 110 (0.014165)
feature 24 (0.013615)
feature 107 (0.013577)
feature 215 (0.013130)
feature 156 (0.012834)
feature 53 (0.012717)
feature 114 (0.012542)
feature 122 (0.011994)
feature 133 (0.011705)
feature 214 (0.011699)
feature 143 (0.011639)
feature 213 (0.010857)
feature 131 (0.010718)
feature 5 (0.010702)
feature 203 (0.010670)
feature 123 (0.010637)
feature 82 (0.010097)
inner fold=3
accuracy=0.511111111111
feature 156 (0.025510)
feature 44 (0.024921)
feature 84 (0.022070)
feature 33 (0.021288)
feature 137 (0.018800)
feature 30 (0.018586)
feature 56 (0.015700)
feature 101 (0.015394)
feature 18 (0.015138)
feature 126 (0.014866)
feature 272 (0.014495)
feature 213 (0.013959)
feature 71 (0.013809)
feature 97 (0.013641)
feature 144 (0.013622)
feature 35 (0.013501)
feature 216 (0.013276)
feature 166 (0.012998)
feature 52 (0.012753)
feature 34 (0.012686)
feature 53 (0.012085)
feature 104 (0.012071)
feature 147 (0.011866)
feature 125 (0.011829)
feature 377 (0.011615)
feature 58 (0.011001)
feature 81 (0.010845)
feature 14 (0.010407)
feature 77 (0.010390)
feature 172 (0.010323)
inner fold=4
accuracy=0.622222222222

lay_id=6
feature 106 (0.031811)
feature 203 (0.029864)
feature 216 (0.022536)
feature 128 (0.021382)
feature 105 (0.021023)
feature 166 (0.020216)
feature 169 (0.019495)
feature 131 (0.019042)
feature 129 (0.017677)
feature 149 (0.016750)
feature 143 (0.016615)
feature 46 (0.015785)
feature 171 (0.014701)
feature 209 (0.014116)
feature 58 (0.014105)
feature 84 (0.014006)
feature 35 (0.013654)
feature 344 (0.012871)
feature 5 (0.011777)
feature 167 (0.011745)
feature 173 (0.011733)
feature 12 (0.011679)
feature 110 (0.011496)
feature 79 (0.010400)
feature 34 (0.010182)
feature 53 (0.009926)
feature 81 (0.009810)
feature 135 (0.009803)
feature 63 (0.009767)
feature 157 (0.009546)
inner fold=0
accuracy=0.673913043478
feature 199 (0.027226)
feature 81 (0.023351)
feature 156 (0.021913)
feature 164 (0.021902)
feature 122 (0.020020)
feature 152 (0.019206)
feature 128 (0.018395)
feature 29 (0.018190)
feature 17 (0.017507)
feature 171 (0.016817)
feature 294 (0.016601)
feature 211 (0.016117)
feature 362 (0.015241)
feature 107 (0.014449)
feature 110 (0.014205)
feature 153 (0.014055)
feature 209 (0.013941)
feature 1 (0.013855)
feature 24 (0.013051)
feature 55 (0.013044)
feature 56 (0.012719)
feature 77 (0.012367)
feature 62 (0.012187)
feature 454 (0.011962)
feature 14 (0.011549)
feature 203 (0.011512)
feature 43 (0.011324)
feature 275 (0.011230)
feature 168 (0.011091)
feature 21 (0.010805)
inner fold=1
accuracy=0.630434782609
feature 294 (0.035168)
feature 231 (0.019580)
feature 84 (0.019464)
feature 153 (0.019042)
feature 41 (0.018209)
feature 142 (0.017127)
feature 46 (0.015786)
feature 152 (0.015731)
feature 3 (0.015401)
feature 12 (0.014814)
feature 81 (0.014160)
feature 227 (0.014108)
feature 129 (0.013884)
feature 211 (0.013720)
feature 214 (0.013478)
feature 396 (0.013337)
feature 171 (0.013281)
feature 137 (0.013037)
feature 344 (0.013002)
feature 141 (0.012865)
feature 39 (0.012672)
feature 77 (0.012560)
feature 79 (0.012421)
feature 60 (0.012102)
feature 301 (0.012086)
feature 42 (0.011425)
feature 169 (0.011410)
feature 235 (0.011320)
feature 4 (0.011216)
feature 203 (0.010740)
inner fold=2
accuracy=0.608695652174
feature 120 (0.029086)
feature 231 (0.026055)
feature 171 (0.025396)
feature 213 (0.021861)
feature 344 (0.019709)
feature 128 (0.019239)
feature 14 (0.019030)
feature 211 (0.018875)
feature 55 (0.018738)
feature 151 (0.017737)
feature 122 (0.017653)
feature 174 (0.017020)
feature 130 (0.016679)
feature 45 (0.015377)
feature 44 (0.015264)
feature 114 (0.014890)
feature 110 (0.013478)
feature 155 (0.013150)
feature 35 (0.012898)
feature 390 (0.012574)
feature 81 (0.012556)
feature 133 (0.012368)
feature 109 (0.012195)
feature 30 (0.012178)
feature 84 (0.011907)
feature 148 (0.011897)
feature 137 (0.011676)
feature 203 (0.011630)
feature 199 (0.011506)
feature 209 (0.010632)
inner fold=3
accuracy=0.577777777778
feature 294 (0.028364)
feature 164 (0.027078)
feature 43 (0.026531)
feature 12 (0.023979)
feature 136 (0.021739)
feature 165 (0.021683)
feature 174 (0.021624)
feature 203 (0.021350)
feature 171 (0.020852)
feature 123 (0.019860)
feature 129 (0.018667)
feature 362 (0.018618)
feature 45 (0.017219)
feature 81 (0.016912)
feature 53 (0.016760)
feature 175 (0.015045)
feature 78 (0.013806)
feature 151 (0.013083)
feature 135 (0.013002)
feature 184 (0.012931)
feature 168 (0.012824)
feature 142 (0.012804)
feature 84 (0.012242)
feature 210 (0.010904)
feature 106 (0.010896)
feature 395 (0.010767)
feature 90 (0.010426)
feature 46 (0.010356)
feature 156 (0.010064)
feature 201 (0.010052)
inner fold=4
accuracy=0.577777777778
feature 294 (0.062213)
feature 44 (0.025038)
feature 235 (0.024341)
feature 231 (0.021346)
feature 142 (0.020675)
feature 81 (0.020107)
feature 216 (0.019170)
feature 78 (0.018659)
feature 28 (0.017961)
feature 214 (0.017767)
feature 208 (0.017433)
feature 215 (0.016044)
feature 14 (0.015942)
feature 57 (0.015910)
feature 131 (0.015748)
feature 158 (0.015681)
feature 114 (0.015043)
feature 222 (0.014405)
feature 134 (0.014349)
feature 137 (0.014127)
feature 70 (0.014073)
feature 45 (0.013744)
feature 166 (0.013459)
feature 344 (0.013001)
feature 173 (0.012386)
feature 201 (0.012373)
feature 211 (0.012155)
feature 202 (0.012005)
feature 170 (0.010866)
feature 55 (0.010555)
inner fold=0
accuracy=0.608695652174
feature 166 (0.042213)
feature 294 (0.042161)
feature 134 (0.024393)
feature 81 (0.022474)
feature 1 (0.020468)
feature 390 (0.019574)
feature 15 (0.017453)
feature 40 (0.016395)
feature 155 (0.016025)
feature 69 (0.015064)
feature 131 (0.014636)
feature 123 (0.014451)
feature 2 (0.014449)
feature 129 (0.014352)
feature 202 (0.013828)
feature 101 (0.013336)
feature 234 (0.012493)
feature 210 (0.012275)
feature 77 (0.011657)
feature 62 (0.011555)
feature 227 (0.011113)
feature 156 (0.011004)
feature 85 (0.010986)
feature 110 (0.010959)
feature 301 (0.010876)
feature 442 (0.010874)
feature 127 (0.010846)
feature 149 (0.009830)
feature 14 (0.009687)
feature 143 (0.009560)
inner fold=1
accuracy=0.695652173913
feature 181 (0.027755)
feature 110 (0.021610)
feature 179 (0.019032)
feature 97 (0.018359)
feature 231 (0.017312)
feature 171 (0.017212)
feature 46 (0.016815)
feature 122 (0.016604)
feature 170 (0.016575)
feature 294 (0.015278)
feature 56 (0.014460)
feature 216 (0.013645)
feature 38 (0.013354)
feature 140 (0.013259)
feature 158 (0.012384)
feature 30 (0.011831)
feature 101 (0.011794)
feature 120 (0.011755)
feature 188 (0.011584)
feature 123 (0.011574)
feature 73 (0.011478)
feature 159 (0.011429)
feature 166 (0.011161)
feature 151 (0.010817)
feature 55 (0.010725)
feature 82 (0.010500)
feature 156 (0.010323)
feature 127 (0.010199)
feature 227 (0.010092)
feature 125 (0.010031)
inner fold=2
accuracy=0.630434782609
feature 294 (0.043278)
feature 82 (0.020237)
feature 381 (0.019605)
feature 151 (0.019141)
feature 164 (0.018162)
feature 58 (0.017640)
feature 136 (0.017443)
feature 62 (0.016503)
feature 211 (0.015282)
feature 130 (0.014903)
feature 138 (0.014779)
feature 137 (0.014658)
feature 202 (0.014516)
feature 127 (0.013798)
feature 128 (0.013775)
feature 199 (0.013401)
feature 43 (0.013301)
feature 166 (0.013229)
feature 38 (0.013204)
feature 203 (0.013132)
feature 134 (0.012329)
feature 135 (0.011646)
feature 215 (0.011471)
feature 142 (0.011082)
feature 156 (0.011030)
feature 14 (0.010700)
feature 79 (0.010661)
feature 173 (0.010580)
feature 105 (0.010284)
feature 209 (0.010195)
inner fold=3
accuracy=0.755555555556
feature 110 (0.039887)
feature 203 (0.025398)
feature 174 (0.022288)
feature 166 (0.021793)
feature 122 (0.021148)
feature 148 (0.020881)
feature 147 (0.020124)
feature 168 (0.020023)
feature 81 (0.017360)
feature 349 (0.017180)
feature 101 (0.016433)
feature 412 (0.014915)
feature 171 (0.014700)
feature 42 (0.014662)
feature 184 (0.014570)
feature 2 (0.014336)
feature 159 (0.014028)
feature 155 (0.013951)
feature 344 (0.013830)
feature 83 (0.013495)
feature 172 (0.012918)
feature 173 (0.012508)
feature 142 (0.012346)
feature 222 (0.011799)
feature 201 (0.011491)
feature 56 (0.011454)
feature 34 (0.011353)
feature 48 (0.011181)
feature 127 (0.011034)
feature 199 (0.010917)
inner fold=4
accuracy=0.6

outer fold 10
lay_id=0
feature 171 (0.033253)
feature 125 (0.031997)
feature 162 (0.030547)
feature 138 (0.027326)
feature 131 (0.023384)
feature 98 (0.022603)
feature 51 (0.022281)
feature 40 (0.022095)
feature 77 (0.019307)
feature 164 (0.018107)
feature 163 (0.017609)
feature 290 (0.016022)
feature 207 (0.014041)
feature 133 (0.014033)
feature 10 (0.013612)
feature 134 (0.013600)
feature 103 (0.013537)
feature 116 (0.013537)
feature 157 (0.013257)
feature 64 (0.012855)
feature 144 (0.012823)
feature 135 (0.012273)
feature 124 (0.012073)
feature 190 (0.012033)
feature 80 (0.011524)
feature 153 (0.011399)
feature 205 (0.011306)
feature 111 (0.011208)
feature 460 (0.011173)
feature 38 (0.011146)
inner fold=0
accuracy=0.595744680851
feature 212 (0.046535)
feature 42 (0.026929)
feature 125 (0.025571)
feature 143 (0.024578)
feature 164 (0.019967)
feature 159 (0.018712)
feature 106 (0.017317)
feature 160 (0.017095)
feature 271 (0.016269)
feature 199 (0.015520)
feature 134 (0.015462)
feature 220 (0.015314)
feature 210 (0.015214)
feature 167 (0.015124)
feature 10 (0.014787)
feature 170 (0.014361)
feature 77 (0.013877)
feature 14 (0.013795)
feature 26 (0.013531)
feature 29 (0.012552)
feature 36 (0.012532)
feature 118 (0.012425)
feature 138 (0.012096)
feature 30 (0.012001)
feature 20 (0.011847)
feature 381 (0.011736)
feature 127 (0.011694)
feature 290 (0.011559)
feature 209 (0.011522)
feature 168 (0.010945)
inner fold=1
accuracy=0.478260869565
feature 290 (0.026513)
feature 135 (0.023607)
feature 51 (0.023428)
feature 116 (0.022699)
feature 75 (0.020368)
feature 195 (0.018125)
feature 147 (0.017674)
feature 169 (0.017375)
feature 227 (0.016635)
feature 198 (0.014510)
feature 30 (0.014181)
feature 377 (0.014177)
feature 206 (0.013865)
feature 38 (0.013828)
feature 271 (0.013375)
feature 106 (0.013178)
feature 68 (0.012658)
feature 133 (0.012609)
feature 178 (0.012426)
feature 144 (0.012260)
feature 167 (0.012045)
feature 29 (0.011326)
feature 438 (0.010967)
feature 136 (0.010784)
feature 58 (0.010348)
feature 56 (0.009305)
feature 160 (0.009172)
feature 35 (0.009051)
feature 74 (0.009051)
feature 194 (0.009010)
inner fold=2
accuracy=0.630434782609
feature 74 (0.029462)
feature 168 (0.025887)
feature 154 (0.024690)
feature 105 (0.020016)
feature 40 (0.019757)
feature 77 (0.019604)
feature 181 (0.018156)
feature 116 (0.017296)
feature 205 (0.016483)
feature 121 (0.015915)
feature 218 (0.014339)
feature 51 (0.013973)
feature 141 (0.013594)
feature 95 (0.013548)
feature 133 (0.013196)
feature 54 (0.012417)
feature 134 (0.012333)
feature 231 (0.012231)
feature 29 (0.012071)
feature 138 (0.011508)
feature 58 (0.011477)
feature 103 (0.011334)
feature 290 (0.011277)
feature 340 (0.011096)
feature 20 (0.010920)
feature 31 (0.010790)
feature 148 (0.010577)
feature 144 (0.010429)
feature 39 (0.010389)
feature 78 (0.010374)
inner fold=3
accuracy=0.6
feature 119 (0.041020)
feature 42 (0.026335)
feature 152 (0.024664)
feature 151 (0.021729)
feature 52 (0.020680)
feature 76 (0.020511)
feature 20 (0.019139)
feature 160 (0.018020)
feature 132 (0.015429)
feature 138 (0.014864)
feature 377 (0.014365)
feature 164 (0.014163)
feature 29 (0.013876)
feature 162 (0.013828)
feature 207 (0.013438)
feature 141 (0.013054)
feature 58 (0.012338)
feature 36 (0.012291)
feature 223 (0.012094)
feature 25 (0.011926)
feature 47 (0.011888)
feature 40 (0.011824)
feature 209 (0.011650)
feature 144 (0.011355)
feature 290 (0.011245)
feature 121 (0.011094)
feature 136 (0.011013)
feature 227 (0.010726)
feature 279 (0.010569)
feature 131 (0.010373)
inner fold=4
accuracy=0.666666666667
feature 152 (0.037445)
feature 125 (0.028789)
feature 154 (0.020513)
feature 75 (0.019324)
feature 149 (0.017042)
feature 223 (0.016562)
feature 195 (0.015890)
feature 65 (0.015782)
feature 358 (0.015720)
feature 106 (0.014768)
feature 205 (0.014199)
feature 207 (0.013977)
feature 141 (0.013264)
feature 48 (0.013262)
feature 438 (0.013245)
feature 209 (0.013146)
feature 38 (0.013012)
feature 121 (0.013007)
feature 161 (0.012953)
feature 169 (0.012895)
feature 10 (0.012895)
feature 95 (0.012596)
feature 167 (0.012311)
feature 51 (0.012109)
feature 212 (0.011896)
feature 24 (0.011671)
feature 52 (0.011647)
feature 54 (0.011137)
feature 126 (0.010942)
feature 164 (0.010819)
inner fold=0
accuracy=0.617021276596
feature 210 (0.028554)
feature 106 (0.026238)
feature 195 (0.026047)
feature 148 (0.024967)
feature 209 (0.024673)
feature 167 (0.023100)
feature 162 (0.021726)
feature 42 (0.020631)
feature 231 (0.020147)
feature 53 (0.016947)
feature 199 (0.016575)
feature 97 (0.016234)
feature 168 (0.015334)
feature 219 (0.015178)
feature 123 (0.015061)
feature 12 (0.014808)
feature 30 (0.014357)
feature 290 (0.014303)
feature 198 (0.013837)
feature 211 (0.013308)
feature 79 (0.013177)
feature 152 (0.012780)
feature 206 (0.012684)
feature 101 (0.012059)
feature 189 (0.011552)
feature 164 (0.011361)
feature 178 (0.011232)
feature 127 (0.011180)
feature 145 (0.011075)
feature 34 (0.010261)
inner fold=1
accuracy=0.586956521739
feature 20 (0.024274)
feature 38 (0.023977)
feature 290 (0.023421)
feature 42 (0.022143)
feature 227 (0.021229)
feature 162 (0.020909)
feature 54 (0.020670)
feature 151 (0.020487)
feature 381 (0.019402)
feature 77 (0.018254)
feature 167 (0.017704)
feature 124 (0.017110)
feature 47 (0.015698)
feature 76 (0.014501)
feature 211 (0.014294)
feature 74 (0.014111)
feature 161 (0.013490)
feature 149 (0.013247)
feature 148 (0.013243)
feature 24 (0.012998)
feature 69 (0.012159)
feature 39 (0.011895)
feature 336 (0.011622)
feature 129 (0.011045)
feature 30 (0.010611)
feature 48 (0.010500)
feature 53 (0.010261)
feature 0 (0.009848)
feature 169 (0.009585)
feature 135 (0.009571)
inner fold=2
accuracy=0.652173913043
feature 290 (0.054157)
feature 223 (0.039392)
feature 125 (0.031602)
feature 152 (0.023869)
feature 199 (0.021752)
feature 30 (0.020357)
feature 130 (0.019481)
feature 133 (0.018089)
feature 77 (0.017794)
feature 198 (0.017031)
feature 110 (0.016852)
feature 144 (0.014695)
feature 0 (0.014418)
feature 59 (0.014283)
feature 164 (0.013638)
feature 381 (0.013114)
feature 197 (0.012647)
feature 203 (0.012593)
feature 38 (0.012440)
feature 138 (0.012410)
feature 123 (0.012284)
feature 160 (0.012181)
feature 40 (0.012179)
feature 94 (0.011921)
feature 209 (0.011787)
feature 34 (0.011727)
feature 25 (0.011668)
feature 49 (0.011588)
feature 42 (0.011483)
feature 210 (0.011423)
inner fold=3
accuracy=0.6
feature 290 (0.043721)
feature 199 (0.029731)
feature 231 (0.027123)
feature 162 (0.023082)
feature 204 (0.022285)
feature 180 (0.020720)
feature 116 (0.016565)
feature 20 (0.016372)
feature 38 (0.015706)
feature 147 (0.015439)
feature 126 (0.014946)
feature 66 (0.014902)
feature 125 (0.014420)
feature 34 (0.013750)
feature 127 (0.013311)
feature 284 (0.013049)
feature 152 (0.012893)
feature 76 (0.012564)
feature 227 (0.012319)
feature 77 (0.012153)
feature 223 (0.011940)
feature 73 (0.011793)
feature 164 (0.011763)
feature 155 (0.011577)
feature 178 (0.011574)
feature 210 (0.011270)
feature 153 (0.011050)
feature 160 (0.011026)
feature 67 (0.010894)
feature 297 (0.010886)
inner fold=4
accuracy=0.6

lay_id=1
feature 172 (0.031945)
feature 46 (0.029211)
feature 145 (0.024509)
feature 129 (0.023740)
feature 294 (0.023088)
feature 14 (0.022026)
feature 209 (0.021154)
feature 231 (0.017711)
feature 171 (0.017615)
feature 156 (0.016911)
feature 175 (0.016648)
feature 159 (0.015286)
feature 138 (0.014824)
feature 151 (0.014669)
feature 216 (0.014522)
feature 34 (0.013960)
feature 127 (0.013002)
feature 130 (0.012994)
feature 43 (0.012828)
feature 235 (0.012466)
feature 381 (0.012114)
feature 78 (0.012017)
feature 110 (0.011963)
feature 21 (0.011887)
feature 56 (0.011876)
feature 166 (0.011615)
feature 60 (0.011468)
feature 148 (0.011326)
feature 105 (0.011093)
feature 53 (0.010935)
inner fold=0
accuracy=0.595744680851
feature 168 (0.038159)
feature 161 (0.025636)
feature 70 (0.025454)
feature 207 (0.024357)
feature 54 (0.021250)
feature 294 (0.019598)
feature 63 (0.019419)
feature 139 (0.018145)
feature 385 (0.016871)
feature 14 (0.015348)
feature 176 (0.015281)
feature 84 (0.014795)
feature 211 (0.014765)
feature 169 (0.014434)
feature 43 (0.014363)
feature 166 (0.013452)
feature 30 (0.013391)
feature 58 (0.013321)
feature 136 (0.013098)
feature 198 (0.012990)
feature 133 (0.012587)
feature 24 (0.011851)
feature 175 (0.011591)
feature 46 (0.011229)
feature 110 (0.010924)
feature 12 (0.010269)
feature 138 (0.009863)
feature 222 (0.009390)
feature 128 (0.009295)
feature 157 (0.008984)
inner fold=1
accuracy=0.652173913043
feature 203 (0.029728)
feature 142 (0.024336)
feature 294 (0.022021)
feature 168 (0.021815)
feature 164 (0.021073)
feature 55 (0.019924)
feature 126 (0.019150)
feature 43 (0.018187)
feature 107 (0.018085)
feature 81 (0.017462)
feature 54 (0.016680)
feature 157 (0.016398)
feature 129 (0.016348)
feature 12 (0.016182)
feature 53 (0.015490)
feature 57 (0.015215)
feature 381 (0.014088)
feature 166 (0.013841)
feature 24 (0.013796)
feature 202 (0.013715)
feature 128 (0.013316)
feature 110 (0.013289)
feature 172 (0.012891)
feature 231 (0.012534)
feature 139 (0.012013)
feature 148 (0.011994)
feature 227 (0.011965)
feature 199 (0.011731)
feature 213 (0.011631)
feature 130 (0.011368)
inner fold=2
accuracy=0.565217391304
feature 175 (0.033421)
feature 79 (0.027992)
feature 174 (0.022073)
feature 107 (0.021539)
feature 156 (0.019246)
feature 77 (0.019145)
feature 80 (0.017430)
feature 55 (0.017240)
feature 235 (0.016472)
feature 14 (0.015728)
feature 158 (0.015225)
feature 56 (0.015176)
feature 166 (0.014995)
feature 130 (0.014489)
feature 33 (0.014328)
feature 81 (0.013852)
feature 172 (0.013263)
feature 168 (0.013251)
feature 145 (0.012712)
feature 131 (0.012091)
feature 381 (0.011479)
feature 126 (0.011412)
feature 104 (0.011399)
feature 143 (0.011397)
feature 62 (0.011154)
feature 294 (0.011140)
feature 102 (0.011091)
feature 188 (0.010802)
feature 182 (0.010267)
feature 155 (0.010251)
inner fold=3
accuracy=0.6
feature 294 (0.037234)
feature 81 (0.031067)
feature 78 (0.024608)
feature 77 (0.023503)
feature 42 (0.022787)
feature 175 (0.020719)
feature 58 (0.019394)
feature 43 (0.016570)
feature 106 (0.016200)
feature 211 (0.015686)
feature 166 (0.014320)
feature 134 (0.013861)
feature 122 (0.013799)
feature 84 (0.013743)
feature 139 (0.013500)
feature 44 (0.013491)
feature 184 (0.013248)
feature 2 (0.013219)
feature 24 (0.012895)
feature 71 (0.012738)
feature 123 (0.012566)
feature 383 (0.012413)
feature 69 (0.012233)
feature 14 (0.011394)
feature 155 (0.011044)
feature 129 (0.010606)
feature 151 (0.010491)
feature 83 (0.010202)
feature 163 (0.010042)
feature 50 (0.010004)
inner fold=4
accuracy=0.622222222222
feature 46 (0.027118)
feature 235 (0.026588)
feature 294 (0.021761)
feature 171 (0.020655)
feature 203 (0.018327)
feature 153 (0.018239)
feature 156 (0.015170)
feature 285 (0.014261)
feature 52 (0.014001)
feature 137 (0.014000)
feature 125 (0.013745)
feature 214 (0.013593)
feature 157 (0.013008)
feature 188 (0.012881)
feature 149 (0.012727)
feature 110 (0.012586)
feature 109 (0.012540)
feature 106 (0.012178)
feature 381 (0.011938)
feature 123 (0.011865)
feature 344 (0.011475)
feature 102 (0.011433)
feature 44 (0.011181)
feature 216 (0.010988)
feature 161 (0.010968)
feature 231 (0.010912)
feature 165 (0.010613)
feature 164 (0.010546)
feature 234 (0.010174)
feature 390 (0.010158)
inner fold=0
accuracy=0.531914893617
feature 46 (0.032380)
feature 44 (0.026360)
feature 152 (0.024622)
feature 97 (0.022598)
feature 81 (0.022009)
feature 203 (0.019972)
feature 166 (0.019644)
feature 156 (0.019040)
feature 56 (0.018344)
feature 34 (0.016234)
feature 79 (0.016185)
feature 211 (0.016010)
feature 43 (0.015788)
feature 199 (0.015008)
feature 143 (0.014450)
feature 123 (0.014205)
feature 209 (0.013964)
feature 135 (0.013534)
feature 127 (0.013424)
feature 78 (0.012975)
feature 181 (0.012927)
feature 139 (0.012890)
feature 238 (0.012564)
feature 223 (0.012515)
feature 174 (0.011916)
feature 110 (0.011617)
feature 128 (0.011457)
feature 38 (0.011357)
feature 151 (0.011351)
feature 227 (0.011318)
inner fold=1
accuracy=0.45652173913
feature 148 (0.023350)
feature 15 (0.020675)
feature 69 (0.018545)
feature 209 (0.018020)
feature 24 (0.017556)
feature 77 (0.017206)
feature 169 (0.017067)
feature 349 (0.017027)
feature 82 (0.016651)
feature 151 (0.015890)
feature 53 (0.015229)
feature 78 (0.015147)
feature 129 (0.014934)
feature 166 (0.014316)
feature 58 (0.014292)
feature 211 (0.014210)
feature 216 (0.014031)
feature 81 (0.012809)
feature 70 (0.012701)
feature 294 (0.012603)
feature 215 (0.012382)
feature 160 (0.012380)
feature 231 (0.012372)
feature 46 (0.012075)
feature 377 (0.011689)
feature 80 (0.011429)
feature 203 (0.011387)
feature 45 (0.011370)
feature 167 (0.011104)
feature 18 (0.010945)
inner fold=2
accuracy=0.5
feature 168 (0.031795)
feature 128 (0.023297)
feature 52 (0.021800)
feature 155 (0.020013)
feature 81 (0.020004)
feature 78 (0.018836)
feature 172 (0.018630)
feature 50 (0.017713)
feature 285 (0.017465)
feature 71 (0.017095)
feature 55 (0.016333)
feature 129 (0.016168)
feature 24 (0.014485)
feature 134 (0.014370)
feature 135 (0.014026)
feature 18 (0.013803)
feature 166 (0.013670)
feature 222 (0.012800)
feature 56 (0.012789)
feature 130 (0.012701)
feature 44 (0.012376)
feature 43 (0.011312)
feature 208 (0.011162)
feature 188 (0.011080)
feature 115 (0.010920)
feature 46 (0.010762)
feature 79 (0.010493)
feature 110 (0.010484)
feature 34 (0.010438)
feature 77 (0.009454)
inner fold=3
accuracy=0.466666666667
feature 172 (0.039081)
feature 168 (0.023319)
feature 231 (0.023007)
feature 227 (0.020294)
feature 70 (0.020269)
feature 103 (0.018198)
feature 48 (0.016538)
feature 81 (0.016112)
feature 101 (0.014870)
feature 175 (0.014857)
feature 1 (0.014690)
feature 156 (0.014566)
feature 5 (0.014236)
feature 142 (0.014145)
feature 294 (0.014095)
feature 203 (0.013593)
feature 216 (0.013355)
feature 200 (0.012751)
feature 381 (0.012688)
feature 159 (0.012659)
feature 122 (0.012405)
feature 46 (0.012382)
feature 184 (0.012214)
feature 82 (0.012113)
feature 56 (0.012080)
feature 235 (0.011966)
feature 127 (0.011964)
feature 77 (0.011929)
feature 214 (0.011926)
feature 167 (0.011898)
inner fold=4
accuracy=0.6

lay_id=2
feature 168 (0.031352)
feature 109 (0.028350)
feature 172 (0.022396)
feature 134 (0.018200)
feature 203 (0.017742)
feature 125 (0.017514)
feature 34 (0.017513)
feature 156 (0.017094)
feature 43 (0.016381)
feature 53 (0.015757)
feature 46 (0.015272)
feature 72 (0.015144)
feature 81 (0.014980)
feature 123 (0.014683)
feature 48 (0.013856)
feature 412 (0.013596)
feature 128 (0.013419)
feature 148 (0.013375)
feature 131 (0.012810)
feature 73 (0.011596)
feature 90 (0.011470)
feature 110 (0.011413)
feature 105 (0.011173)
feature 129 (0.011146)
feature 102 (0.011087)
feature 208 (0.011009)
feature 175 (0.010875)
feature 4 (0.010866)
feature 166 (0.010575)
feature 173 (0.010542)
inner fold=0
accuracy=0.404255319149
feature 172 (0.030185)
feature 139 (0.029931)
feature 171 (0.025289)
feature 24 (0.024317)
feature 164 (0.023409)
feature 81 (0.023181)
feature 227 (0.022980)
feature 216 (0.017974)
feature 136 (0.017784)
feature 141 (0.017443)
feature 33 (0.015790)
feature 101 (0.014973)
feature 135 (0.013187)
feature 123 (0.012941)
feature 52 (0.012717)
feature 153 (0.012487)
feature 106 (0.012442)
feature 161 (0.012255)
feature 2 (0.012242)
feature 142 (0.012020)
feature 235 (0.011621)
feature 134 (0.011613)
feature 14 (0.010687)
feature 157 (0.010672)
feature 180 (0.010666)
feature 46 (0.010558)
feature 143 (0.010289)
feature 202 (0.010280)
feature 208 (0.010246)
feature 127 (0.010024)
inner fold=1
accuracy=0.586956521739
feature 173 (0.029845)
feature 412 (0.024487)
feature 81 (0.020313)
feature 464 (0.020233)
feature 51 (0.019855)
feature 83 (0.019689)
feature 71 (0.017761)
feature 148 (0.016549)
feature 408 (0.016130)
feature 30 (0.015826)
feature 5 (0.014884)
feature 60 (0.014817)
feature 362 (0.014518)
feature 70 (0.014465)
feature 24 (0.014439)
feature 174 (0.014357)
feature 123 (0.014135)
feature 127 (0.013848)
feature 47 (0.013278)
feature 197 (0.012796)
feature 133 (0.012094)
feature 4 (0.011996)
feature 120 (0.011973)
feature 129 (0.011621)
feature 166 (0.011435)
feature 153 (0.011381)
feature 40 (0.011232)
feature 39 (0.010794)
feature 194 (0.010721)
feature 78 (0.010222)
inner fold=2
accuracy=0.630434782609
feature 168 (0.025843)
feature 122 (0.022626)
feature 46 (0.022013)
feature 211 (0.021092)
feature 131 (0.019805)
feature 210 (0.019464)
feature 203 (0.019312)
feature 164 (0.018493)
feature 294 (0.016942)
feature 70 (0.016686)
feature 84 (0.016614)
feature 130 (0.016441)
feature 12 (0.016208)
feature 110 (0.015244)
feature 166 (0.015211)
feature 301 (0.015200)
feature 208 (0.014863)
feature 148 (0.014733)
feature 107 (0.014535)
feature 143 (0.014508)
feature 33 (0.014171)
feature 102 (0.014107)
feature 151 (0.013475)
feature 83 (0.013305)
feature 123 (0.013117)
feature 235 (0.012084)
feature 134 (0.011487)
feature 40 (0.011205)
feature 142 (0.010607)
feature 147 (0.010583)
inner fold=3
accuracy=0.666666666667
feature 136 (0.021913)
feature 199 (0.021266)
feature 166 (0.020263)
feature 131 (0.019996)
feature 165 (0.019198)
feature 33 (0.018370)
feature 158 (0.016729)
feature 137 (0.016307)
feature 129 (0.016234)
feature 34 (0.015968)
feature 84 (0.015291)
feature 175 (0.015211)
feature 110 (0.014724)
feature 176 (0.014602)
feature 214 (0.014553)
feature 193 (0.014206)
feature 30 (0.013730)
feature 139 (0.013330)
feature 174 (0.013324)
feature 53 (0.013317)
feature 160 (0.012781)
feature 216 (0.012319)
feature 156 (0.012272)
feature 72 (0.011905)
feature 184 (0.011483)
feature 142 (0.011321)
feature 102 (0.010755)
feature 203 (0.010685)
feature 79 (0.010580)
feature 1 (0.010558)
inner fold=4
accuracy=0.577777777778
feature 294 (0.029674)
feature 209 (0.025418)
feature 81 (0.023523)
feature 171 (0.022839)
feature 203 (0.020062)
feature 129 (0.018289)
feature 136 (0.017962)
feature 101 (0.017408)
feature 134 (0.016480)
feature 109 (0.015166)
feature 56 (0.014841)
feature 47 (0.014817)
feature 215 (0.014602)
feature 139 (0.013844)
feature 163 (0.013182)
feature 173 (0.012861)
feature 14 (0.012635)
feature 97 (0.012055)
feature 174 (0.011949)
feature 44 (0.011685)
feature 12 (0.011643)
feature 43 (0.011394)
feature 231 (0.011062)
feature 151 (0.010728)
feature 78 (0.010688)
feature 216 (0.010654)
feature 58 (0.010651)
feature 125 (0.010440)
feature 381 (0.010370)
feature 155 (0.010314)
inner fold=0
accuracy=0.659574468085
feature 171 (0.039596)
feature 211 (0.029662)
feature 216 (0.028176)
feature 157 (0.027993)
feature 115 (0.020499)
feature 209 (0.016760)
feature 173 (0.016500)
feature 84 (0.015805)
feature 34 (0.014617)
feature 12 (0.014149)
feature 110 (0.013729)
feature 54 (0.013664)
feature 62 (0.012967)
feature 128 (0.012615)
feature 16 (0.012495)
feature 147 (0.012397)
feature 78 (0.012295)
feature 143 (0.012005)
feature 125 (0.011555)
feature 454 (0.010914)
feature 385 (0.010375)
feature 15 (0.010367)
feature 272 (0.010317)
feature 46 (0.010256)
feature 231 (0.010138)
feature 68 (0.009968)
feature 203 (0.009904)
feature 227 (0.009585)
feature 151 (0.009291)
feature 175 (0.009159)
inner fold=1
accuracy=0.652173913043
feature 294 (0.029090)
feature 43 (0.027593)
feature 55 (0.027491)
feature 161 (0.024770)
feature 46 (0.021825)
feature 14 (0.020296)
feature 109 (0.020251)
feature 56 (0.019948)
feature 30 (0.016863)
feature 222 (0.016304)
feature 41 (0.015915)
feature 158 (0.015801)
feature 125 (0.015461)
feature 130 (0.015084)
feature 174 (0.014566)
feature 272 (0.013625)
feature 81 (0.012938)
feature 173 (0.012655)
feature 153 (0.012483)
feature 168 (0.012405)
feature 171 (0.012293)
feature 362 (0.012208)
feature 24 (0.011975)
feature 203 (0.011849)
feature 235 (0.011834)
feature 129 (0.011507)
feature 103 (0.011424)
feature 166 (0.011408)
feature 157 (0.011320)
feature 53 (0.011175)
inner fold=2
accuracy=0.630434782609
feature 294 (0.035418)
feature 81 (0.027358)
feature 29 (0.026401)
feature 171 (0.024869)
feature 126 (0.021986)
feature 362 (0.021783)
feature 166 (0.019126)
feature 122 (0.017898)
feature 69 (0.017702)
feature 142 (0.016792)
feature 3 (0.016469)
feature 184 (0.016047)
feature 203 (0.015859)
feature 14 (0.015568)
feature 159 (0.015172)
feature 46 (0.015089)
feature 155 (0.014538)
feature 156 (0.014301)
feature 60 (0.014116)
feature 24 (0.013696)
feature 160 (0.012888)
feature 58 (0.012636)
feature 207 (0.012207)
feature 79 (0.010854)
feature 344 (0.010699)
feature 101 (0.010684)
feature 71 (0.010610)
feature 151 (0.010240)
feature 131 (0.009986)
feature 50 (0.009851)
inner fold=3
accuracy=0.6
feature 129 (0.045512)
feature 153 (0.024494)
feature 294 (0.022849)
feature 203 (0.019968)
feature 173 (0.019925)
feature 216 (0.019609)
feature 4 (0.018868)
feature 180 (0.017411)
feature 17 (0.016326)
feature 143 (0.015978)
feature 53 (0.015044)
feature 171 (0.014637)
feature 120 (0.014628)
feature 84 (0.013278)
feature 464 (0.012960)
feature 377 (0.012931)
feature 166 (0.012783)
feature 168 (0.012284)
feature 123 (0.011499)
feature 109 (0.011488)
feature 12 (0.011417)
feature 300 (0.011408)
feature 210 (0.010992)
feature 275 (0.010448)
feature 152 (0.010304)
feature 172 (0.009897)
feature 186 (0.009687)
feature 214 (0.009538)
feature 24 (0.009516)
feature 181 (0.009423)
inner fold=4
accuracy=0.622222222222

lay_id=3
feature 24 (0.024587)
feature 148 (0.024503)
feature 168 (0.020207)
feature 164 (0.019470)
feature 173 (0.019382)
feature 56 (0.019208)
feature 81 (0.017744)
feature 30 (0.016738)
feature 55 (0.016543)
feature 294 (0.016192)
feature 172 (0.015799)
feature 53 (0.015248)
feature 77 (0.014891)
feature 129 (0.014713)
feature 142 (0.014606)
feature 58 (0.014386)
feature 175 (0.013816)
feature 430 (0.013779)
feature 227 (0.013554)
feature 78 (0.013376)
feature 84 (0.012736)
feature 194 (0.011993)
feature 114 (0.011906)
feature 57 (0.011884)
feature 222 (0.011715)
feature 134 (0.011579)
feature 186 (0.011499)
feature 165 (0.011399)
feature 211 (0.010494)
feature 171 (0.010399)
inner fold=0
accuracy=0.574468085106
feature 153 (0.033880)
feature 79 (0.027596)
feature 171 (0.024692)
feature 125 (0.022320)
feature 294 (0.021829)
feature 158 (0.019706)
feature 174 (0.018804)
feature 81 (0.018301)
feature 40 (0.016982)
feature 123 (0.015993)
feature 142 (0.015020)
feature 235 (0.014285)
feature 362 (0.013775)
feature 159 (0.013485)
feature 173 (0.012103)
feature 77 (0.012068)
feature 164 (0.012027)
feature 56 (0.012021)
feature 381 (0.010925)
feature 213 (0.010715)
feature 22 (0.010650)
feature 48 (0.010554)
feature 151 (0.010544)
feature 135 (0.009934)
feature 122 (0.009918)
feature 285 (0.009890)
feature 385 (0.009844)
feature 58 (0.009833)
feature 168 (0.009298)
feature 43 (0.009219)
inner fold=1
accuracy=0.652173913043
feature 215 (0.027609)
feature 123 (0.024173)
feature 235 (0.023417)
feature 173 (0.023070)
feature 131 (0.022230)
feature 52 (0.020672)
feature 138 (0.020412)
feature 100 (0.020184)
feature 115 (0.019751)
feature 157 (0.019065)
feature 175 (0.017909)
feature 168 (0.016685)
feature 57 (0.016500)
feature 151 (0.015894)
feature 30 (0.015848)
feature 172 (0.015784)
feature 81 (0.015422)
feature 120 (0.014836)
feature 1 (0.014311)
feature 78 (0.013915)
feature 28 (0.013830)
feature 53 (0.013470)
feature 56 (0.013306)
feature 126 (0.013217)
feature 135 (0.012173)
feature 362 (0.012162)
feature 110 (0.012098)
feature 159 (0.011853)
feature 181 (0.011235)
feature 3 (0.011174)
inner fold=2
accuracy=0.5
feature 166 (0.032073)
feature 115 (0.026294)
feature 153 (0.026062)
feature 227 (0.020751)
feature 130 (0.020620)
feature 55 (0.019859)
feature 294 (0.019191)
feature 159 (0.017881)
feature 157 (0.017717)
feature 385 (0.015413)
feature 84 (0.015096)
feature 38 (0.014806)
feature 51 (0.014625)
feature 171 (0.014517)
feature 128 (0.014459)
feature 168 (0.013609)
feature 151 (0.013318)
feature 136 (0.013179)
feature 122 (0.013057)
feature 156 (0.012707)
feature 103 (0.012444)
feature 412 (0.012229)
feature 39 (0.011836)
feature 215 (0.011804)
feature 172 (0.011730)
feature 235 (0.011178)
feature 199 (0.011050)
feature 207 (0.010989)
feature 137 (0.010468)
feature 158 (0.010242)
inner fold=3
accuracy=0.622222222222
feature 81 (0.052337)
feature 43 (0.025636)
feature 174 (0.023318)
feature 129 (0.023132)
feature 168 (0.021064)
feature 48 (0.019520)
feature 151 (0.019260)
feature 203 (0.017711)
feature 223 (0.017058)
feature 224 (0.015630)
feature 148 (0.015394)
feature 136 (0.015140)
feature 215 (0.014815)
feature 123 (0.014791)
feature 235 (0.014570)
feature 211 (0.013685)
feature 134 (0.013517)
feature 138 (0.012597)
feature 173 (0.012435)
feature 35 (0.012350)
feature 180 (0.012228)
feature 383 (0.012035)
feature 231 (0.011974)
feature 80 (0.011317)
feature 171 (0.011136)
feature 78 (0.010800)
feature 389 (0.010432)
feature 199 (0.010402)
feature 18 (0.010285)
feature 165 (0.009980)
inner fold=4
accuracy=0.555555555556
feature 142 (0.046668)
feature 84 (0.027284)
feature 155 (0.022862)
feature 159 (0.021086)
feature 166 (0.017654)
feature 171 (0.017304)
feature 101 (0.017039)
feature 153 (0.016417)
feature 231 (0.015724)
feature 167 (0.015172)
feature 168 (0.015083)
feature 227 (0.015020)
feature 294 (0.014875)
feature 69 (0.014562)
feature 13 (0.014560)
feature 29 (0.014476)
feature 46 (0.014360)
feature 199 (0.013393)
feature 52 (0.012184)
feature 81 (0.012139)
feature 30 (0.012051)
feature 208 (0.011815)
feature 202 (0.011272)
feature 38 (0.011266)
feature 100 (0.011034)
feature 165 (0.010799)
feature 40 (0.010725)
feature 109 (0.010443)
feature 131 (0.010281)
feature 35 (0.010056)
inner fold=0
accuracy=0.63829787234
feature 129 (0.029922)
feature 216 (0.025299)
feature 173 (0.023581)
feature 165 (0.022974)
feature 168 (0.021674)
feature 81 (0.021397)
feature 122 (0.019869)
feature 145 (0.018524)
feature 78 (0.018126)
feature 171 (0.017782)
feature 172 (0.017540)
feature 109 (0.017390)
feature 24 (0.017094)
feature 164 (0.015941)
feature 127 (0.015399)
feature 203 (0.014875)
feature 135 (0.014852)
feature 110 (0.013174)
feature 142 (0.012860)
feature 123 (0.012852)
feature 143 (0.012711)
feature 161 (0.012688)
feature 44 (0.012578)
feature 148 (0.011610)
feature 126 (0.011547)
feature 51 (0.011518)
feature 43 (0.011028)
feature 50 (0.010601)
feature 5 (0.010321)
feature 166 (0.010129)
inner fold=1
accuracy=0.695652173913
feature 231 (0.042207)
feature 294 (0.037984)
feature 159 (0.029803)
feature 168 (0.027622)
feature 175 (0.023507)
feature 101 (0.021200)
feature 157 (0.020173)
feature 158 (0.018665)
feature 81 (0.015978)
feature 127 (0.015949)
feature 97 (0.015815)
feature 344 (0.015007)
feature 84 (0.014892)
feature 33 (0.014452)
feature 102 (0.014294)
feature 13 (0.013801)
feature 154 (0.012784)
feature 143 (0.012637)
feature 227 (0.012445)
feature 207 (0.012288)
feature 156 (0.012007)
feature 164 (0.011953)
feature 160 (0.011947)
feature 134 (0.011655)
feature 152 (0.011103)
feature 202 (0.011029)
feature 79 (0.010687)
feature 28 (0.010685)
feature 107 (0.010605)
feature 109 (0.010540)
inner fold=2
accuracy=0.5
feature 235 (0.036406)
feature 231 (0.029991)
feature 168 (0.023900)
feature 53 (0.020181)
feature 294 (0.016970)
feature 102 (0.016910)
feature 166 (0.016606)
feature 18 (0.015902)
feature 107 (0.015868)
feature 134 (0.015618)
feature 385 (0.014949)
feature 36 (0.014776)
feature 159 (0.014515)
feature 161 (0.014141)
feature 171 (0.013670)
feature 58 (0.013396)
feature 377 (0.012481)
feature 454 (0.012355)
feature 173 (0.012224)
feature 123 (0.012185)
feature 364 (0.012138)
feature 155 (0.012090)
feature 115 (0.012038)
feature 43 (0.011843)
feature 80 (0.011811)
feature 101 (0.011732)
feature 175 (0.011258)
feature 224 (0.011054)
feature 169 (0.010882)
feature 164 (0.010810)
inner fold=3
accuracy=0.6
feature 168 (0.040854)
feature 294 (0.027165)
feature 14 (0.024434)
feature 123 (0.024054)
feature 101 (0.023531)
feature 134 (0.021565)
feature 110 (0.019179)
feature 43 (0.017274)
feature 136 (0.017159)
feature 78 (0.017032)
feature 372 (0.015753)
feature 81 (0.015378)
feature 164 (0.014893)
feature 120 (0.014833)
feature 157 (0.014818)
feature 215 (0.014559)
feature 122 (0.013987)
feature 227 (0.013759)
feature 344 (0.013639)
feature 130 (0.013231)
feature 171 (0.012974)
feature 126 (0.012948)
feature 153 (0.012630)
feature 57 (0.012446)
feature 79 (0.011470)
feature 50 (0.011271)
feature 21 (0.011063)
feature 140 (0.010512)
feature 188 (0.010499)
feature 231 (0.010463)
inner fold=4
accuracy=0.666666666667

lay_id=4
feature 158 (0.028929)
feature 294 (0.027062)
feature 207 (0.021001)
feature 53 (0.020908)
feature 43 (0.019915)
feature 33 (0.019245)
feature 135 (0.018449)
feature 14 (0.017777)
feature 344 (0.016142)
feature 52 (0.015233)
feature 168 (0.015080)
feature 44 (0.014883)
feature 136 (0.014836)
feature 383 (0.013897)
feature 147 (0.013859)
feature 122 (0.013853)
feature 210 (0.013544)
feature 13 (0.012895)
feature 77 (0.012732)
feature 203 (0.012256)
feature 166 (0.012197)
feature 211 (0.012181)
feature 362 (0.012138)
feature 57 (0.011608)
feature 174 (0.011550)
feature 301 (0.011183)
feature 17 (0.010908)
feature 184 (0.010581)
feature 56 (0.010277)
feature 102 (0.010025)
inner fold=0
accuracy=0.595744680851
feature 81 (0.032271)
feature 52 (0.030401)
feature 203 (0.030169)
feature 120 (0.029922)
feature 148 (0.027195)
feature 24 (0.026938)
feature 51 (0.023842)
feature 56 (0.021677)
feature 222 (0.020241)
feature 127 (0.016824)
feature 136 (0.016712)
feature 55 (0.015930)
feature 171 (0.014928)
feature 294 (0.013627)
feature 156 (0.013165)
feature 362 (0.012534)
feature 123 (0.012409)
feature 54 (0.011551)
feature 57 (0.010973)
feature 383 (0.010346)
feature 77 (0.010294)
feature 78 (0.010215)
feature 142 (0.010007)
feature 202 (0.009991)
feature 126 (0.009658)
feature 209 (0.009261)
feature 214 (0.009189)
feature 464 (0.009058)
feature 128 (0.008837)
feature 27 (0.008776)
inner fold=1
accuracy=0.608695652174
feature 4 (0.024813)
feature 294 (0.023855)
feature 57 (0.022274)
feature 213 (0.020527)
feature 81 (0.020023)
feature 125 (0.019296)
feature 168 (0.017358)
feature 151 (0.017204)
feature 172 (0.016351)
feature 28 (0.015549)
feature 123 (0.015061)
feature 38 (0.014408)
feature 222 (0.014237)
feature 167 (0.014195)
feature 344 (0.013994)
feature 174 (0.013608)
feature 148 (0.013104)
feature 138 (0.012504)
feature 134 (0.012433)
feature 55 (0.012256)
feature 161 (0.012182)
feature 135 (0.011482)
feature 62 (0.011341)
feature 199 (0.011296)
feature 2 (0.011197)
feature 200 (0.011157)
feature 208 (0.010940)
feature 211 (0.010834)
feature 227 (0.010801)
feature 122 (0.010772)
inner fold=2
accuracy=0.695652173913
feature 78 (0.026296)
feature 164 (0.025143)
feature 28 (0.023872)
feature 294 (0.020783)
feature 174 (0.019596)
feature 168 (0.018941)
feature 207 (0.018445)
feature 128 (0.017549)
feature 55 (0.017340)
feature 137 (0.016579)
feature 153 (0.016533)
feature 127 (0.016182)
feature 46 (0.015514)
feature 3 (0.015434)
feature 173 (0.014399)
feature 52 (0.014061)
feature 167 (0.013641)
feature 22 (0.013460)
feature 171 (0.013429)
feature 42 (0.013214)
feature 38 (0.013199)
feature 158 (0.013006)
feature 148 (0.012921)
feature 411 (0.012403)
feature 219 (0.012377)
feature 138 (0.012313)
feature 114 (0.012206)
feature 14 (0.011876)
feature 47 (0.011743)
feature 235 (0.011736)
inner fold=3
accuracy=0.644444444444
feature 168 (0.048943)
feature 102 (0.028789)
feature 134 (0.026442)
feature 18 (0.026110)
feature 81 (0.019829)
feature 129 (0.019235)
feature 137 (0.019205)
feature 79 (0.018392)
feature 128 (0.015389)
feature 131 (0.015281)
feature 161 (0.014155)
feature 143 (0.012827)
feature 125 (0.012734)
feature 53 (0.012427)
feature 123 (0.012329)
feature 57 (0.012103)
feature 152 (0.012014)
feature 54 (0.011953)
feature 51 (0.011541)
feature 24 (0.011193)
feature 44 (0.010845)
feature 48 (0.010703)
feature 84 (0.010642)
feature 62 (0.010475)
feature 235 (0.010280)
feature 136 (0.010114)
feature 173 (0.009606)
feature 126 (0.009501)
feature 151 (0.009459)
feature 397 (0.009366)
inner fold=4
accuracy=0.6
feature 184 (0.026133)
feature 81 (0.023564)
feature 171 (0.023287)
feature 164 (0.023068)
feature 172 (0.022814)
feature 235 (0.019381)
feature 107 (0.019112)
feature 90 (0.018193)
feature 168 (0.016043)
feature 151 (0.015879)
feature 24 (0.015776)
feature 166 (0.015278)
feature 174 (0.014209)
feature 34 (0.014196)
feature 216 (0.014060)
feature 161 (0.013980)
feature 169 (0.013310)
feature 18 (0.012631)
feature 210 (0.012485)
feature 130 (0.011788)
feature 77 (0.011674)
feature 58 (0.011603)
feature 201 (0.011600)
feature 208 (0.011180)
feature 396 (0.011007)
feature 42 (0.010690)
feature 139 (0.010393)
feature 142 (0.010318)
feature 38 (0.010250)
feature 102 (0.009949)
inner fold=0
accuracy=0.446808510638
feature 81 (0.047098)
feature 157 (0.021746)
feature 174 (0.021294)
feature 138 (0.019947)
feature 166 (0.019756)
feature 207 (0.018202)
feature 103 (0.017449)
feature 139 (0.016952)
feature 105 (0.016766)
feature 14 (0.015916)
feature 57 (0.015364)
feature 148 (0.015310)
feature 101 (0.013687)
feature 110 (0.012898)
feature 223 (0.012539)
feature 54 (0.012492)
feature 45 (0.012344)
feature 82 (0.011947)
feature 165 (0.011662)
feature 235 (0.011646)
feature 106 (0.011441)
feature 104 (0.011255)
feature 145 (0.010961)
feature 381 (0.010775)
feature 385 (0.010652)
feature 143 (0.010372)
feature 383 (0.010136)
feature 134 (0.010028)
feature 175 (0.009998)
feature 70 (0.009556)
inner fold=1
accuracy=0.652173913043
feature 81 (0.033274)
feature 294 (0.031212)
feature 139 (0.029459)
feature 149 (0.017461)
feature 155 (0.016296)
feature 172 (0.016177)
feature 227 (0.016087)
feature 209 (0.015951)
feature 129 (0.015832)
feature 79 (0.015359)
feature 101 (0.014181)
feature 138 (0.014130)
feature 171 (0.014111)
feature 123 (0.014085)
feature 42 (0.013865)
feature 102 (0.013720)
feature 3 (0.013272)
feature 165 (0.012714)
feature 84 (0.012252)
feature 275 (0.012133)
feature 151 (0.012118)
feature 127 (0.011704)
feature 145 (0.011405)
feature 60 (0.011403)
feature 122 (0.011190)
feature 219 (0.010445)
feature 133 (0.010073)
feature 168 (0.009998)
feature 235 (0.009779)
feature 411 (0.009775)
inner fold=2
accuracy=0.652173913043
feature 102 (0.034371)
feature 56 (0.027880)
feature 385 (0.018891)
feature 157 (0.018397)
feature 175 (0.017654)
feature 14 (0.017468)
feature 60 (0.017268)
feature 207 (0.017188)
feature 210 (0.016829)
feature 171 (0.016784)
feature 155 (0.016543)
feature 18 (0.016458)
feature 123 (0.016436)
feature 275 (0.015611)
feature 105 (0.015373)
feature 78 (0.015023)
feature 172 (0.014285)
feature 21 (0.014003)
feature 153 (0.013972)
feature 164 (0.013810)
feature 168 (0.013781)
feature 81 (0.013708)
feature 122 (0.013358)
feature 57 (0.012469)
feature 138 (0.011506)
feature 156 (0.011229)
feature 29 (0.011207)
feature 145 (0.011179)
feature 202 (0.010952)
feature 209 (0.010822)
inner fold=3
accuracy=0.577777777778
feature 136 (0.024739)
feature 123 (0.024464)
feature 46 (0.020767)
feature 81 (0.020165)
feature 235 (0.020038)
feature 168 (0.018414)
feature 15 (0.017937)
feature 165 (0.017549)
feature 171 (0.017489)
feature 208 (0.017296)
feature 110 (0.015742)
feature 114 (0.014910)
feature 115 (0.014733)
feature 294 (0.014651)
feature 126 (0.014215)
feature 107 (0.014055)
feature 222 (0.013585)
feature 381 (0.013391)
feature 362 (0.013369)
feature 166 (0.012926)
feature 79 (0.012631)
feature 285 (0.011710)
feature 4 (0.011168)
feature 134 (0.010897)
feature 203 (0.010668)
feature 53 (0.010599)
feature 138 (0.010327)
feature 0 (0.010220)
feature 103 (0.010161)
feature 44 (0.010098)
inner fold=4
accuracy=0.666666666667

lay_id=5
feature 171 (0.032592)
feature 120 (0.031643)
feature 46 (0.028674)
feature 81 (0.025223)
feature 285 (0.020486)
feature 159 (0.020166)
feature 84 (0.019256)
feature 153 (0.018044)
feature 385 (0.017880)
feature 227 (0.017560)
feature 34 (0.015769)
feature 272 (0.015664)
feature 174 (0.015577)
feature 219 (0.014976)
feature 362 (0.014854)
feature 223 (0.014661)
feature 152 (0.014428)
feature 115 (0.013942)
feature 235 (0.013787)
feature 158 (0.013415)
feature 33 (0.013257)
feature 164 (0.012886)
feature 135 (0.012408)
feature 106 (0.012362)
feature 197 (0.012134)
feature 122 (0.011844)
feature 203 (0.011836)
feature 14 (0.011795)
feature 131 (0.011334)
feature 54 (0.010907)
inner fold=0
accuracy=0.68085106383
feature 168 (0.040198)
feature 84 (0.036089)
feature 142 (0.024134)
feature 44 (0.022365)
feature 55 (0.021387)
feature 18 (0.020477)
feature 51 (0.020348)
feature 390 (0.019848)
feature 52 (0.019065)
feature 136 (0.019065)
feature 214 (0.018358)
feature 381 (0.017153)
feature 172 (0.016197)
feature 81 (0.015276)
feature 114 (0.014193)
feature 166 (0.013573)
feature 128 (0.013539)
feature 107 (0.013266)
feature 110 (0.012579)
feature 123 (0.012046)
feature 171 (0.011778)
feature 139 (0.011646)
feature 129 (0.011535)
feature 35 (0.011372)
feature 159 (0.011121)
feature 194 (0.011109)
feature 156 (0.010562)
feature 231 (0.010420)
feature 207 (0.010415)
feature 106 (0.010344)
inner fold=1
accuracy=0.673913043478
feature 231 (0.038820)
feature 156 (0.027251)
feature 103 (0.027099)
feature 235 (0.026308)
feature 168 (0.024310)
feature 166 (0.023533)
feature 158 (0.022722)
feature 163 (0.022252)
feature 129 (0.021762)
feature 165 (0.019156)
feature 115 (0.018663)
feature 301 (0.017411)
feature 18 (0.016793)
feature 104 (0.015871)
feature 71 (0.015148)
feature 174 (0.015020)
feature 84 (0.014500)
feature 46 (0.013488)
feature 14 (0.013399)
feature 294 (0.012829)
feature 126 (0.012781)
feature 110 (0.012492)
feature 184 (0.011934)
feature 202 (0.011772)
feature 385 (0.011743)
feature 123 (0.011449)
feature 80 (0.011022)
feature 30 (0.010458)
feature 136 (0.010207)
feature 203 (0.010187)
inner fold=2
accuracy=0.630434782609
feature 168 (0.031927)
feature 171 (0.031874)
feature 227 (0.031644)
feature 175 (0.025591)
feature 103 (0.024287)
feature 130 (0.021473)
feature 167 (0.018994)
feature 157 (0.018329)
feature 58 (0.017882)
feature 79 (0.017356)
feature 29 (0.016898)
feature 24 (0.016694)
feature 56 (0.016299)
feature 129 (0.015824)
feature 294 (0.015235)
feature 4 (0.013174)
feature 53 (0.013162)
feature 159 (0.012848)
feature 165 (0.012748)
feature 52 (0.011729)
feature 62 (0.011648)
feature 143 (0.011045)
feature 0 (0.010676)
feature 84 (0.010541)
feature 224 (0.010390)
feature 164 (0.010151)
feature 44 (0.009976)
feature 73 (0.009853)
feature 211 (0.009272)
feature 70 (0.009207)
inner fold=3
accuracy=0.6
feature 344 (0.032871)
feature 129 (0.027151)
feature 55 (0.022148)
feature 168 (0.021472)
feature 53 (0.020918)
feature 120 (0.020862)
feature 167 (0.020689)
feature 84 (0.019329)
feature 24 (0.017844)
feature 172 (0.015976)
feature 214 (0.015119)
feature 208 (0.015119)
feature 202 (0.014920)
feature 164 (0.013988)
feature 131 (0.013777)
feature 56 (0.013526)
feature 171 (0.012915)
feature 199 (0.012887)
feature 29 (0.012468)
feature 299 (0.012329)
feature 103 (0.012313)
feature 197 (0.012098)
feature 231 (0.012034)
feature 147 (0.011682)
feature 122 (0.011649)
feature 235 (0.011318)
feature 34 (0.011265)
feature 70 (0.011110)
feature 381 (0.010444)
feature 151 (0.010319)
inner fold=4
accuracy=0.666666666667
feature 156 (0.029408)
feature 203 (0.029364)
feature 130 (0.026679)
feature 136 (0.021024)
feature 171 (0.020334)
feature 139 (0.019699)
feature 168 (0.018048)
feature 14 (0.016518)
feature 4 (0.016153)
feature 199 (0.015071)
feature 235 (0.014928)
feature 84 (0.014589)
feature 56 (0.013609)
feature 148 (0.013009)
feature 34 (0.012812)
feature 137 (0.012699)
feature 216 (0.012524)
feature 131 (0.012356)
feature 207 (0.012337)
feature 2 (0.012329)
feature 209 (0.012288)
feature 123 (0.011850)
feature 57 (0.011752)
feature 30 (0.011735)
feature 18 (0.011368)
feature 51 (0.011072)
feature 142 (0.011008)
feature 160 (0.010708)
feature 62 (0.010642)
feature 21 (0.010624)
inner fold=0
accuracy=0.617021276596
feature 81 (0.050795)
feature 82 (0.034871)
feature 42 (0.025770)
feature 30 (0.024492)
feature 213 (0.022757)
feature 164 (0.020014)
feature 158 (0.018467)
feature 131 (0.018045)
feature 135 (0.018018)
feature 56 (0.017412)
feature 168 (0.015759)
feature 138 (0.015258)
feature 173 (0.014250)
feature 454 (0.014180)
feature 148 (0.013914)
feature 235 (0.013786)
feature 39 (0.013491)
feature 137 (0.012739)
feature 151 (0.012649)
feature 275 (0.012369)
feature 77 (0.012007)
feature 128 (0.011657)
feature 200 (0.011489)
feature 105 (0.011334)
feature 142 (0.010569)
feature 53 (0.010386)
feature 219 (0.010219)
feature 166 (0.009826)
feature 231 (0.009544)
feature 52 (0.009440)
inner fold=1
accuracy=0.717391304348
feature 203 (0.024571)
feature 107 (0.024551)
feature 153 (0.023921)
feature 168 (0.023241)
feature 171 (0.022705)
feature 115 (0.020416)
feature 130 (0.017939)
feature 14 (0.017223)
feature 137 (0.016462)
feature 12 (0.016144)
feature 18 (0.014783)
feature 62 (0.013993)
feature 80 (0.013896)
feature 48 (0.013518)
feature 79 (0.013440)
feature 181 (0.013008)
feature 209 (0.012999)
feature 172 (0.012985)
feature 148 (0.012336)
feature 35 (0.012313)
feature 110 (0.012007)
feature 235 (0.011571)
feature 27 (0.011521)
feature 120 (0.011488)
feature 139 (0.011427)
feature 46 (0.011228)
feature 160 (0.011180)
feature 164 (0.011011)
feature 173 (0.010878)
feature 58 (0.010637)
inner fold=2
accuracy=0.54347826087
feature 171 (0.032107)
feature 81 (0.030912)
feature 235 (0.027812)
feature 164 (0.025977)
feature 24 (0.025552)
feature 143 (0.024908)
feature 148 (0.022849)
feature 156 (0.020631)
feature 84 (0.018921)
feature 141 (0.016637)
feature 144 (0.015915)
feature 8 (0.015759)
feature 153 (0.015630)
feature 126 (0.015529)
feature 211 (0.015437)
feature 18 (0.015199)
feature 185 (0.013921)
feature 294 (0.013754)
feature 97 (0.012778)
feature 12 (0.012691)
feature 52 (0.012681)
feature 142 (0.012190)
feature 181 (0.012177)
feature 98 (0.012053)
feature 168 (0.012005)
feature 55 (0.011687)
feature 227 (0.011480)
feature 155 (0.010987)
feature 137 (0.010226)
feature 128 (0.010119)
inner fold=3
accuracy=0.555555555556
feature 136 (0.029412)
feature 137 (0.029388)
feature 134 (0.028210)
feature 51 (0.022874)
feature 123 (0.020437)
feature 38 (0.019923)
feature 362 (0.019501)
feature 109 (0.017793)
feature 163 (0.016537)
feature 78 (0.016510)
feature 128 (0.016033)
feature 155 (0.015831)
feature 158 (0.015802)
feature 213 (0.015050)
feature 172 (0.014579)
feature 79 (0.014393)
feature 46 (0.014122)
feature 294 (0.014020)
feature 235 (0.013739)
feature 174 (0.013590)
feature 165 (0.013525)
feature 156 (0.013306)
feature 80 (0.013064)
feature 101 (0.012866)
feature 125 (0.012723)
feature 143 (0.012314)
feature 159 (0.011742)
feature 214 (0.011422)
feature 34 (0.011390)
feature 42 (0.011254)
inner fold=4
accuracy=0.488888888889
